Système Agentique pour la Santé Anténatale — YAML System Complet
Architecture, Modèles ML/Santé, Frontend & Instructions Cursor

1. YAML SYSTEM PRINCIPAL — Configuration Complète
yamlCopy# ============================================================================
# SYSTÈME AGENTIQUE D'INTELLIGENCE OBSTÉTRICALE ET SANTÉ FŒTALE
# Version: 2.0.0
# Date: 2025-07-10
# Classification: Dispositif Médical IA - Classe IIb (EU MDR 2017/745)
# EU AI Act: Système à Haut Risque (Annexe III, §5)
# ============================================================================

apiVersion: obstetrics.ai/v2
kind: AgentOrchestratorConfig
metadata:
  name: obstetric-fetal-intelligence-system
  version: "2.0.0"
  description: >
    Plateforme agentique multi-modèles pour la surveillance fœto-maternelle,
    l'assistance obstétricale en salle de naissance, et le suivi néonatal.
    Système explicable (XAI) avec human-in-the-loop obligatoire pour
    toute décision critique. Ne se substitue jamais au jugement clinique.
  classification:
    medical_device_class: "IIb"
    eu_ai_act_risk: "high"
    intended_use: "Clinical Decision Support - Obstetrics & Neonatology"
    intended_users:
      - "Obstétriciens"
      - "Sages-femmes"
      - "Néonatologistes"
      - "Anesthésistes obstétricaux"
    clinical_setting: "Maternité niveau 2/3 avec bloc obstétrical et néonatologie"
  labels:
    domain: "obstetrics-neonatology"
    environment: "hospital-production"
    security_level: "phi-protected"
    fhir_version: "R4"

# ============================================================================
# SECTION 1: PRINCIPES ÉTHIQUES ET GOUVERNANCE
# ============================================================================
ethics:
  core_principles:
    primum_non_nocere:
      description: >
        Aucune recommandation ne doit compromettre la santé de la mère
        ou du fœtus. Mécanisme d'arrêt d'urgence si divergence détectée.
      enforcement: "hard_constraint"
      violation_action: "immediate_halt_and_notify"

    patient_autonomy:
      description: >
        Les parents sont informés et conservent le droit de refuser
        ou accepter les propositions. Décision partagée facilitée.
      enforcement: "soft_constraint"
      implementation: "informed_consent_tracking"

    transparency:
      description: >
        Chaque recommandation accompagnée d'une explication en langage
        clair, de références scientifiques (source, date, niveau de preuve,
        intervalle de confiance).
      enforcement: "hard_constraint"
      citation_format: "[Source, Année, Niveau de preuve]"

    human_supervision:
      description: >
        Validation clinicien obligatoire pour toute décision à haut risque.
        Classification pathologique = pause automatique + notification humaine.
      enforcement: "hard_constraint"
      escalation_chain:
        - level: 1
          role: "sage-femme de garde"
          timeout_seconds: 120
        - level: 2
          role: "obstétricien de garde"
          timeout_seconds: 180
        - level: 3
          role: "chef de service + équipe urgence"
          timeout_seconds: 60

  confidentiality:
    encryption_at_rest: "AES-256-GCM"
    encryption_in_transit: "TLS-1.3"
    data_anonymization: "k-anonymity (k>=5) + differential_privacy (ε=1.0)"
    consent_management: "FHIR Consent resource tracking"
    data_retention_policy: "10 years (legal medical record requirement)"
    right_to_erasure: "supported with audit trail preservation"

  audit:
    continuous_audit: true
    log_integrity: "SHA-256 hash chain (tamper-evident)"
    periodic_review: "quarterly"
    bias_monitoring: "monthly demographic parity analysis"
    performance_review: "weekly AUC/sensitivity/specificity tracking"

  scope_limitations:
    - "Ne pose AUCUN diagnostic final de manière autonome"
    - "Ne valide AUCUNE prescription sans approbation humaine"
    - "Ne déclenche AUCUN acte invasif"
    - "Domaine strictement obstétrical et néonatal"
    - "Décline poliment toute requête hors périmètre"
    out_of_scope_response: >
      Je suis spécialisé en obstétrique et néonatologie. Cette question
      dépasse mon domaine de compétence. Je vous recommande de consulter
      un spécialiste approprié.

# ============================================================================
# SECTION 2: INFRASTRUCTURE ML ET MODÈLES
# ============================================================================
ml_infrastructure:
  # --------------------------------------------------------------------------
  # 2.1 MODÈLES DE LANGAGE (LLM) — Routage Multi-Modèles
  # --------------------------------------------------------------------------
  llm_models:
    primary_reasoning:
      model_id: "claude-opus-4"
      provider: "anthropic"
      version: "claude-opus-4-20250514"
      role: "Raisonnement clinique complexe, synthèse multi-agents"
      use_cases:
        - "Agent de Raisonnement Symbolique"
        - "Agent de Narration Clinique"
        - "Résolution de conflits entre guidelines"
        - "Analyse éthique des recommandations"
      parameters:
        temperature: 0.1
        max_tokens: 4096
        top_p: 0.9
        presence_penalty: 0.0
      extended_thinking:
        enabled: true
        budget_tokens: 10000
      cost_tier: "premium"
      latency_target_ms: 5000
      fallback: "claude-sonnet-4"

    fast_analysis:
      model_id: "claude-sonnet-4"
      provider: "anthropic"
      version: "claude-sonnet-4-20250514"
      role: "Analyses rapides, monitoring temps réel, triage"
      use_cases:
        - "Agent CTG Monitor (analyse continue)"
        - "Agent Intake & Monitoring"
        - "Agent de Surveillance Thérapeutique"
        - "Réponses temps réel chat clinicien"
      parameters:
        temperature: 0.2
        max_tokens: 2048
        top_p: 0.9
        presence_penalty: 0.0
      cost_tier: "standard"
      latency_target_ms: 1500
      fallback: "gpt-4o"

    deep_research:
      model_id: "claude-4.5-sonnet"
      provider: "anthropic"
      version: "claude-4-5-sonnet-latest"
      role: "Recherche approfondie, analyse de littérature, méta-analyses"
      use_cases:
        - "Agent Polygraphe & Recherche"
        - "Analyse de publications PubMed/Cochrane"
        - "Vérification croisée des hallucinations"
        - "Synthèse de revues systématiques"
      parameters:
        temperature: 0.15
        max_tokens: 8192
        top_p: 0.85
        presence_penalty: 0.0
      cost_tier: "premium"
      latency_target_ms: 8000
      fallback: "claude-opus-4"

    multimodal_clinical:
      model_id: "gpt-4o"
      provider: "openai"
      version: "gpt-4o-2025-latest"
      role: "Analyse multimodale (imagerie échographique, tracés CTG visuels)"
      use_cases:
        - "Interprétation visuelle des tracés CTG"
        - "Analyse d'images échographiques"
        - "Lecture de partogrammes papier numérisés"
        - "OCR et extraction de données formulaires"
      parameters:
        temperature: 0.1
        max_tokens: 4096
        top_p: 0.9
        vision_detail: "high"
      cost_tier: "premium"
      latency_target_ms: 3000
      fallback: "claude-opus-4"

    advanced_reasoning:
      model_id: "o3"
      provider: "openai"
      version: "o3-2025-latest"
      role: "Raisonnement avancé pour cas complexes, diagnostics différentiels"
      use_cases:
        - "Cas obstétricaux complexes (multi-pathologies)"
        - "Diagnostics différentiels difficiles"
        - "Optimisation de protocoles thérapeutiques"
        - "Agent Quantum Birth Optimizer (planification)"
      parameters:
        reasoning_effort: "high"
        max_completion_tokens: 8192
      cost_tier: "ultra-premium"
      latency_target_ms: 15000
      usage_policy: "triggered_only_on_high_complexity"
      fallback: "claude-opus-4"

    european_sovereign:
      model_id: "mistral-large"
      provider: "mistral"
      version: "mistral-large-2025-latest"
      role: "Modèle souverain EU pour conformité RGPD, backup"
      use_cases:
        - "Traitement données sensibles nécessitant souveraineté EU"
        - "Backup en cas d'indisponibilité providers US"
        - "Agent d'Engagement Utilisateur (conversations)"
        - "Traduction et adaptation culturelle"
      parameters:
        temperature: 0.3
        max_tokens: 2048
        top_p: 0.9
      cost_tier: "standard"
      latency_target_ms: 2000
      deployment: "eu-west-1 (on-premise option available)"
      fallback: "claude-sonnet-4"

    enterprise_medical:
      model_id: "ibm-granite-medical"
      provider: "ibm"
      version: "granite-3.3-8b-instruct"
      role: "Modèle médical spécialisé, extraction structurée, FHIR"
      use_cases:
        - "Extraction structurée de données médicales"
        - "Mapping terminologique (SNOMED-CT, ICD-11, LOINC)"
        - "Génération de ressources FHIR conformes"
        - "Classification de documents médicaux"
        - "Agent Passerelle de Streaming (validation FHIR)"
      parameters:
        temperature: 0.0
        max_tokens: 1024
        top_p: 0.95
      cost_tier: "low"
      latency_target_ms: 500
      deployment: "on-premise (IBM Cloud Pak for Data)"
      fine_tuning:
        enabled: true
        dataset: "hospital_obstetric_records_anonymized"
        method: "LoRA"
        epochs: 5
      fallback: "mistral-large"

  # --------------------------------------------------------------------------
  # 2.2 ROUTAGE INTELLIGENT DES MODÈLES
  # --------------------------------------------------------------------------
  model_router:
    strategy: "complexity_and_latency_aware"
    rules:
      - condition: "urgency == 'critical' AND latency_required < 2000ms"
        route_to: "claude-sonnet-4"
        reason: "Réponse rapide pour situations critiques"

      - condition: "task == 'multimodal' AND has_images == true"
        route_to: "gpt-4o"
        reason: "Analyse visuelle requise"

      - condition: "complexity == 'high' AND task == 'reasoning'"
        route_to: "o3"
        reason: "Raisonnement avancé pour cas complexes"

      - condition: "task == 'research' AND depth == 'systematic_review'"
        route_to: "claude-4.5-sonnet"
        reason: "Recherche approfondie littérature"

      - condition: "task == 'fhir_extraction' OR task == 'terminology_mapping'"
        route_to: "ibm-granite-medical"
        reason: "Spécialisation médicale structurée"

      - condition: "data_sovereignty == 'eu_required'"
        route_to: "mistral-large"
        reason: "Conformité souveraineté données EU"

      - condition: "default"
        route_to: "claude-opus-4"
        reason: "Modèle principal par défaut"

    fallback_chain:
      - "claude-opus-4"
      - "claude-sonnet-4"
      - "mistral-large"
      - "ibm-granite-medical"

    circuit_breaker:
      failure_threshold: 3
      reset_timeout_seconds: 60
      half_open_requests: 1

  # --------------------------------------------------------------------------
  # 2.3 MODÈLES ML SPÉCIALISÉS SANTÉ (Non-LLM)
  # --------------------------------------------------------------------------
  specialized_ml_models:
    ctg_classifier:
      model_type: "Deep Learning - 1D-CNN + BiLSTM + Attention"
      framework: "PyTorch 2.4"
      description: >
        Classification CTG selon critères FIGO (Normal/Suspect/Pathologique).
        Entraîné sur CTU-UHB dataset (552 enregistrements) + données
        hospitalières anonymisées (15,000 tracés).
      architecture:
        input: "Signal FHR + Tocogramme (séries temporelles 4Hz)"
        layers:
          - "Conv1D(1, 64, kernel=7) + BatchNorm + ReLU"
          - "Conv1D(64, 128, kernel=5) + BatchNorm + ReLU"
          - "Conv1D(128, 256, kernel=3) + BatchNorm + ReLU"
          - "BiLSTM(256, hidden=128, layers=2, dropout=0.3)"
          - "MultiHeadAttention(heads=8, dim=256)"
          - "Linear(256, 3) + Softmax"
        output: "Probabilités [Normal, Suspect, Pathologique]"
      training:
        dataset_primary: "CTU-UHB Czech Technical University"
        dataset_secondary: "Hospital internal (anonymized, n=15000)"
        validation: "5-fold stratified cross-validation"
        augmentation: "TimeWarping, Jittering, WindowSlicing"
        optimizer: "AdamW(lr=1e-4, weight_decay=0.01)"
        scheduler: "CosineAnnealingWarmRestarts"
        epochs: 100
        early_stopping_patience: 15
      performance:
        sensitivity_pathological: ">= 0.95"
        specificity_normal: ">= 0.90"
        auc_roc: ">= 0.94"
        f1_weighted: ">= 0.89"
      explainability:
        method: "GradCAM temporal + SHAP DeepExplainer"
        output: "Heatmap temporelle sur segments CTG critiques"
      deployment:
        runtime: "TorchServe"
        hardware: "NVIDIA A100 (inference)"
        latency_target_ms: 200
        batch_size: 1
        model_registry: "MLflow"

    cesarean_risk_predictor:
      model_type: "Gradient Boosting - XGBoost"
      framework: "XGBoost 2.1 + scikit-learn 1.5"
      description: >
        Prédiction du risque de césarienne en urgence basée sur
        caractéristiques maternelles, obstétricales et CTG.
      features:
        maternal:
          - "age"
          - "bmi"
          - "parity"
          - "gestational_age_weeks"
          - "previous_cesarean (binary)"
          - "preeclampsia (binary)"
          - "gestational_diabetes (binary)"
          - "membrane_rupture_hours"
        obstetrical:
          - "bishop_score"
          - "cervical_dilation_cm"
          - "cervical_effacement_pct"
          - "fetal_station"
          - "contraction_frequency_per_10min"
          - "oxytocin_dose_mIU_min"
          - "labor_duration_hours"
          - "partogram_alert_line_crossed (binary)"
          - "partogram_action_line_crossed (binary)"
        fetal:
          - "fhr_baseline_bpm"
          - "fhr_variability_category"
          - "decelerations_type"
          - "decelerations_frequency"
          - "estimated_fetal_weight_g"
          - "amniotic_fluid_index"
      target: "emergency_cesarean (binary)"
      training:
        dataset: "Multicenter retrospective (n=50,000 deliveries)"
        class_balance: "SMOTE + class_weight balanced"
        hyperparameter_tuning: "Optuna (500 trials, 5-fold CV)"
        best_params:
          n_estimators: 800
          max_depth: 7
          learning_rate: 0.05
          subsample: 0.8
          colsample_bytree: 0.7
          min_child_weight: 5
          reg_alpha: 0.1
          reg_lambda: 1.0
      performance:
        auc_roc: ">= 0.88"
        sensitivity: ">= 0.85"
        specificity: ">= 0.80"
        ppv: ">= 0.70"
        npv: ">= 0.92"
        calibration: "Platt scaling applied"
      explainability:
        method: "SHAP TreeExplainer"
        output: "Force plots + summary plots per patient"
        top_features_reported: 10
      deployment:
        runtime: "FastAPI + ONNX Runtime"
        latency_target_ms: 50
        model_registry: "MLflow"

    apgar_predictor:
      model_type: "Random Forest + Logistic Regression Ensemble"
      framework: "scikit-learn 1.5"
      description: >
        Prédiction du risque d'Apgar bas (<7) à 5 minutes,
        basée sur données intrapartum et caractéristiques néonatales.
      features:
        - "gestational_age_weeks"
        - "birth_weight_estimated_g"
        - "fhr_last_30min_baseline"
        - "fhr_last_30min_variability"
        - "decelerations_last_30min"
        - "labor_duration_hours"
        - "mode_of_delivery"
        - "meconium_stained_liquor (binary)"
        - "maternal_fever (binary)"
        - "cord_ph_if_available"
      target: "apgar_5min_below_7 (binary)"
      performance:
        auc_roc: ">= 0.82"
        sensitivity: ">= 0.80"
        npv: ">= 0.95"
      explainability:
        method: "SHAP + LIME"
      deployment:
        runtime: "FastAPI + scikit-learn native"
        latency_target_ms: 30

    rciu_detector:
      model_type: "LightGBM + Neural Network Ensemble"
      framework: "LightGBM 4.4 + PyTorch 2.4"
      description: >
        Détection du Retard de Croissance Intra-Utérin à partir des
        données échographiques et Doppler.
      features:
        biometric:
          - "biparietal_diameter_mm"
          - "head_circumference_mm"
          - "abdominal_circumference_mm"
          - "femur_length_mm"
          - "estimated_fetal_weight_g"
          - "percentile_weight_for_ga"
        doppler:
          - "umbilical_artery_pi"
          - "umbilical_artery_ri"
          - "middle_cerebral_artery_pi"
          - "cerebroplacental_ratio"
          - "uterine_artery_pi"
          - "uterine_artery_notching (binary)"
        maternal:
          - "maternal_age"
          - "maternal_bmi"
          - "hypertension (binary)"
          - "smoking (binary)"
          - "previous_rciu (binary)"
      target: "rciu_confirmed (binary)"
      performance:
        auc_roc: ">= 0.90"
        sensitivity: ">= 0.88"
        specificity: ">= 0.85"
      explainability:
        method: "SHAP + feature importance ranking"

    preeclampsia_risk_model:
      model_type: "Bayesian Logistic Regression"
      framework: "PyMC 5.x"
      description: >
        Modèle bayésien de risque de pré-éclampsie intégrant biomarqueurs,
        Doppler utérin et facteurs de risque. Fournit des distributions
        postérieures de probabilité (incertitude quantifiée).
      features:
        - "maternal_age"
        - "bmi"
        - "chronic_hypertension (binary)"
        - "previous_preeclampsia (binary)"
        - "papp_a_mom"
        - "plgf_pg_ml"
        - "sflt1_pg_ml"
        - "sflt1_plgf_ratio"
        - "uterine_artery_mean_pi"
        - "mean_arterial_pressure_mmhg"
      target: "preeclampsia_before_37w (binary)"
      performance:
        auc_roc: ">= 0.87"
        detection_rate_10pct_fpr: ">= 0.75"
      uncertainty_quantification: true
      deployment:
        runtime: "FastAPI + PyMC posterior sampling"

    ultrasound_quality_checker:
      model_type: "CNN (ResNet-50 fine-tuned)"
      framework: "PyTorch 2.4 + torchvision"
      description: >
        Vérification automatique de la qualité des coupes échographiques
        (plan correct, mesurabilité) avant analyse biométrique.
      architecture:
        backbone: "ResNet-50 (ImageNet pretrained)"
        head: "FC(2048, 512) + ReLU + Dropout(0.5) + FC(512, 5)"
        output_classes:
          - "biparietal_plane_quality"
          - "abdominal_plane_quality"
          - "femur_plane_quality"
          - "overall_quality_score"
          - "measurability_flag"
      deployment:
        runtime: "TorchServe"
        hardware: "NVIDIA T4"
        latency_target_ms: 100

  # --------------------------------------------------------------------------
  # 2.4 INFRASTRUCTURE ML OPS
  # --------------------------------------------------------------------------
  mlops:
    experiment_tracking:
      platform: "MLflow 2.x"
      backend_store: "PostgreSQL"
      artifact_store: "MinIO (S3-compatible, on-premise)"

    model_registry:
      platform: "MLflow Model Registry"
      stages:
        - "Development"
        - "Staging"
        - "Production"
        - "Archived"
      approval_required_for_production: true
      approvers:
        - "ML Engineer Lead"
        - "Clinical Validation Team"
        - "Regulatory Affairs"

    monitoring:
      data_drift:
        tool: "Evidently AI"
        check_frequency: "daily"
        drift_threshold: 0.05
        alert_channel: "slack + email to ML team"
      model_performance:
        tool: "Custom Prometheus metrics + Grafana"
        metrics_tracked:
          - "auc_roc_rolling_7d"
          - "sensitivity_rolling_7d"
          - "specificity_rolling_7d"
          - "calibration_error_rolling_7d"
          - "prediction_latency_p99"
        degradation_threshold: "5% drop from baseline"
        alert_action: "notify_ml_team + flag_for_retraining"

    retraining:
      trigger: "data_drift OR performance_degradation OR quarterly_schedule"
      pipeline: "Kubeflow Pipelines"
      validation_before_deploy:
        - "Automated test suite (unit + integration)"
        - "Clinical validation on holdout set"
        - "Bias audit (demographic parity)"
        - "Regulatory documentation update"

    feature_store:
      platform: "Feast"
      offline_store: "PostgreSQL"
      online_store: "Redis"
      feature_groups:
        - name: "maternal_features"
          entities: ["patient_id"]
          features: 25
          refresh: "real-time"
        - name: "fetal_features"
          entities: ["patient_id", "pregnancy_id"]
          features: 30
          refresh: "real-time"
        - name: "labor_features"
          entities: ["patient_id", "labor_id"]
          features: 20
          refresh: "streaming (1s)"
        - name: "ctg_features"
          entities: ["patient_id", "ctg_session_id"]
          features: 15
          refresh: "streaming (250ms)"

# ============================================================================
# SECTION 3: ARCHITECTURE DES AGENTS
# ============================================================================
spec:
  mode: run_all
  execution_mode: sequential_with_parallel_branches
  continuous_trigger: true
  trigger_sources:
    - "FHIR Subscription (new Observation)"
    - "FHIR Subscription (new MedicationAdministration)"
    - "FHIR Subscription (new DiagnosticReport)"
    - "Manual clinician trigger"
    - "Scheduled interval (every 5 minutes during active labor)"

  # --------------------------------------------------------------------------
  # 3.1 AGENT PASSERELLE DE STREAMING
  # --------------------------------------------------------------------------
  agents:
    - id: StreamingGatewayAgent
      name: "Streaming Gateway Agent"
      description: >
        Premier agent de la chaîne. Reçoit les flux FHIR R4 en temps réel
        (Observations, MedicationAdministration, DiagnosticReport). Valide
        le schéma, anonymise les données (suppression identifiants directs),
        vérifie la cohérence physiologique des valeurs, et propage les
        événements validés aux agents en aval.
      inputs:
        fhir_subscriptions:
          - resource_type: "Observation"
            criteria: "category=vital-signs OR category=exam"
            channel: "websocket"
          - resource_type: "MedicationAdministration"
            criteria: "status=in-progress OR status=completed"
            channel: "websocket"
          - resource_type: "DiagnosticReport"
            criteria: "category=LAB OR category=imaging"
            channel: "websocket"
      outputs:
        validated_events:
          format: "FHIR Bundle (anonymized)"
          destination: "internal message bus (NATS)"
        rejection_log:
          format: "JSON audit entry"
          destination: "audit_log"
      processing_rules:
        schema_validation: "FHIR R4 profile validation (HL7 validator)"
        anonymization:
          fields_removed:
            - "patient.name"
            - "patient.identifier[type=MRN]"
            - "patient.address"
            - "patient.telecom"
          fields_pseudonymized:
            - "patient.id -> SHA-256(patient.id + daily_salt)"
        physiological_bounds_check:
          fhr_bpm: { min: 60, max: 220 }
          maternal_hr_bpm: { min: 40, max: 180 }
          maternal_systolic_mmhg: { min: 60, max: 250 }
          maternal_diastolic_mmhg: { min: 30, max: 150 }
          temperature_celsius: { min: 34.0, max: 42.0 }
          cervical_dilation_cm: { min: 0, max: 10 }
        on_validation_failure: "reject_event + log_audit + alert_if_critical"
      llm_model: "ibm-granite-medical"
      llm_settings:
        temperature: 0.0
        max_tokens: 256
        purpose: "FHIR resource classification and metadata extraction"
      rest_endpoint:
        path: "/api/v2/streaming-gateway"
        method: POST
        input_schema: "FHIR Bundle"
        output_schema: "FHIR Bundle (validated, anonymized)"
        rate_limit: "1000 events/second"
      monitoring:
        metrics:
          - "events_received_total"
          - "events_validated_total"
          - "events_rejected_total"
          - "validation_latency_ms"
        alerting:
          rejection_rate_threshold: 0.05
          latency_p99_threshold_ms: 100

    # --------------------------------------------------------------------------
    # 3.2 AGENT CTG MONITOR
    # --------------------------------------------------------------------------
    - id: CTGMonitorAgent
      name: "CTG Monitor Agent"
      description: >
        Surveillance continue du cardiotocogramme (CTG). Analyse la fréquence
        cardiaque fœtale (FHR), la variabilité (STV/LTV), les accélérations
        et décélérations, et les contractions utérines. Classifie selon FIGO
        2015 (Normal/Suspect/Pathologique). Utilise le modèle ML ctg_classifier
        combiné avec l'analyse LLM pour fournir une interprétation explicable.
        Détection proactive de motifs subtils de détresse fœtale.
      inputs:
        - source: "StreamingGatewayAgent"
          data: "Observations CTG (FHR signal 4Hz, tocogramme)"
        - source: "StreamingGatewayAgent"
          data: "Observations constantes maternelles (pour contexte)"
      outputs:
        narrative_summary:
          format: "markdown"
          max_words: 300
          content: >
            Résumé narratif de l'état du rythme cardiaque fœtal incluant :
            baseline FHR, variabilité (STV/LTV), accélérations, type et
            fréquence des décélérations, classification FIGO, tendance
            sur les 30 dernières minutes, et alertes éventuelles.
            Chaque affirmation référence sa source (capteur, guide FIGO).
        critical_metrics:
          - metric: "FHR Baseline"
            unit: "bpm"
            confidence_interval: "±5 bpm"
            provenance: "Capteur CTG (moyenne mobile 10 min)"
          - metric: "Variabilité STV"
            unit: "ms"
            confidence_interval: "±1 ms"
            provenance: "Analyse signal CTG (Dawes-Redman)"
          - metric: "Variabilité LTV"
            unit: "bpm"
            confidence_interval: "±2 bpm"
            provenance: "Analyse bande passante CTG"
          - metric: "Accélérations"
            unit: "count/20min"
            provenance: "Détection automatique (>15bpm, >15s)"
          - metric: "Décélérations"
            submetrics:
              - type: "Précoces"
                count: "<calculé>"
              - type: "Tardives"
                count: "<calculé>"
              - type: "Variables"
                count: "<calculé>"
              - type: "Prolongées"
                count: "<calculé>"
            provenance: "Classification automatique ML + FIGO criteria"
          - metric: "Classification FIGO"
            value: "<Normal/Suspect/Pathologique>"
            confidence: "<0.0-1.0>"
            provenance: "FIGO Intrapartum Fetal Monitoring Guidelines 2015"
          - metric: "Contractions utérines"
            unit: "count/10min"
            provenance: "Tocogramme externe/interne"
          - metric: "Score de détresse fœtale ML"
            unit: "probabilité 0-1"
            confidence_interval: "IC95%"
            provenance: "Modèle ctg_classifier v2.1"
        situation_report:
          template: >
            Classification: {figo_class}. {alert_level}.
            {action_recommendation}
          alert_levels:
            normal: "Aucune escalade requise. Continuer monitoring standard."
            suspect: "Surveillance rapprochée. Réévaluer dans 15 min."
            pathological: "ALERTE CRITIQUE. Intervention humaine OBLIGATOIRE.
                          Préparer éventuelle extraction en urgence."
        json_dashboard:
          format: "JSON structured"
          includes:
            - "all critical_metrics with timestamps"
            - "trend_data_last_60min"
            - "ml_model_version_and_performance"
      ml_models_used:
        - "ctg_classifier"
      llm_model: "claude-sonnet-4"
      llm_settings:
        temperature: 0.15
        max_tokens: 1024
        top_p: 0.9
        prompt_template: |
          Tu es un expert en cardiotocographie fœtale. Analyse les données
          CTG suivantes et fournis une interprétation selon les critères FIGO 2015.

          DONNÉES CTG:
          {ctg_data}

          RÉSULTATS ML:
          {ml_predictions}

          CONTEXTE MATERNEL:
          {maternal_context}

          Fournis:
          1. Résumé narratif (max 300 mots) avec classification FIGO
          2. Métriques critiques avec intervalles de confiance
          3. Situation report avec niveau d'alerte
          4. Si pathologique: justification détaillée et urgence

          Cite tes sources [FIGO 2015, Ayres-de-Campos et al.].
          En cas de doute, privilégie TOUJOURS la sécurité du fœtus.
      fhir_output: "Observation (CTG interpretation)"
      rest_endpoint:
        path: "/api/v2/ctg-monitor"
        method: POST
        input_schema: "FHIR Bundle (Observations CTG)"
        output_schema: "FHIR Observation (FHR analysis + FIGO classification)"
      human_in_the_loop:
        trigger_condition: "figo_classification == 'Pathologique' OR fetal_distress_score >= 0.8"
        action: "pause_and_notify_human"
        notification:
          channels: ["dashboard_alert", "pager", "sms"]
          message: "ALERTE CTG PATHOLOGIQUE - Validation obstétricien requise"
          timeout_seconds: 120
          escalation: "chef_de_garde"

    # --------------------------------------------------------------------------
    # 3.3 AGENT BISHOP & PARTOGRAMME
    # --------------------------------------------------------------------------
    - id: BishopPartogramAgent
      name: "Bishop Score & Partogram Agent"
      description: >
        Évalue le score de Bishop (5 critères : dilatation, effacement,
        consistance, position du col, hauteur de la présentation) pour
        estimer la favorabilité du col. Suit le partogramme en temps réel,
        trace la courbe de dilatation et la compare aux lignes d'alerte
        et d'action OMS. Détecte stagnation du travail et dystocie.
      inputs:
        - source: "StreamingGatewayAgent"
          data: "Observations (examens cervicaux, contractions)"
        - source: "CTGMonitorAgent"
          data: "Données CTG contextuelles (contractions)"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Résumé de l'état du col, score de Bishop détaillé, phase
            du travail (latente/active/expulsion), vitesse de dilatation,
            position par rapport aux lignes d'alerte/action du partogramme,
            et recommandations si stagnation détectée.
        critical_metrics:
          - metric: "Score de Bishop"
            components:
              dilation: { value: "<0-3>", max: 3 }
              effacement: { value: "<0-3>", max: 3 }
              consistency: { value: "<0-2>", max: 2 }
              position: { value: "<0-2>", max: 2 }
              station: { value: "<0-3>", max: 3 }
            total: "<0-13>"
            interpretation: "<Défavorable(≤5)/Favorable(6-8)/Très favorable(≥9)>"
            provenance: "Examen clinique sage-femme/obstétricien"
            reference: "[Bishop 1964, Cleveland Clinic 2024]"
          - metric: "Phase du travail"
            value: "<Latente/Active/Transition/Expulsion>"
            criteria: "Friedman curve modified + Zhang 2010"
            provenance: "Calcul basé sur dilatation et durée"
          - metric: "Vitesse de dilatation"
            value: "<calculée>"
            unit: "cm/heure"
            confidence_interval: "±0.3 cm/h"
            provenance: "Régression linéaire sur dernières mesures"
          - metric: "Position partogramme"
            value: "<Avant ligne alerte/Entre alerte et action/Après ligne action>"
            provenance: "OMS Partogramme Guidelines [1]"
          - metric: "Dynamique utérine"
            contractions_per_10min: "<calculé>"
            duration_seconds_mean: "<calculé>"
            montevideo_units: "<calculé si IUPC>"
            provenance: "Tocogramme"
        situation_report:
          stagnation_detection:
            threshold_primipara: "2 hours without progress in active phase"
            threshold_multipara: "1 hour without progress in active phase"
            alert: >
              Travail stagnant détecté. Durée stagnation: {hours}h.
              Position: {partogram_position}.
              Recommandation: {recommendation}.
              Ref: [OMS Partogramme, NICE Intrapartum Care 2023]
      ml_models_used: []
      llm_model: "claude-sonnet-4"
      llm_settings:
        temperature: 0.2
        max_tokens: 800
        prompt_template: |
          Tu es un obstétricien expert en suivi du travail. Analyse les données
          cervicales et le partogramme suivants.

          EXAMEN CERVICAL:
          {cervical_exam_data}

          HISTORIQUE PARTOGRAMME:
          {partogram_history}

          CONTRACTIONS:
          {contraction_data}

          Calcule:
          1. Score de Bishop détaillé (5 composantes) avec interprétation
          2. Phase du travail actuelle
          3. Vitesse de dilatation
          4. Position sur le partogramme OMS (avant/après lignes alerte/action)
          5. Recommandation si stagnation

          Réf: [Bishop 1964], [OMS Partogramme], [NICE 2023], [Zhang 2010]
      fhir_output: "Observation (Bishop Score + Partogram status)"
      rest_endpoint:
        path: "/api/v2/bishop-partogram"
        method: POST
      human_in_the_loop:
        trigger_condition: "partogram_position == 'after_action_line'"
        action: "pause_and_notify_human"

    # --------------------------------------------------------------------------
    # 3.4 AGENT RCIU (Retard de Croissance Intra-Utérin)
    # --------------------------------------------------------------------------
    - id: RCIURiskAgent
      name: "RCIU Risk Assessment Agent"
      description: >
        Évalue le risque de Retard de Croissance Intra-Utérin à partir des
        données biométriques fœtales (échographies), Doppler ombilical et
        cérébral, et facteurs de risque maternels. Utilise le modèle ML
        rciu_detector combiné avec l'interprétation LLM.
      inputs:
        - source: "StreamingGatewayAgent"
          data: "DiagnosticReports (échographies obstétricales, Doppler)"
        - source: "StreamingGatewayAgent"
          data: "Observations (biométries fœtales, poids estimé)"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Évaluation du risque RCIU incluant percentiles de croissance,
            indices Doppler (IP artère ombilicale, ACM, ratio cérébro-
            placentaire), facteurs de risque identifiés, et plan de
            surveillance recommandé.
        critical_metrics:
          - metric: "Risque RCIU"
            value: "<probabilité 0-1>"
            confidence_interval: "IC95%"
            provenance: "Modèle rciu_detector v1.3"
          - metric: "Percentile poids estimé"
            value: "<percentile>"
            reference_curve: "INTERGROWTH-21st ou Hadlock"
            provenance: "Échographie + courbe de référence"
          - metric: "IP Artère Ombilicale"
            value: "<calculé>"
            percentile: "<percentile>"
            provenance: "Doppler ombilical"
          - metric: "Ratio Cérébro-Placentaire"
            value: "<calculé>"
            normal_threshold: ">1.08"
            provenance: "ACM PI / Ombilical PI"
          - metric: "Poids fœtal estimé"
            value: "<grammes>"
            confidence_interval: "±15%"
            formula: "Hadlock 4-parameter"
        situation_report:
          risk_levels:
            low: "Pas de RCIU suspecté. Surveillance standard."
            moderate: "RCIU possible. Doppler de contrôle recommandé à J+7."
            high: "RCIU probable. Surveillance rapprochée + avis spécialiste."
            critical: "RCIU sévère avec Doppler pathologique.
                      HOSPITALISATION et DISCUSSION extraction recommandées."
      ml_models_used:
        - "rciu_detector"
        - "ultrasound_quality_checker"
      llm_model: "claude-opus-4"
      llm_settings:
        temperature: 0.15
        max_tokens: 1024
        extended_thinking: true
      fhir_output: "RiskAssessment (RCIU)"
      rest_endpoint:
        path: "/api/v2/rciu-risk"
        method: POST
      human_in_the_loop:
        trigger_condition: "risk_level == 'critical' OR umbilical_artery_absent_end_diastolic_flow"
        action: "pause_and_notify_human"

    # --------------------------------------------------------------------------
    # 3.5 AGENT PRÉ-ÉCLAMPSIE
    # --------------------------------------------------------------------------
    - id: PreeclampsiaRiskAgent
      name: "Preeclampsia Risk Agent"
      description: >
        Évalue le risque de pré-éclampsie à partir des biomarqueurs
        (sFlt-1/PlGF), Doppler utérin, tension artérielle, et facteurs
        de risque. Modèle bayésien fournissant une distribution de
        probabilité (incertitude quantifiée).
      inputs:
        - source: "StreamingGatewayAgent"
          data: "Observations (TA, protéinurie, biomarqueurs)"
        - source: "StreamingGatewayAgent"
          data: "DiagnosticReports (Doppler utérin, bilans biologiques)"
      outputs:
        narrative_summary:
          max_words: 300
        critical_metrics:
          - metric: "Risque pré-éclampsie < 37 SA"
            value: "<distribution postérieure>"
            credible_interval: "HDI 95%"
            provenance: "Modèle bayésien preeclampsia_risk_model v2.0"
          - metric: "Ratio sFlt-1/PlGF"
            value: "<calculé>"
            threshold_38: "Seuil 38 (rule-out)"
            threshold_85: "Seuil 85 (rule-in <34 SA)"
            provenance: "PROGNOSIS/PREDICTION studies"
          - metric: "TA systolique max 24h"
            value: "<mmHg>"
            threshold_severe: "≥160 mmHg"
          - metric: "Protéinurie"
            value: "<g/24h ou ratio P/C>"
            provenance: "Analyse urinaire"
        situation_report:
          severity_classification: "<Légère/Modérée/Sévère/HELLP>"
      ml_models_used:
        - "preeclampsia_risk_model"
      llm_model: "claude-opus-4"
      llm_settings:
        temperature: 0.1
        max_tokens: 1024
        extended_thinking: true
      fhir_output: "RiskAssessment (Preeclampsia)"
      rest_endpoint:
        path: "/api/v2/preeclampsia-risk"
        method: POST
      human_in_the_loop:
        trigger_condition: >
          severity == 'Sévère' OR severity == 'HELLP' OR
          systolic_bp >= 160 OR sflt1_plgf_ratio >= 85
        action: "pause_and_notify_human"

    # --------------------------------------------------------------------------
    # 3.6 AGENT APGAR & TRANSITION NÉONATALE
    # --------------------------------------------------------------------------
    - id: ApgarTransitionAgent
      name: "Apgar & Neonatal Transition Agent"
      description: >
        Évalue le score d'Apgar à 1 et 5 minutes, prédit le risque
        d'Apgar bas via le modèle ML, coordonne les soins néonataux
        immédiats, recommande le Kangaroo Mother Care selon les
        guidelines OMS 2022 pour les bébés prématurés ou petit poids.
      inputs:
        - source: "StreamingGatewayAgent"
          data: "Observations néonatales (Apgar, signes vitaux nouveau-né)"
        - source: "CTGMonitorAgent"
          data: "Dernières données CTG (contexte pré-natal)"
        - source: "MotherBabyRiskAgent"
          data: "Profil de risque combiné mère-enfant"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            État du nouveau-né, scores Apgar détaillés (5 composantes
            chacun), besoin de réanimation, recommandation soins Kangourou,
            plan de surveillance néonatale.
        critical_metrics:
          - metric: "Score Apgar 1 min"
            components:
              appearance: "<0-2>"
              pulse: "<0-2>"
              grimace: "<0-2>"
              activity: "<0-2>"
              respiration: "<0-2>"
            total: "<0-10>"
            provenance: "Évaluation clinique pédiatre/sage-femme [APGAR 1952, StatPearls]"
          - metric: "Score Apgar 5 min"
            components: "idem"
            total: "<0-10>"
          - metric: "Prédiction Apgar bas (ML)"
            value: "<probabilité 0-1>"
            confidence_interval: "IC95%"
            provenance: "Modèle apgar_predictor v1.2"
          - metric: "Poids naissance"
            value: "<grammes>"
            percentile: "<percentile pour AG>"
            provenance: "Pesée en salle de naissance"
          - metric: "pH cordon (si disponible)"
            value: "<pH>"
            normal_range: "7.20-7.40"
            provenance: "Gaz du sang cordon"
          - metric: "Recommandation Kangourou"
            eligible: "<oui/non>"
            criteria: "Prématuré < 37 SA OU poids < 2500g"
            duration_recommended: "≥ 8h/jour"
            reference: "[OMS KMC Guidelines 2022] [6]"
        situation_report:
          apgar_interpretation:
            normal: "Apgar ≥ 7 à 5 min. Adaptation néonatale satisfaisante."
            moderate_depression: >
              Apgar 4-6 à 5 min. Détresse modérée. Surveillance renforcée.
              Aspiration/stimulation. Pédiatre présent.
            severe_depression: >
              ALERTE: Apgar ≤ 3 à 5 min. Réanimation néonatale URGENTE.
              Appel pédiatre + équipe NICU. Ventilation assistée probable.
      ml_models_used:
        - "apgar_predictor"
      llm_model: "claude-sonnet-4"
      llm_settings:
        temperature: 0.1
        max_tokens: 800
        prompt_template: |
          Tu es un néonatologue expert. Évalue l'adaptation néonatale
          du nouveau-né suivant.

          DONNÉES NOUVEAU-NÉ:
          {neonatal_data}

          CONTEXTE PRÉNATAL:
          {prenatal_context}

          PRÉDICTION ML:
          {ml_apgar_prediction}

          Fournis:
          1. Score Apgar détaillé (5 composantes) à 1 et 5 min
          2. Interprétation et plan de soins immédiats
          3. Éligibilité et recommandation Kangaroo Mother Care [OMS 2022]
          4. Plan de surveillance néonatale
          5. Alertes si Apgar ≤ 6

          Réf: [StatPearls APGAR], [OMS KMC 2022], [NRP Guidelines]
      fhir_output: "Observation (Apgar scores + neonatal assessment)"
      rest_endpoint:
        path: "/api/v2/apgar-transition"
        method: POST
      human_in_the_loop:
        trigger_condition: "apgar_5min <= 6 OR predicted_low_apgar_probability >= 0.7"
        action: "pause_and_notify_human"
        notification:
          channels: ["dashboard_alert", "pager_neonatologist", "sms"]
          message: "ALERTE NÉONATALE - Apgar bas / Risque détresse néonatale"

    # --------------------------------------------------------------------------
    # 3.7 AGENT DE RECHERCHE & POLYGRAPHE
    # --------------------------------------------------------------------------
    - id: ResearchPolygraphAgent
      name: "Research & Polygraph Agent"
      description: >
        Interroge la base de connaissances médicales (PubMed, Cochrane,
        UpToDate, HAS, CNGOF, FIGO) pour contextualiser le cas clinique.
        Vérifie la cohérence et l'exactitude des sorties des autres agents
        (détection d'hallucinations). Évalue le niveau de preuve des
        recommandations citées.
      inputs:
        - source: "all_agents"
          data: "Sorties narratives et métriques de tous les agents"
        - source: "knowledge_hub"
          data: "Base de connaissances indexée"
      knowledge_sources:
        primary:
          - name: "PubMed"
            api: "NCBI E-utilities"
            query_strategy: "MeSH terms + clinical context"
            refresh_interval_minutes: 30
          - name: "Cochrane Library"
            api: "Cochrane API"
            focus: "Systematic reviews, meta-analyses"
            refresh_interval_minutes: 60
          - name: "UpToDate"
            access: "Institutional license API"
            focus: "Clinical decision support summaries"
          - name: "ClinicalTrials.gov"
            api: "ClinicalTrials.gov API v2"
            focus: "Ongoing trials in obstetrics/neonatology"
        national:
          - name: "HAS (Haute Autorité de Santé)"
            url: "https://www.has-sante.fr"
            focus: "Recommandations de bonne pratique"
          - name: "CNGOF"
            url: "http://www.cngof.fr"
            focus: "Recommandations obstétricales françaises"
        pharmaceutical:
          - name: "VIDAL"
            access: "API license"
            focus: "Médicaments en grossesse, tératogénicité"
          - name: "CRAT (Centre de Référence sur les Agents Tératogènes)"
            url: "https://www.lecrat.fr"
            focus: "Sécurité médicamenteuse en grossesse"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Synthèse des connaissances pertinentes pour le cas,
            avec citations formelles, niveaux de preuve, et signalement
            de données conflictuelles le cas échéant.
        critical_metrics:
          - metric: "Documents pertinents trouvés"
            value: "<count>"
            provenance: "Recherche multi-sources"
          - metric: "Score de crédibilité moyen"
            value: "<0-1>"
            provenance: "Évaluation automatique (impact factor, design, date)"
          - metric: "Indice de confiance global"
            value: "<0-1>"
            provenance: "Vérification croisée LLM vs connaissances"
          - metric: "Risque d'hallucination détecté"
            value: "<0-1>"
            threshold_alert: 0.1
            provenance: "Cross-check symbolique + factuel"
          - metric: "Conflits identifiés"
            value: "<count>"
            details: "Liste des contradictions entre sources"
        situation_report:
          confidence_assessment: >
            Confiance globale: {score}. {conflicts_if_any}.
            Toutes les affirmations vérifiées contre {n_sources} sources.
      llm_model: "claude-4.5-sonnet"
      llm_settings:
        temperature: 0.1
        max_tokens: 4096
        prompt_template: |
          Tu es un vérificateur médical expert (Medical Fact Checker).

          SORTIES DES AGENTS À VÉRIFIER:
          {agent_outputs}

          BASE DE CONNAISSANCES DISPONIBLE:
          {knowledge_base_summary}

          RÉSULTATS DE RECHERCHE:
          {search_results}

          Tâches:
          1. Vérifie chaque affirmation clinique contre les sources
          2. Identifie toute hallucination ou incohérence
          3. Évalue le niveau de preuve de chaque recommandation
          4. Signale les données conflictuelles entre sources
          5. Fournis un score de confiance global (0-1)

          Format tes citations: [Auteur et al., Année, Journal, Niveau de preuve]
          En cas de doute, signale-le explicitement.
      fhir_output: "Observation (confidence scores + verification results)"
      rest_endpoint:
        path: "/api/v2/research-polygraph"
        method: POST
      crawler_config:
        dmz_deployment: true
        respect_robots_txt: true
        allowed_formats: ["pdf", "html", "xml"]
        output_format: "markdown with metadata"
        rate_limiting: "1 request/second per source"
        audit_logging: true

    # --------------------------------------------------------------------------
    # 3.8 AGENT DE RISQUE COMBINÉ MÈRE-BÉBÉ
    # --------------------------------------------------------------------------
    - id: MotherBabyRiskAgent
      name: "Mother-Baby Risk Correlation Agent"
      description: >
        Analyse conjointe des risques maternels et fœtaux. Utilise les
        modèles ML (cesarean_risk_predictor, apgar_predictor) avec
        interprétation SHAP pour fournir des scores de risque personnalisés
        explicables. Simulations Monte Carlo pour scénarios prospectifs.
      inputs:
        - source: "CTGMonitorAgent"
          data: "Classification CTG + métriques FHR"
        - source: "BishopPartogramAgent"
          data: "Score Bishop + progression travail"
        - source: "RCIURiskAgent"
          data: "Risque RCIU + biométries"
        - source: "PreeclampsiaRiskAgent"
          data: "Risque pré-éclampsie"
        - source: "StreamingGatewayAgent"
          data: "Toutes observations maternelles et fœtales"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Synthèse des risques combinés mère-enfant avec probabilités
            personnalisées, facteurs contributifs principaux (SHAP),
            et recommandations graduées.
        critical_metrics:
          - metric: "Risque césarienne urgente"
            value: "<probabilité 0-1>"
            confidence_interval: "IC95%"
            top_contributing_factors:
              - factor: "<nom>"
                shap_value: "<float>"
                direction: "<increase/decrease>"
            provenance: "Modèle cesarean_risk_predictor v3.1"
          - metric: "Risque détresse fœtale"
            value: "<probabilité 0-1>"
            confidence_interval: "IC95%"
            provenance: "Ensemble CTG + clinical features"
          - metric: "Risque hémorragie post-partum"
            value: "<probabilité 0-1>"
            provenance: "Modèle logistique facteurs HPP"
          - metric: "Indice de risque combiné"
            value: "<score composite>"
            confidence_interval: "±0.1"
            provenance: "Weighted ensemble + Monte Carlo simulation"
          - metric: "Scénarios Monte Carlo"
            n_simulations: 10000
            best_scenario: "<description>"
            worst_scenario: "<description>"
            median_outcome: "<description>"
        situation_report:
          risk_classification: "<Faible/Modéré/Élevé/Critique>"
          action_required: "<description>"
      ml_models_used:
        - "cesarean_risk_predictor"
        - "apgar_predictor"
        - "rciu_detector"
        - "preeclampsia_risk_model"
      llm_model: "claude-opus-4"
      llm_settings:
        temperature: 0.15
        max_tokens: 1500
        extended_thinking: true
      fhir_output: "RiskAssessment (combined mother-baby)"
      rest_endpoint:
        path: "/api/v2/mother-baby-risk"
        method: POST
      human_in_the_loop:
        trigger_condition: >
          combined_risk == 'Élevé' OR combined_risk == 'Critique' OR
          cesarean_risk >= 0.7
        action: "pause_and_notify_human"

    # --------------------------------------------------------------------------
    # 3.9 AGENT DE SURVEILLANCE THÉRAPEUTIQUE
    # --------------------------------------------------------------------------
    - id: TherapeuticMonitoringAgent
      name: "Therapeutic Monitoring & Progression Agent"
      description: >
        Surveille les médicaments administrés (ocytocine, MgSO4,
        corticoïdes, antibioprophylaxie) et leurs effets. Vérifie
        l'adéquation posologique et détecte les effets indésirables.
        Suit les marqueurs de progression maternels et fœtaux.
      inputs:
        - source: "StreamingGatewayAgent"
          data: "MedicationAdministration (tous médicaments en cours)"
        - source: "StreamingGatewayAgent"
          data: "Observations (constantes vitales, labo)"
        - source: "CTGMonitorAgent"
          data: "Réponse fœtale aux traitements"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            État pharmacologique complet, doses en cours, réponse clinique,
            effets indésirables détectés, et recommandations d'ajustement.
        critical_metrics:
          - metric: "Ocytocine"
            dose_current: "<mUI/min>"
            dose_max_recommended: "40 mUI/min"
            response: "<contractions/10min>"
            hyperkinesia_detected: "<oui/non>"
            provenance: "Perfuseur + tocogramme"
          - metric: "Sulfate de Magnésium (si applicable)"
            dose_loading: "<g>"
            dose_maintenance: "<g/h>"
            magnesemia: "<mmol/L>"
            therapeutic_range: "2.0-3.5 mmol/L"
            toxicity_signs: "<ROT absents, FR < 12, diurèse < 30ml/h>"
          - metric: "Corticoïdes antenatals (si applicable)"
            type: "<bétaméthasone/dexaméthasone>"
            doses_given: "<1/2>"
            time_since_last_dose: "<heures>"
            optimal_window: "24h-7j post-administration"
          - metric: "Antibioprophylaxie Strep B (si applicable)"
            administered: "<oui/non>"
            timing: "<heures avant accouchement>"
            adequate: "<oui (≥4h) / non>"
        situation_report:
          alerts:
            - type: "dose_max_approaching"
              message: "Ocytocine proche dose maximale recommandée"
            - type: "toxicity_risk"
              message: "Magnésémie en limite haute"
            - type: "protocol_non_adherence"
              message: "Antibioprophylaxie Strep B non administrée alors qu'indiquée"
      llm_model: "claude-sonnet-4"
      llm_settings:
        temperature: 0.1
        max_tokens: 800
      fhir_output: "MedicationStatement + Observation (therapeutic monitoring)"
      rest_endpoint:
        path: "/api/v2/therapeutic-monitoring"
        method: POST

    # --------------------------------------------------------------------------
    # 3.10 AGENT DE RAISONNEMENT SYMBOLIQUE
    # --------------------------------------------------------------------------
    - id: SymbolicReasoningAgent
      name: "Symbolic Reasoning & Guidelines Agent"
      description: >
        Applique des règles formelles (IF/THEN) issues des guidelines
        HAS, FIGO, CNGOF, NICE, ACOG aux données du cas. Identifie
        les règles déclenchées, les écarts par rapport aux protocoles,
        et les conflits entre guidelines différentes.
      inputs:
        - source: "all_clinical_agents"
          data: "Données consolidées du cas"
        - source: "ResearchPolygraphAgent"
          data: "Base de connaissances vérifiée"
      rule_engine:
        platform: "Drools 8.x (ou Python rule engine custom)"
        rule_sets:
          - name: "FIGO_CTG_Classification"
            source: "FIGO 2015 Intrapartum Monitoring"
            rules_count: 45
          - name: "OMS_Partogramme"
            source: "WHO Partograph Guidelines"
            rules_count: 20
          - name: "HAS_Prise_en_charge_travail"
            source: "HAS Recommandations 2017-2024"
            rules_count: 35
          - name: "NICE_Intrapartum_Care"
            source: "NICE CG190 updated 2023"
            rules_count: 50
          - name: "ACOG_Practice_Bulletins"
            source: "ACOG Selected Bulletins"
            rules_count: 40
          - name: "Neonatal_Resuscitation"
            source: "NRP/ILCOR Guidelines 2022"
            rules_count: 25
          - name: "Preeclampsia_Management"
            source: "ISSHP 2021 + ACOG 2020"
            rules_count: 30
          - name: "Hospital_Local_Protocols"
            source: "CHU Protocols 2024"
            rules_count: 60
            customizable: true
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Règles déclenchées, références aux guidelines, degré de
            confiance, écarts détectés entre pratique et protocole,
            conflits entre guidelines si applicable.
        critical_metrics:
          - metric: "Règles déclenchées"
            value: "<count>"
            details: "Liste avec source et confiance"
          - metric: "Écarts au protocole"
            value: "<count>"
            severity: "<mineur/majeur/critique>"
            details: "Description et guideline de référence"
          - metric: "Conflits inter-guidelines"
            value: "<count>"
            details: "Guidelines en conflit et recommandation"
          - metric: "Conformité globale"
            value: "<pourcentage>"
            provenance: "Rule engine evaluation"
      llm_model: "claude-opus-4"
      llm_settings:
        temperature: 0.05
        max_tokens: 1200
        extended_thinking: true
      fhir_output: "DetectedIssue (guideline deviations)"
      rest_endpoint:
        path: "/api/v2/symbolic-reasoning"
        method: POST

    # --------------------------------------------------------------------------
    # 3.11 AGENT QUANTUM BIRTH OPTIMIZER
    # --------------------------------------------------------------------------
    - id: QuantumBirthOptimizerAgent
      name: "Quantum Birth Optimizer Agent"
      description: >
        Utilise des algorithmes d'optimisation avancés (Quantum-inspired
        Monte Carlo, algorithme de Grover simulé via Qiskit) pour
        explorer les scénarios d'accouchement optimaux : timing du
        déclenchement, mode d'accouchement, allocation des ressources.
        Composant principalement de recherche et prospectif.
      inputs:
        - source: "MotherBabyRiskAgent"
          data: "Profil de risque complet"
        - source: "BishopPartogramAgent"
          data: "État du travail"
        - source: "TherapeuticMonitoringAgent"
          data: "Réponse aux traitements"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Scénario optimal identifié avec probabilités, analyse
            de sensibilité, et justification algorithmique.
        critical_metrics:
          - metric: "Probabilité accouchement sans complication"
            value: "<calculée>"
            confidence_interval: "IC90%"
            provenance: "Simulation quantique (10000 runs)"
          - metric: "Timing optimal intervention"
            value: "<heures>"
            confidence_interval: "±1h"
            provenance: "Optimisation multi-objectif"
          - metric: "Mode d'accouchement recommandé"
            value: "<Spontané/Instrumental/Césarienne>"
            probability_success: "<calculée>"
          - metric: "Temps de calcul"
            value: "<secondes>"
            provenance: "Qiskit Aer simulator / IBM Quantum"
      quantum_config:
        framework: "Qiskit 1.x"
        backend: "qasm_simulator (production: ibm_brisbane)"
        algorithm: "QAOA + VQE for optimization"
        n_qubits: 12
        shots: 8192
      llm_model: "o3"
      llm_settings:
        reasoning_effort: "high"
        max_completion_tokens: 4096
      fhir_output: "Observation (birth optimization recommendation)"
      rest_endpoint:
        path: "/api/v2/quantum-optimizer"
        method: POST
      usage_policy: "triggered_only_on_request_or_complex_cases"

    # --------------------------------------------------------------------------
    # 3.12 AGENT DE COORDINATION & CONFORMITÉ
    # --------------------------------------------------------------------------
    - id: CoordinationComplianceAgent
      name: "Coordination & Compliance Agent"
      description: >
        Orchestre le workflow complet, vérifie la conformité réglementaire
        (RGPD, EU AI Act, MDR) à chaque étape, maintient l'audit trail,
        gère les mécanismes human-in-the-loop, et coordonne les
        interventions d'urgence.
      inputs:
        - source: "all_agents"
          data: "Statuts et résultats de tous les agents"
      outputs:
        narrative_summary:
          max_words: 300
          content: >
            Récapitulatif de l'exécution du pipeline, statut de
            conformité, interventions humaines déclenchées, et
            prochaines étapes.
        critical_metrics:
          - metric: "Agents invoqués"
            value: "<count>"
            details: "Liste avec statut (OK/WARNING/ERROR/HALTED)"
          - metric: "Conformité RGPD"
            value: "<Conforme/Non conforme>"
            details: "Vérifications effectuées"
          - metric: "Conformité EU AI Act"
            value: "<Conforme/Non conforme>"
            details: "Annexe IV checklist"
          - metric: "Interventions humaines requises"
            value: "<count>"
            details: "Agent source, raison, statut (en attente/validé/rejeté)"
          - metric: "Audit trail complet"
            format: "SHA-256 hash chain"
            entries: "<count>"
        situation_report:
          pipeline_status: "<Complete/In Progress/Halted awaiting human>"
          next_steps: "<description>"
      compliance_checks:
        eu_ai_act:
          annex_iv_documentation: true
          risk_management_system: "ISO 14971 compliant"
          data_governance: "verified"
          transparency_obligations: "met"
          human_oversight: "implemented"
          accuracy_robustness: "tested"
          cybersecurity: "verified"
        gdpr:
          lawful_basis: "legitimate interest (healthcare) + consent"
          data_minimization: "verified"
          purpose_limitation: "verified"
          storage_limitation: "10 years (medical records)"
          data_protection_impact_assessment: "completed"
        medical_device:
          ce_marking: "in_process"
          iso_13485: "quality_management_system"
          iso_14971: "risk_management"
          iec_62304: "software_lifecycle"
          clinical_evaluation: "ongoing"
      llm_model: "mistral-large"
      llm_settings:
        temperature: 0.0
        max_tokens: 1000
      fhir_output: "AuditEvent (compliance report)"
      rest_endpoint:
        path: "/api/v2/coordination-compliance"
        method: POST

    # --------------------------------------------------------------------------
    # 3.13 AGENT DE NARRATION CLINIQUE
    # --------------------------------------------------------------------------
    - id: ClinicalNarrativeAgent
      name: "Clinical Narrative Generator"
      description: >
        Génère le rapport clinique final consolidé à destination des
        cliniciens. Intègre les résultats de tous les agents dans un
        format structuré, avec citations complètes et recommandations
        finales actionnables.
      inputs:
        - source: "all_agents"
          data: "Toutes les sorties (narratives + métriques + situations)"
        - source: "ResearchPolygraphAgent"
          data: "Vérifications et sources"
        - source: "CoordinationComplianceAgent"
          data: "Statut de conformité et audit trail"
      outputs:
        clinical_report:
          format: "FHIR Composition (markdown body)"
          sections:
            - title: "Situation Clinique"
              content: "Synthèse état mère et fœtus"
            - title: "Monitoring Fœtal"
              content: "Résultats CTG + classification FIGO"
            - title: "Progression du Travail"
              content: "Bishop + Partogramme + dynamique"
            - title: "Évaluation des Risques"
              content: "Risques combinés avec SHAP"
            - title: "Thérapeutique en Cours"
              content: "Médicaments + réponse"
            - title: "Conformité Protocoles"
              content: "Règles appliquées + écarts"
            - title: "Recommandations"
              content: "Actions proposées avec justification"
            - title: "Plan de Soins Néonataux"
              content: "Préparation nouveau-né + Kangourou"
            - title: "Sources et Audit"
              content: "Citations complètes + audit trail"
          max_words: 800
          citation_format: "[Auteur, Année, Source, Niveau de preuve]"
        json_dashboard:
          format: "JSON"
          includes: "All metrics from all agents aggregated"
      llm_model: "claude-opus-4"
      llm_settings:
        temperature: 0.3
        max_tokens: 3000
        extended_thinking: true
        prompt_template: |
          Tu es un obstétricien senior rédigeant un rapport clinique
          pour l'équipe soignante. Synthétise TOUTES les analyses suivantes
          dans un rapport structuré, clair, et actionnable.

          DONNÉES COMPLÈTES:
          {all_agent_outputs}

          VÉRIFICATION POLYGRAPHE:
          {polygraph_results}

          CONFORMITÉ:
          {compliance_status}

          Rédige un rapport clinique structuré avec les sections suivantes:
          1. Situation Clinique (résumé concis)
          2. Monitoring Fœtal (CTG, classification, tendances)
          3. Progression du Travail (Bishop, partogramme)
          4. Évaluation des Risques (scores, facteurs, SHAP)
          5. Thérapeutique (médicaments, réponse)
          6. Conformité Protocoles (guidelines, écarts)
          7. Recommandations (actions concrètes avec justification)
          8. Plan Néonatal (Apgar attendu, Kangourou, surveillance)
          9. Sources (citations complètes)

          RÈGLES:
          - Chaque affirmation doit avoir une source
          - Les alertes critiques en MAJUSCULES
          - Les recommandations doivent être actionnables
          - Mentionner les limites et incertitudes
          - Ne JAMAIS affirmer un diagnostic définitif
      fhir_output: "Composition (full clinical report)"
      rest_endpoint:
        path: "/api/v2/clinical-narrative"
        method: POST

    # --------------------------------------------------------------------------
    # 3.14 AGENT D'ENGAGEMENT UTILISATEUR
    # --------------------------------------------------------------------------
    - id: UserEngagementAgent
      name: "User Engagement Agent"
      description: >
        Gère l'interaction conversationnelle avec les cliniciens et,
        séparément, avec les patients/familles. Adapte le niveau de
        langage, répond aux questions, clarifie les recommandations,
        et permet de relancer des analyses si nécessaire.
      inputs:
        - source: "ClinicalNarrativeAgent"
          data: "Rapport clinique complet"
        - source: "user_input"
          data: "Questions et commandes du clinicien"
      outputs:
        conversation_response:
          format: "markdown"
          max_words: 500
          adaptation_modes:
            clinician:
              language_level: "medical_professional"
              detail_level: "high"
              includes_references: true
            patient_family:
              language_level: "plain_language"
              detail_level: "moderate"
              includes_references: false
              empathetic_tone: true
        action_triggers:
          - trigger: "rerun_analysis"
            description: "Relance le pipeline complet avec nouvelles données"
          - trigger: "deep_dive"
            description: "Approfondit un aspect spécifique"
          - trigger: "explain_recommendation"
            description: "Explique en détail une recommandation"
      llm_model: "mistral-large"
      llm_settings:
        temperature: 0.5
        max_tokens: 1000
        presence_penalty: 0.2
        prompt_template: |
          Tu es un assistant obstétrical bienveillant et compétent.
          Tu interagis avec {user_role} au sujet du cas
Tu interagis avec {user_role} au sujet du cas clinique suivant.

          RAPPORT CLINIQUE COMPLET:
          {clinical_report}

          QUESTION/DEMANDE DE L'UTILISATEUR:
          {user_input}

          CONTEXTE DE LA CONVERSATION:
          {conversation_history}

          RÈGLES D'INTERACTION:
          - Si clinicien: langage médical précis, citations, détails techniques
          - Si patient/famille: langage simple, empathique, rassurant mais honnête
          - Ne JAMAIS donner de diagnostic définitif
          - Toujours rappeler que la décision finale revient à l'équipe médicale
          - Si la question dépasse ton domaine, oriente vers le spécialiste approprié
          - Propose des questions de suivi pertinentes

          Réponds de manière concise, utile et bienveillante.
      fhir_output: "Communication (user interaction log)"
      rest_endpoint:
        path: "/api/v2/user-engagement"
        method: POST
        websocket_endpoint: "/ws/v2/user-engagement"

  # ==========================================================================
  # SECTION 4: ORCHESTRATION ET PIPELINE
  # ==========================================================================
  orchestration:
    engine: "Apache Airflow 2.9 + NATS JetStream"
    
    pipeline_sequence:
      # Phase 1: Ingestion et Monitoring (parallèle)
      phase_1_ingestion:
        parallel: true
        agents:
          - StreamingGatewayAgent
        timeout_seconds: 5
        
      # Phase 2: Analyses Spécialisées (parallèle)
      phase_2_specialized_analysis:
        parallel: true
        depends_on: ["phase_1_ingestion"]
        agents:
          - CTGMonitorAgent
          - BishopPartogramAgent
          - RCIURiskAgent
          - PreeclampsiaRiskAgent
          - TherapeuticMonitoringAgent
        timeout_seconds: 30
        
      # Phase 3: Synthèse des Risques
      phase_3_risk_synthesis:
        parallel: false
        depends_on: ["phase_2_specialized_analysis"]
        agents:
          - MotherBabyRiskAgent
        timeout_seconds: 20
        human_checkpoint: true
        
      # Phase 4: Vérification et Raisonnement (parallèle)
      phase_4_verification:
        parallel: true
        depends_on: ["phase_3_risk_synthesis"]
        agents:
          - ResearchPolygraphAgent
          - SymbolicReasoningAgent
        timeout_seconds: 45
        
      # Phase 5: Optimisation (optionnelle)
      phase_5_optimization:
        parallel: false
        depends_on: ["phase_4_verification"]
        agents:
          - QuantumBirthOptimizerAgent
        timeout_seconds: 120
        optional: true
        trigger_condition: "complex_case OR manual_request"
        
      # Phase 6: Conformité et Coordination
      phase_6_compliance:
        parallel: false
        depends_on: ["phase_4_verification"]
        agents:
          - CoordinationComplianceAgent
        timeout_seconds: 15
        human_checkpoint: true
        
      # Phase 7: Rapport Final
      phase_7_narrative:
        parallel: false
        depends_on: ["phase_6_compliance"]
        agents:
          - ClinicalNarrativeAgent
        timeout_seconds: 30
        
      # Phase 8: Engagement Continu
      phase_8_engagement:
        parallel: false
        depends_on: ["phase_7_narrative"]
        agents:
          - UserEngagementAgent
        timeout_seconds: null  # Reste actif indéfiniment
        continuous: true

    fallback_strategy:
      on_agent_failure:
        action: "retry_with_fallback_model"
        max_retries: 2
        retry_delay_seconds: 5
        fallback_behavior: >
          Utilisation de valeurs par défaut sûres (conservative defaults),
          notification de l'agent défaillant dans le rapport, et poursuite
          du pipeline avec mention explicite de la limitation.
      on_timeout:
        action: "skip_with_warning"
        warning_in_report: true
      on_critical_failure:
        action: "halt_pipeline + emergency_notification"
        notification_channels: ["pager", "sms", "dashboard_critical_alert"]

    human_in_the_loop:
      global_triggers:
        - agent: "CTGMonitorAgent"
          condition: "figo_classification == 'Pathologique'"
          action: "pause_and_notify_human"
          priority: "CRITICAL"
          
        - agent: "ApgarTransitionAgent"
          condition: "apgar_5min <= 6"
          action: "pause_and_notify_human"
          priority: "CRITICAL"
          
        - agent: "MotherBabyRiskAgent"
          condition: "combined_risk_level in ['Élevé', 'Critique']"
          action: "pause_and_notify_human"
          priority: "HIGH"
          
        - agent: "PreeclampsiaRiskAgent"
          condition: "severity in ['Sévère', 'HELLP']"
          action: "pause_and_notify_human"
          priority: "CRITICAL"
          
        - agent: "RCIURiskAgent"
          condition: "risk_level == 'critical'"
          action: "pause_and_notify_human"
          priority: "HIGH"
          
        - agent: "TherapeuticMonitoringAgent"
          condition: "toxicity_detected == true"
          action: "pause_and_notify_human"
          priority: "CRITICAL"
          
        - agent: "SymbolicReasoningAgent"
          condition: "critical_protocol_deviation == true"
          action: "notify_human_continue"
          priority: "MEDIUM"

      notification_system:
        channels:
          dashboard_alert:
            type: "visual + audio"
            location: "salle de naissance monitoring screen"
            persistence: "until_acknowledged"
          pager:
            type: "numeric pager"
            recipients: ["obstetricien_garde", "sage_femme_responsable"]
          sms:
            type: "SMS encrypted"
            recipients: ["obstetricien_garde"]
            template: "ALERTE {priority}: {agent_name} - {condition_description}"
          email:
            type: "encrypted email"
            recipients: ["equipe_obstetrique"]
            for_priority: ["LOW", "MEDIUM"]

      acknowledgment:
        required: true
        timeout_seconds: 300
        escalation_on_timeout: true
        escalation_chain:
          - level: 1
            timeout_s: 120
            notify: "sage_femme_garde"
          - level: 2
            timeout_s: 180
            notify: "obstetricien_garde"
          - level: 3
            timeout_s: 300
            notify: "chef_service + directeur_garde"

    audit_log:
      enabled: true
      storage: "PostgreSQL + S3 cold storage"
      hash_algorithm: "SHA-256"
      hash_chain: true
      retention_years: 10
      fields_per_entry:
        - "timestamp_utc"
        - "agent_id"
        - "action_type"
        - "input_hash"
        - "output_hash"
        - "model_used"
        - "model_version"
        - "confidence_scores"
        - "human_decision (if applicable)"
        - "latency_ms"
        - "error_details (if any)"
        - "previous_entry_hash"

    security:
      threshold: 0.1
      on_security_breach: "halt_and_flag"
      anomaly_detection:
        method: "statistical outlier detection on agent outputs"
        alert_on: "unexpected output patterns, injection attempts"
      input_sanitization:
        enabled: true
        methods: ["FHIR schema validation", "prompt injection detection"]

  # ==========================================================================
  # SECTION 5: SORTIE FINALE AGRÉGÉE
  # ==========================================================================
  final_output:
    global_summary:
      format: "FHIR Composition + JSON dashboard"
      description: >
        Synthèse globale finale du cas obstétrical avec citations
        des guidelines et données sources. Rapport actionnable pour
        le clinicien avec recommandations graduées.
      
    aggregated_metrics:
      outcomes_by_agent:
        StreamingGatewayAgent: "status: OK, events_processed: <n>"
        CTGMonitorAgent: "<FIGO classification + alert level>"
        BishopPartogramAgent: "<Bishop score + labor phase + partogram status>"
        RCIURiskAgent: "<RCIU risk level + percentile>"
        PreeclampsiaRiskAgent: "<PE risk + severity>"
        ApgarTransitionAgent: "<Apgar scores + KMC recommendation>"
        ResearchPolygraphAgent: "<confidence score + hallucination risk>"
        MotherBabyRiskAgent: "<combined risk + top factors>"
        TherapeuticMonitoringAgent: "<medication status + alerts>"
        SymbolicReasoningAgent: "<compliance % + deviations>"
        QuantumBirthOptimizerAgent: "<optimal scenario (if triggered)>"
        CoordinationComplianceAgent: "<compliance status + audit entries>"
        ClinicalNarrativeAgent: "<report generated + sections>"
        UserEngagementAgent: "<interactions + satisfaction>"
        
      risk_flags:
        format: "priority-ordered list"
        example:
          - priority: "CRITICAL"
            flag: "CTG Pathologique - décélérations tardives répétitives"
            source: "CTGMonitorAgent"
          - priority: "HIGH"
            flag: "Travail stagnant > 2h (après ligne d'action)"
            source: "BishopPartogramAgent"
          - priority: "MEDIUM"
            flag: "Apgar prédit potentiellement bas"
            source: "ApgarTransitionAgent"
            
      recommendations:
        format: "actionable list with justification"
        example:
          - action: "Préparer bloc opératoire pour césarienne potentielle"
            justification: "Risque césarienne urgente 70% [cesarean_risk_predictor]"
            urgency: "30 minutes"
            reference: "[NICE CG190, 2023]"
          - action: "Appeler néonatologue en salle de naissance"
            justification: "Apgar prédit < 7, RCIU modéré"
            urgency: "avant accouchement"
            reference: "[NRP Guidelines 2022]"
          - action: "Initier Kangaroo Mother Care dès stabilisation"
            justification: "Poids estimé < 2500g, bénéfice prouvé [OMS 2022]"
            urgency: "post-natal immédiat"
            reference: "[WHO KMC Guidelines 2022] [6]"

    polygraph_surveillance:
      confidence_threshold: 0.90
      cross_verification_method: "Symbolique vs LLM vs données brutes"
      hallucination_detection: "Factual grounding check against FHIR data"
      result_format: >
        Confiance globale: {score}/1.0.
        Vérifications: {n_checks} effectuées.
        Incohérences: {n_inconsistencies} (détails: ...).
        Hallucinations détectées: {n_hallucinations}.

  # ==========================================================================
  # SECTION 6: CONFORMITÉ RÉGLEMENTAIRE
  # ==========================================================================
  compliance:
    eu_ai_act:
      classification: "High-Risk AI System (Annex III, §5 - Healthcare)"
      annex_iv_technical_documentation: true
      risk_management: "ISO 14971 compliant"
      data_governance: "Documented data quality measures"
      transparency: "User manual + explainability module"
      human_oversight: "Implemented (multi-level HITL)"
      accuracy_robustness_cybersecurity: "Tested and documented"
      post_market_monitoring: "Continuous performance tracking"
      
    medical_device_regulation:
      mdr_2017_745: true
      device_class: "IIb (active therapeutic device with AI)"
      notified_body: "TBD"
      clinical_evaluation: "Ongoing (CER per MEDDEV 2.7/1 Rev 4)"
      quality_management: "ISO 13485:2016"
      software_lifecycle: "IEC 62304:2006+A1:2015"
      risk_management: "ISO 14971:2019"
      usability: "IEC 62366-1:2015"
      
    data_protection:
      gdpr:
        lawful_basis: "Art. 6(1)(d) vital interests + Art. 9(2)(h) healthcare"
        dpia_completed: true
        dpo_contact: "dpo@hospital.eu"
        data_processing_agreements: "signed with all LLM providers"
        cross_border_transfers: "SCCs + supplementary measures for US providers"
      hipaa:
        applicable: "for international collaborations"
        baa_signed: "with applicable providers"
        
    standards:
      - "ISO 13485:2016 (Quality Management - Medical Devices)"
      - "ISO 14971:2019 (Risk Management)"
      - "IEC 62304:2006+A1:2015 (Medical Device Software Lifecycle)"
      - "IEC 62366-1:2015 (Usability Engineering)"
      - "ISO 27001:2022 (Information Security)"
      - "ISO 27799:2016 (Health Informatics Security)"
      - "HL7 FHIR R4 (Interoperability)"
      - "IHE profiles (Integration)"
      
    traceability:
      description: >
        Traçabilité complète de tous les artefacts: prompts utilisés,
        sorties générées, décisions prises, modèles invoqués (version),
        données d'entrée (hash), interventions humaines, et timestamps.
      implementation: "SHA-256 hash chain audit log"
      retention: "10 years minimum"
      tamper_evidence: "Blockchain-anchored quarterly snapshots"

# ============================================================================
# SECTION 7: INFRASTRUCTURE DE DÉPLOIEMENT
# ============================================================================
infrastructure:
  deployment:
    platform: "Kubernetes (K8s) on-premise hospital data center"
    container_runtime: "containerd"
    orchestration: "Helm charts + ArgoCD"
    
    namespaces:
      - name: "obs-ai-prod"
        purpose: "Production agents and services"
        resource_limits:
          cpu: "64 cores"
          memory: "256 Gi"
          gpu: "4x NVIDIA A100 80GB"
      - name: "obs-ai-staging"
        purpose: "Pre-production validation"
      - name: "obs-ai-ml"
        purpose: "ML training and experimentation"
        
    services:
      api_gateway:
        type: "Kong API Gateway"
        tls: "TLS 1.3 mutual authentication"
        rate_limiting: "per-client token bucket"
        authentication: "OAuth 2.0 + SMART on FHIR"
        
      message_bus:
        type: "NATS JetStream"
        purpose: "Inter-agent communication"
        retention: "24h (in-memory) + 30d (persistent)"
        encryption: "TLS 1.3"
        
      fhir_server:
        type: "HAPI FHIR R4"
        database: "PostgreSQL 16"
        subscriptions: "WebSocket + REST Hook"
        terminology: "SNOMED-CT, ICD-11, LOINC, ATC"
        
      feature_store:
        type: "Feast"
        online: "Redis Cluster"
        offline: "PostgreSQL"
        
      model_serving:
        type: "TorchServe + ONNX Runtime + FastAPI"
        scaling: "HPA based on request queue depth"
        canary_deployments: true
        
      monitoring:
        metrics: "Prometheus + Grafana"
        logging: "ELK Stack (Elasticsearch, Logstash, Kibana)"
        tracing: "Jaeger (OpenTelemetry)"
        alerting: "Alertmanager + PagerDuty integration"
        
      database:
        primary: "PostgreSQL 16 (HA with Patroni)"
        cache: "Redis Cluster 7.x"
        vector_store: "pgvector (for knowledge embeddings)"
        object_storage: "MinIO (S3-compatible)"
        
  networking:
    dmz:
      purpose: "Knowledge crawler, external API calls"
      firewall_rules: "egress only to approved domains"
      approved_domains:
        - "api.ncbi.nlm.nih.gov"
        - "api.cochranelibrary.com"
        - "clinicaltrials.gov"
        - "www.has-sante.fr"
        - "api.anthropic.com"
        - "api.openai.com"
        - "api.mistral.ai"
        - "api.ibm.com"
    internal:
      purpose: "Agent communication, FHIR server, databases"
      isolation: "NetworkPolicy (deny-all default, allow-list)"
      encryption: "mTLS between all services"
      
  backup_and_recovery:
    database_backup:
      frequency: "hourly incremental, daily full"
      retention: "30 days hot, 1 year cold, 10 years archive"
      encryption: "AES-256-GCM"
    disaster_recovery:
      rpo: "1 hour"
      rto: "4 hours"
      strategy: "active-passive with automated failover"

# ============================================================================
# SECTION 8: RÉFÉRENCES CLINIQUES ET SCIENTIFIQUES
# ============================================================================
references:
  clinical_guidelines:
    - id: 1
      title: "WHO Partograph in Management of Labour"
      source: "World Health Organization"
      url: "https://www.ijsdr.org/papers/IJSDR2210065.pdf"
      year: 2022
      evidence_level: "Strong recommendation"
      
    - id: 2
      title: "AI in Neonatal Intensive Care Units: A Systematic Review"
      source: "npj Digital Medicine"
      url: "https://www.nature.com/articles/s41746-023-00941-5"
      year: 2023
      evidence_level: "Systematic review"
      
    - id: 3
      title: "Bishop Score: Purpose and Impact on Labor"
      source: "Cleveland Clinic"
      url: "https://my.clevelandclinic.org/health/diagnostics/24252-bishop-score"
      year: 2024
      evidence_level: "Clinical reference"
      
    - id: 4
      title: "Bishop Score"
      source: "Wikipedia (clinical reference)"
      url: "https://en.wikipedia.org/wiki/Bishop_score"
      year: 2024
      evidence_level: "General reference"
      
    - id: 5
      title: "APGAR Score - StatPearls"
      source: "NCBI Bookshelf"
      url: "https://www.ncbi.nlm.nih.gov/books/NBK470569/"
      year: 2024
      evidence_level: "Clinical reference (peer-reviewed)"
      
    - id: 6
      title: "Kangaroo Mother Care Resources"
      source: "World Health Organization"
      url: "https://www.who.int/news/item/16-05-2023-new-resources-released-to-help-more-preterm-and-low-birthweight-babies-benefit-from-kangaroo-mother-care"
      year: 2023
      evidence_level: "WHO Guideline"

  additional_references:
    - "FIGO Intrapartum Fetal Monitoring Guidelines (Ayres-de-Campos et al., 2015)"
    - "NICE CG190: Intrapartum Care (Updated 2023)"
    - "ACOG Practice Bulletin: Fetal Heart Rate Monitoring (2022)"
    - "CNGOF: Recommandations pour la pratique clinique"
    - "HAS: Recommandations de bonne pratique en obstétrique"
    - "ISSHP: Classification and Diagnosis of Hypertensive Disorders of Pregnancy (2021)"
    - "ILCOR/NRP: Neonatal Resuscitation Guidelines (2022)"
    - "Zhang et al.: Contemporary Patterns of Spontaneous Labor (2010)"
    - "INTERGROWTH-21st: International Fetal and Newborn Growth Standards"

2. FRONTEND — Application React/Next.js pour Dashboard Obstétrical
2.1 Structure du Projet Frontend
Copyobstetric-ai-dashboard/
├── .cursor/
│   └── rules/
│       └── obstetric-ai.mdc          # Règles Cursor (voir section 3)
├── src/
│   ├── app/
│   │   ├── layout.tsx
│   │   ├── page.tsx                   # Dashboard principal
│   │   ├── globals.css
│   │   ├── patient/
│   │   │   └── [id]/
│   │   │       ├── page.tsx           # Vue patient individuel
│   │   │       ├── ctg/
│   │   │       │   └── page.tsx       # Monitoring CTG temps réel
│   │   │       ├── labor/
│   │   │       │   └── page.tsx       # Partogramme & Bishop
│   │   │       ├── risks/
│   │   │       │   └── page.tsx       # Évaluation risques
│   │   │       └── neonatal/
│   │   │           └── page.tsx       # Suivi néonatal
│   │   ├── alerts/
│   │   │   └── page.tsx               # Centre d'alertes
│   │   └── api/
│   │       ├── agents/
│   │       │   └── route.ts           # API proxy vers agents
│   │       ├── fhir/
│   │       │   └── route.ts           # FHIR proxy
│   │       └── ws/
│   │           └── route.ts           # WebSocket handler
│   ├── components/
│   │   ├── layout/
│   │   │   ├── Sidebar.tsx
│   │   │   ├── Header.tsx
│   │   │   ├── AlertBanner.tsx
│   │   │   └── PatientSelector.tsx
│   │   ├── dashboard/
│   │   │   ├── PatientOverviewCard.tsx
│   │   │   ├── ActiveLaborBoard.tsx
│   │   │   └── RiskHeatmap.tsx
│   │   ├── ctg/
│   │   │   ├── CTGChart.tsx           # Tracé CTG temps réel
│   │   │   ├── FIGOClassBadge.tsx     # Badge classification FIGO
│   │   │   ├── CTGMetricsPanel.tsx
│   │   │   └── DecelerationMarkers.tsx
│   │   ├── labor/
│   │   │   ├── PartogramChart.tsx     # Graphique partogramme
│   │   │   ├── BishopScoreCard.tsx    # Score de Bishop
│   │   │   ├── ContractionMonitor.tsx
│   │   │   └── LaborTimeline.tsx
│   │   ├── risk/
│   │   │   ├── RiskGauge.tsx          # Jauges de risque
│   │   │   ├── SHAPWaterfall.tsx      # Visualisation SHAP
│   │   │   ├── RiskFactorList.tsx
│   │   │   └── MonteCarloScenarios.tsx
│   │   ├── neonatal/
│   │   │   ├── ApgarScoreCard.tsx     # Carte score Apgar
│   │   │   ├── KangarooCareTimer.tsx  # Timer soins Kangourou
│   │   │   └── NeonatalVitals.tsx
│   │   ├── narrative/
│   │   │   ├── ClinicalReportPanel.tsx # Rapport narratif
│   │   │   ├── SourceCitationList.tsx  # Citations sources
│   │   │   └── ReportExporter.tsx
│   │   ├── chat/
│   │   │   ├── AgentChat.tsx          # Chat avec l'IA
│   │   │   ├── MessageBubble.tsx
│   │   │   └── QuickActions.tsx
│   │   ├── compliance/
│   │   │   ├── AuditTrailViewer.tsx
│   │   │   ├── GuidelineComplianceBadge.tsx
│   │   │   └── HumanValidationModal.tsx
│   │   └── ui/                        # Composants UI réutilisables
│   │       ├── AlertLevel.tsx
│   │       ├── ConfidenceBadge.tsx
│   │       ├── MetricCard.tsx
│   │       ├── RealTimeIndicator.tsx
│   │       └── LoadingSpinner.tsx
│   ├── hooks/
│   │   ├── useWebSocket.ts           # Hook WebSocket temps réel
│   │   ├── useFHIR.ts                # Hook FHIR client
│   │   ├── useAgentPipeline.ts       # Hook orchestration agents
│   │   ├── useCTGStream.ts           # Hook streaming CTG
│   │   ├── useAlerts.ts              # Hook gestion alertes
│   │   └── useAuditLog.ts            # Hook audit trail
│   ├── lib/
│   │   ├── fhir-client.ts            # Client FHIR R4
│   │   ├── agent-client.ts           # Client API agents
│   │   ├── websocket-manager.ts      # Gestionnaire WebSocket
│   │   ├── ctg-signal-processor.ts   # Traitement signal CTG côté client
│   │   ├── partogram-calculator.ts   # Calculs partogramme
│   │   ├── bishop-calculator.ts      # Calcul score Bishop
│   │   └── alert-manager.ts          # Gestion alertes multi-canal
│   ├── types/
│   │   ├── fhir.ts                   # Types FHIR R4
│   │   ├── agents.ts                 # Types agents (inputs/outputs)
│   │   ├── ctg.ts                    # Types CTG
│   │   ├── labor.ts                  # Types travail/partogramme
│   │   ├── risk.ts                   # Types évaluation risques
│   │   └── neonatal.ts               # Types néonataux
│   └── stores/
│       ├── patient-store.ts          # État patient (Zustand)
│       ├── alert-store.ts            # État alertes
│       ├── ctg-store.ts              # État CTG buffer
│       └── pipeline-store.ts         # État pipeline agents
├── public/
│   ├── sounds/
│   │   ├── alert-critical.mp3
│   │   ├── alert-high.mp3
│   │   └── alert-medium.mp3
│   └── icons/
├── package.json
├── next.config.ts
├── tailwind.config.ts
├── tsconfig.json
└── docker/
    ├── Dockerfile
    └── nginx.conf
2.2 Composants Frontend Clés
typescriptCopy// ============================================================================
// src/app/patient/[id]/page.tsx — Vue Patient Principale (Split Layout)
// ============================================================================

'use client';

import React, { useEffect, useState } from 'react';
import { useParams } from 'next/navigation';
import { useWebSocket } from '@/hooks/useWebSocket';
import { useAgentPipeline } from '@/hooks/useAgentPipeline';
import { useFHIR } from '@/hooks/useFHIR';
import { useAlerts } from '@/hooks/useAlerts';

import { ClinicalReportPanel } from '@/components/narrative/ClinicalReportPanel';
import { CTGChart } from '@/components/ctg/CTGChart';
import { FIGOClassBadge } from '@/components/ctg/FIGOClassBadge';
import { CTGMetricsPanel } from '@/components/ctg/CTGMetricsPanel';
import { PartogramChart } from '@/components/labor/PartogramChart';
import { BishopScoreCard } from '@/components/labor/BishopScoreCard';
import { RiskGauge } from '@/components/risk/RiskGauge';
import { SHAPWaterfall } from '@/components/risk/SHAPWaterfall';
import { ApgarScoreCard } from '@/components/neonatal/ApgarScoreCard';
import { KangarooCareTimer } from '@/components/neonatal/KangarooCareTimer';
import { AgentChat } from '@/components/chat/AgentChat';
import { AlertBanner } from '@/components/layout/AlertBanner';
import { HumanValidationModal } from '@/components/compliance/HumanValidationModal';
import { AuditTrailViewer } from '@/components/compliance/AuditTrailViewer';

import type { PatientContext, AgentPipelineOutput, Alert } from '@/types/agents';

export default function PatientDashboard() {
  const { id: patientId } = useParams<{ id: string }>();
  
  // --- Hooks ---
  const {
    data: fhirData,
    loading: fhirLoading,
    subscribe
  } = useFHIR(patientId);
  
  const {
    messages: wsMessages,
    connected: wsConnected,
    send: wsSend
  } = useWebSocket(`/ws/v2/patient/${patientId}`);
  
  const {
    pipelineOutput,
    pipelineStatus,
    triggerPipeline,
    acknowledgeHumanReview
  } = useAgentPipeline(patientId);
  
  const {
    alerts,
    criticalAlerts,
    acknowledgeAlert
  } = useAlerts(patientId);

  // --- State ---
  const [activeTab, setActiveTab] = useState<
    'overview' | 'ctg' | 'labor' | 'risks' | 'neonatal' | 'audit'
  >('overview');
  const [showValidationModal, setShowValidationModal] = useState(false);
  const [pendingValidation, setPendingValidation] = useState<any>(null);

  // --- FHIR Subscriptions ---
  useEffect(() => {
    if (patientId) {
      subscribe('Observation', `subject=Patient/${patientId}&category=vital-signs`);
      subscribe('Observation', `subject=Patient/${patientId}&code=http://loinc.org|76477-9`); // FHR
      subscribe('MedicationAdministration', `subject=Patient/${patientId}`);
      subscribe('DiagnosticReport', `subject=Patient/${patientId}`);
    }
  }, [patientId, subscribe]);

  // --- Handle Human-in-the-Loop triggers ---
  useEffect(() => {
    if (pipelineOutput?.humanReviewRequired) {
      setPendingValidation(pipelineOutput.humanReviewDetails);
      setShowValidationModal(true);
      // Play critical alert sound
      const audio = new Audio('/sounds/alert-critical.mp3');
      audio.play().catch(() => {});
    }
  }, [pipelineOutput?.humanReviewRequired]);

  return (
    <div className="min-h-screen bg-slate-950 text-white">
      {/* ---- ALERT BANNER (top, persistent for critical) ---- */}
      {criticalAlerts.length > 0 && (
        <AlertBanner
          alerts={criticalAlerts}
          onAcknowledge={acknowledgeAlert}
        />
      )}

      {/* ---- HUMAN VALIDATION MODAL ---- */}
      {showValidationModal && pendingValidation && (
        <HumanValidationModal
          validation={pendingValidation}
          onApprove={(decision) => {
            acknowledgeHumanReview(pendingValidation.id, decision);
            setShowValidationModal(false);
          }}
          onReject={(reason) => {
            acknowledgeHumanReview(pendingValidation.id, {
              approved: false,
              reason
            });
            setShowValidationModal(false);
          }}
        />
      )}

      {/* ---- HEADER ---- */}
      <header className="border-b border-slate-800 px-6 py-3 flex items-center justify-between">
        <div className="flex items-center gap-4">
          <h1 className="text-xl font-bold text-cyan-400">
            🏥 Intelligence Obstétricale
          </h1>
          <div className="flex items-center gap-2">
            <span className={`h-2 w-2 rounded-full ${
              wsConnected ? 'bg-green-500 animate-pulse' : 'bg-red-500'
            }`} />
            <span className="text-xs text-slate-400">
              {wsConnected ? 'Temps réel actif' : 'Déconnecté'}
            </span>
          </div>
        </div>
        <div className="flex items-center gap-4">
          <span className="text-sm text-slate-300">
            Patient: <strong>{fhirData?.patient?.identifier || patientId}</strong>
          </span>
          <span className="text-sm text-slate-400">
            {fhirData?.patient?.gestationalAge || '??'} SA
          </span>
          <span className={`px-2 py-1 rounded text-xs font-bold ${
            pipelineStatus === 'running' ? 'bg-blue-600' :
            pipelineStatus === 'awaiting_human' ? 'bg-amber-600 animate-pulse' :
            pipelineStatus === 'complete' ? 'bg-green-700' :
            'bg-slate-700'
          }`}>
            Pipeline: {pipelineStatus}
          </span>
        </div>
      </header>

      {/* ---- TAB NAVIGATION ---- */}
      <nav className="border-b border-slate-800 px-6">
        <div className="flex gap-1">
          {[
            { key: 'overview', label: '📊 Vue d\'ensemble', icon: '📊' },
            { key: 'ctg', label: '💓 CTG Monitor', icon: '💓' },
            { key: 'labor', label: '👶 Travail', icon: '👶' },
            { key: 'risks', label: '⚠️ Risques', icon: '⚠️' },
            { key: 'neonatal', label: '🍼 Néonatal', icon: '🍼' },
            { key: 'audit', label: '📋 Audit', icon: '📋' },
          ].map(tab => (
            <button
              key={tab.key}
              onClick={() => setActiveTab(tab.key as any)}
              className={`px-4 py-3 text-sm font-medium border-b-2 transition-colors ${
                activeTab === tab.key
                  ? 'border-cyan-400 text-cyan-400'
                  : 'border-transparent text-slate-400 hover:text-white'
              }`}
            >
              {tab.label}
            </button>
          ))}
        </div>
      </nav>

      {/* ---- MAIN CONTENT: SPLIT LAYOUT ---- */}
      <main className="flex h-[calc(100vh-120px)]">
        {/* LEFT PANEL: Narrative Summary (~60%) */}
        <div className="w-3/5 border-r border-slate-800 overflow-y-auto p-6">
          {activeTab === 'overview' && (
            <div className="space-y-6">
              {/* Clinical Report Narrative */}
              <ClinicalReportPanel
                report={pipelineOutput?.clinicalNarrative}
                loading={pipelineStatus === 'running'}
              />
              
              {/* Quick Risk Summary */}
              <div className="grid grid-cols-3 gap-4">
                <RiskGauge
                  title="Risque Césarienne"
                  value={pipelineOutput?.risks?.cesareanRisk}
                  threshold={0.7}
                />
                <RiskGauge
                  title="Détresse Fœtale"
                  value={pipelineOutput?.risks?.fetalDistressRisk}
                  threshold={0.6}
                />
                <RiskGauge
                  title="HPP"
                  value={pipelineOutput?.risks?.pphRisk}
                  threshold={0.5}
                />
              </div>
              
              {/* Partogram Mini */}
              <PartogramChart
                data={pipelineOutput?.labor?.partogramData}
                compact={true}
              />
            </div>
          )}
          
          {activeTab === 'ctg' && (
            <div className="space-y-4">
              <div className="flex items-center justify-between">
                <h2 className="text-lg font-semibold">
                  Monitoring Cardiotocographique
                </h2>
                <FIGOClassBadge
                  classification={pipelineOutput?.ctg?.figoClass}
                  confidence={pipelineOutput?.ctg?.figoConfidence}
                />
              </div>
              <CTGChart
                fhrData={fhirData?.ctgStream?.fhr}
                tocoData={fhirData?.ctgStream?.toco}
                markers={pipelineOutput?.ctg?.decelerationMarkers}
                realtime={true}
              />
              <CTGMetricsPanel metrics={pipelineOutput?.ctg?.metrics} />
            </div>
          )}
          
          {activeTab === 'labor' && (
            <div className="space-y-4">
              <BishopScoreCard
                score={pipelineOutput?.labor?.bishopScore}
              />
              <PartogramChart
                data={pipelineOutput?.labor?.partogramData}
                alertLine={true}
                actionLine={true}
                compact={false}
              />
            </div>
          )}
          
          {activeTab === 'risks' && (
            <div className="space-y-4">
              <SHAPWaterfall
                features={pipelineOutput?.risks?.shapValues}
                baseValue={pipelineOutput?.risks?.baseRisk}
                prediction={pipelineOutput?.risks?.cesareanRisk}
                title="Facteurs de risque césarienne (SHAP)"
              />
              <div className="bg-slate-900 rounded-lg p-4">
                <h3 className="text-sm font-semibold text-slate-300 mb-3">
                  Scénarios Monte Carlo (10,000 simulations)
                </h3>
                {/* Monte Carlo distribution chart */}
              </div>
            </div>
          )}
          
          {activeTab === 'neonatal' && (
            <div className="space-y-4">
              <ApgarScoreCard
                apgar1min={pipelineOutput?.neonatal?.apgar1min}
                apgar5min={pipelineOutput?.neonatal?.apgar5min}
                predicted={pipelineOutput?.neonatal?.predictedApgar}
              />
              <KangarooCareTimer
                eligible={pipelineOutput?.neonatal?.kmcEligible}
                startTime={pipelineOutput?.neonatal?.kmcStartTime}
                targetHoursPerDay={8}
              />
            </div>
          )}
          
          {activeTab === 'audit' && (
            <AuditTrailViewer
              patientId={patientId}
              entries={pipelineOutput?.audit?.entries}
            />
          )}
        </div>

        {/* RIGHT PANEL: JSON Dashboard + Chat (~40%) */}
        <div className="w-2/5 flex flex-col">
          {/* JSON Dashboard (top half) */}
          <div className="h-1/2 border-b border-slate-800 overflow-y-auto p-4">
            <div className="flex items-center justify-between mb-3">
              <h3 className="text-sm font-semibold text-slate-300">
                📊 Métriques Temps Réel (JSON)
              </h3>
              <button
                className="text-xs text-cyan-400 hover:text-cyan-300"
                onClick={() => {/* copy JSON to clipboard */}}
              >
                Copier JSON
              </button>
            </div>
            <pre className="text-xs text-green-400 bg-slate-900 rounded-lg p-3 
                          overflow-auto font-mono leading-relaxed">
              {JSON.stringify(pipelineOutput?.aggregatedMetrics, null, 2)}
            </pre>
          </div>

          {/* Agent Chat (bottom half) */}
          <div className="h-1/2 flex flex-col">
            <AgentChat
              patientId={patientId}
              pipelineContext={pipelineOutput}
              onSendMessage={(msg) => wsSend({
                type: 'chat',
                content: msg
              })}
              messages={wsMessages.filter(m => m.type === 'chat')}
            />
          </div>
        </div>
      </main>
    </div>
  );
}
typescriptCopy// ============================================================================
// src/components/ctg/CTGChart.tsx — Tracé CTG Temps Réel
// ============================================================================

'use client';

import React, { useRef, useEffect, useMemo, useCallback } from 'react';
import {
  LineChart, Line, XAxis, YAxis, CartesianGrid,
  Tooltip, ReferenceLine, ReferenceArea, ResponsiveContainer
} from 'recharts';

interface CTGChartProps {
  fhrData: Array<{ time: number; value: number }>;
  tocoData: Array<{ time: number; value: number }>;
  markers?: Array<{
    startTime: number;
    endTime: number;
    type: 'early' | 'late' | 'variable' | 'prolonged';
    severity: 'mild' | 'moderate' | 'severe';
  }>;
  realtime: boolean;
  windowMinutes?: number;
}

const DECEL_COLORS = {
  early: 'rgba(59, 130, 246, 0.2)',    // blue
  late: 'rgba(239, 68, 68, 0.3)',      // red - dangerous
  variable: 'rgba(245, 158, 11, 0.2)', // amber
  prolonged: 'rgba(220, 38, 38, 0.4)', // dark red
};

export function CTGChart({
  fhrData,
  tocoData,
  markers = [],
  realtime,
  windowMinutes = 30
}: CTGChartProps) {
  const chartRef = useRef<HTMLDivElement>(null);

  const visibleFHR = useMemo(() => {
    if (!realtime || !fhrData.length) return fhrData;
    const cutoff = Date.now() - windowMinutes * 60 * 1000;
    return fhrData.filter(d => d.time >= cutoff);
  }, [fhrData, realtime, windowMinutes]);

  const visibleToco = useMemo(() => {
    if (!realtime || !tocoData.length) return tocoData;
    const cutoff = Date.now() - windowMinutes * 60 * 1000;
    return tocoData.filter(d => d.time >= cutoff);
  }, [tocoData, realtime, windowMinutes]);

  return (
    <div ref={chartRef} className="space-y-2">
      {/* FHR Chart */}
      <div className="bg-slate-900 rounded-lg p-3">
        <div className="flex items-center justify-between mb-2">
          <h4 className="text-xs font-semibold text-slate-400 uppercase">
            Fréquence Cardiaque Fœtale (bpm)
          </h4>
          {realtime && (
            <span className="flex items-center gap-1 text-xs text-green-400">
              <span className="h-1.5 w-1.5 rounded-full bg-green-400 animate-pulse" />
              Live
            </span>
          )}
        </div>
        <ResponsiveContainer width="100%" height={200}>
          <LineChart data={visibleFHR}>
            <CartesianGrid strokeDasharray="3 3" stroke="#334155" />
            <XAxis
              dataKey="time"
              tickFormatter={(t) => new Date(t).toLocaleTimeString('fr-FR', {
                hour: '2-digit',
                minute: '2-digit'
              })}
              stroke="#64748b"
              fontSize={10}
            />
            <YAxis
              domain={[60, 200]}
              stroke="#64748b"
              fontSize={10}
              ticks={[60, 80, 100, 110, 120, 140, 160, 180, 200]}
            />
            
            {/* Normal range band */}
            <ReferenceArea y1={110} y2={160} fill="rgba(34, 197, 94, 0.05)" />
            
            {/* Bradycardia threshold */}
            <ReferenceLine y={110} stroke="#f59e0b" strokeDasharray="5 5" />
            
            {/* Tachycardia threshold */}
            <ReferenceLine y={160} stroke="#f59e0b" strokeDasharray="5 5" />
            
            {/* Severe bradycardia */}
            <ReferenceLine y={100} stroke="#ef4444" strokeDasharray="3 3" />
            
            {/* Deceleration markers */}
            {markers.map((marker, idx) => (
              <ReferenceArea
                key={idx}
                x1={marker.startTime}
                x2={marker.endTime}
                fill={DECEL_COLORS[marker.type]}
                label={{
                  value: marker.type.charAt(0).toUpperCase(),
                  fontSize: 9,
                  fill: '#fff'
                }}
              />
            ))}
            
            <Line
              type="monotone"
              dataKey="value"
              stroke="#06b6d4"
              strokeWidth={1.5}
              dot={false}
              isAnimationActive={false}
            />
            
            <Tooltip
              contentStyle={{
                backgroundColor: '#1e293b',
                border: '1px solid #475569',
                borderRadius: '8px',
                fontSize: '12px'
              }}
              labelFormatter={(t) => new Date(t as number).toLocaleTimeString('fr-FR')}
              formatter={(v: number) => [`${v} bpm`, 'FHR']}
            />
          </LineChart>
        </ResponsiveContainer>
      </div>

      {/* Tocogram */}
      <div className="bg-slate-900 rounded-lg p-3">
        <h4 className="text-xs font-semibold text-slate-400 uppercase mb-2">
          Tocogramme (contractions utérines)
        </h4>
        <ResponsiveContainer width="100%" height={100}>
          <LineChart data={visibleToco}>
            <CartesianGrid strokeDasharray="3 3" stroke="#334155" />
            <XAxis
              dataKey="time"
              tickFormatter={(t) => new Date(t).toLocaleTimeString('fr-FR', {
                hour: '2-digit',
                minute: '2-digit'
              })}
              stroke="#64748b"
              fontSize={10}
            />
            <YAxis domain={[0, 100]} stroke="#64748b" fontSize={10} />
            <Line
              type="monotone"
              dataKey="value"
              stroke="#a78bfa"
              strokeWidth={1.5}
              dot={false}
              isAnimationActive={false}
              fill="rgba(167, 139, 250, 0.1)"
            />
          </LineChart>
        </ResponsiveContainer>
      </div>
    </div>
  );
}
typescriptCopy// ============================================================================
// src/components/labor/BishopScoreCard.tsx — Carte Score de Bishop
// ============================================================================

'use client';

import React from 'react';

interface BishopComponent {
  name: string;
  value: number;
  max: number;
  description: string;
}

interface BishopScoreProps {
  score?: {
    total: number;
    components: {
      dilation: number;
      effacement: number;
      consistency: number;
      position: number;
      station: number;
    };
    interpretation: string;
    provenance: string;
    timestamp: string;
  };
}

const BISHOP_DESCRIPTIONS: Record<string, Record<number, string>> = {
  dilation: { 0: 'Fermé', 1: '1-2 cm', 2: '3-4 cm', 3: '≥5 cm' },
  effacement: { 0: '0-30%', 1: '40-50%', 2: '60-70%', 3: '≥80%' },
  consistency: { 0: 'Ferme', 1: 'Moyen', 2: 'Mou' },
  position: { 0: 'Postérieur', 1: 'Central', 2: 'Antérieur' },
  station: { 0: '-3', 1: '-2', 2: '-1/0', 3: '+1/+2' },
};

export function BishopScoreCard({ score }: BishopScoreProps) {
  if (!score) {
    return (
      <div className="bg-slate-900 rounded-lg p-4 animate-pulse">
        <div className="h-6 bg-slate-800 rounded w-1/3 mb-4" />
        <div className="h-20 bg-slate-800 rounded" />
      </div>
    );
  }

  const getInterpretationColor = (interpretation: string) => {
    if (interpretation.includes('Très favorable')) return 'text-green-400 bg-green-950';
    if (interpretation.includes('Favorable')) return 'text-cyan-400 bg-cyan-950';
    return 'text-amber-400 bg-amber-950';
  };

  const getBarColor = (value: number, max: number) => {
    const ratio = value / max;
    if (ratio >= 0.75) return 'bg-green-500';
    if (ratio >= 0.5) return 'bg-cyan-500';
    if (ratio >= 0.25) return 'bg-amber-500';
    return 'bg-red-500';
  };

  const components: BishopComponent[] = [
    { name: 'Dilatation', value: score.components.dilation, max: 3,
      description: BISHOP_DESCRIPTIONS.dilation[score.components.dilation] },
    { name: 'Effacement', value: score.components.effacement, max: 3,
      description: BISHOP_DESCRIPTIONS.effacement[score.components.effacement] },
    { name: 'Consistance', value: score.components.consistency, max: 2,
      description: BISHOP_DESCRIPTIONS.consistency[score.components.consistency] },
    { name: 'Position', value: score.components.position, max: 2,
      description: BISHOP_DESCRIPTIONS.position[score.components.position] },
    { name: 'Station', value: score.components.station, max: 3,
      description: BISHOP_DESCRIPTIONS.station[score.components.station] },
  ];

  return (
    <div className="bg-slate-900 rounded-lg p-4">
      <div className="flex items-center justify-between mb-4">
        <h3 className="text-sm font-semibold text-slate-300">
          Score de Bishop
        </h3>
        <div className="flex items-center gap-2">
          <span className="text-3xl font-bold text-white">
            {score.total}
          </span>
          <span className="text-sm text-slate-400">/13</span>
        </div>
      </div>
      
      <span className={`inline-block px-2 py-1 rounded text-xs font-semibold mb-4 ${
        getInterpretationColor(score.interpretation)
      }`}>
        {score.interpretation}
      </span>

      <div className="space-y-3">
        {components.map((comp) => (
          <div key={comp.name} className="flex items-center gap-3">
            <span className="text-xs text-slate-400 w-24 text-right">
              {comp.name}
            </span>
            <div className="flex-1 h-3 bg-slate-800 rounded-full overflow-hidden">
              <div
                className={`h-full rounded-full transition-all duration-500 ${
                  getBarColor(comp.value, comp.max)
                }`}
                style={{ width: `${(comp.value / comp.max) * 100}%` }}
              />
            </div>
            <span className="text-xs text-slate-300 w-8 text-right">
              {comp.value}/{comp.max}
            </span>
            <span className="text-xs text-slate-500 w-20">
              {comp.description}
            </span>
          </div>
        ))}
      </div>
      
      <div className="mt-3 pt-3 border-t border-slate-800 flex justify-between">
        <span className="text-[10px] text-slate-500">
          Réf: [Bishop 1964] [3][4]
        </span>
        <span className="text-[10px] text-slate-500">
          {new Date(score.timestamp).toLocaleTimeString('fr-FR')}
        </span>
      </div>
    </div>
  );
}
typescriptCopy// ============================================================================
// src/components/risk/SHAPWaterfall.tsx — Visualisation SHAP Explicable
// ============================================================================

'use client';

import React from 'react';

interface SHAPFeature {
  name: string;
  value: number;          // SHAP value
  featureValue: string;   // Actual feature value for display
  direction: 'increase' | 'decrease';
}

interface SHAPWaterfallProps {
  features: SHAPFeature[];
  baseValue: number;
  prediction: number;
  title: string;
}

export function SHAPWaterfall({
  features,
  baseValue,
  prediction,
  title
}: SHAPWaterfallProps) {
  if (!features?.length) return null;

  const sorted = [...features].sort(
    (a, b) => Math.abs(b.value) - Math.abs(a.value)
  );
  const maxAbsValue = Math.max(...sorted.map(f => Math.abs(f.value)));

  return (
    <div className="bg-slate-900 rounded-lg p-4">
      <h3 className="text-sm font-semibold text-slate-300 mb-1">{title}</h3>
      <p className="text-xs text-slate-500 mb-4">
        Explication IA: contribution de chaque facteur au risque prédit
      </p>

      {/* Base value */}
      <div className="flex items-center gap-2 mb-3 text-xs">
        <span className="text-slate-400">Risque de base:</span>
        <span className="text-white font-mono">
          {(baseValue * 100).toFixed(1)}%
        </span>
      </div>

      {/* Feature bars */}
      <div className="space-y-2">
        {sorted.slice(0, 10).map((feature, idx) => {
          const barWidth = (Math.abs(feature.value) / maxAbsValue) * 100;
          const isIncrease = feature.direction === 'increase';
          
          return (
            <div key={idx} className="flex items-center gap-2">
              <span className="text-[11px] text-slate-400 w-40 text-right truncate"
                    title={feature.name}>
                {feature.name}
              </span>
              <div className="flex-1 h-5 relative flex items-center">
                <div className="absolute inset-0 flex items-center">
                  <div className="w-full h-[1px] bg-slate-700" />
                </div>
                <div
                  className={`h-5 rounded-sm relative z-10 flex items-center px-1 ${
                    isIncrease
                      ? 'bg-red-500/30 border border-red-500/50'
                      : 'bg-blue-500/30 border border-blue-500/50'
                  }`}
                  style={{
                    width: `${Math.max(barWidth, 5)}%`,
                    marginLeft: isIncrease ? '50%' : `${50 - barWidth}%`
                  }}
                >
                  <span className={`text-[9px] font-mono ${
                    isIncrease ? 'text-red-300' : 'text-blue-300'
                  }`}>
                    {isIncrease ? '+' : ''}{(feature.value * 100).toFixed(1)}%
                  </span>
                </div>
              </div>
              <span className="text-[10px] text-slate-500 w-20 font-mono">
                = {feature.featureValue}
              </span>
            </div>
          );
        })}
      </div>

      {/* Prediction */}
      <div className="flex items-center gap-2 mt-4 pt-3 border-t border-slate-700">
        <span className="text-slate-300 text-sm font-semibold">
          Risque prédit:
        </span>
        <span className={`text-lg font-bold font-mono ${
          prediction >= 0.7 ? 'text-red-400' :
          prediction >= 0.4 ? 'text-amber-400' :
          'text-green-400'
        }`}>
          {(prediction * 100).toFixed(1)}%
        </span>
        <span className="text-[10px] text-slate-500">
          (IC95%: ±{((prediction * 0.1) * 100).toFixed(1)}%)
        </span>
      </div>
      
      <p className="text-[10px] text-slate-600 mt-2">
        Explainability: SHAP TreeExplainer | Modèle: cesarean_risk_predictor v3.1
      </p>
    </div>
  );
}
typescriptCopy// ============================================================================
// src/components/neonatal/ApgarScoreCard.tsx — Score d'Apgar
// ============================================================================

'use client';

import React from 'react';

interface ApgarComponents {
  appearance: number;
  pulse: number;
  grimace: number;
  activity: number;
  respiration: number;
}

interface ApgarScoreCardProps {
  apgar1min?: { total: number; components: ApgarComponents };
  apgar5min?: { total: number; components: ApgarComponents };
  predicted?: { probability_low: number; confidence: number };
}

const COMPONENT_LABELS: Record<keyof ApgarComponents, {
  label: string;
  descriptions: string[]
}> = {
  appearance: {
    label: 'Apparence (coloration)',
    descriptions: ['Bleu/pâle', 'Extrémités bleues', 'Rose']
  },
  pulse: {
    label: 'Pouls (FC)',
    descriptions: ['Absent', '<100 bpm', '≥100 bpm']
  },
  grimace: {
    label: 'Grimace (réflexes)',
    descriptions: ['Aucune', 'Faible', 'Vive']
  },
  activity: {
    label: 'Activité (tonus)',
    descriptions: ['Flasque', 'Flexion', 'Mouvements actifs']
  },
  respiration: {
    label: 'Respiration',
    descriptions: ['Absente', 'Irrégulière', 'Cri vigoureux']
  },
};

export function ApgarScoreCard({ apgar1min, apgar5min, predicted }: ApgarScoreCardProps) {
  const getScoreColor = (score: number | undefined) => {
    if (score === undefined) return 'text-slate-500';
    if (score >= 7) return 'text-green-400';
    if (score >= 4) return 'text-amber-400';
    return 'text-red-400';
  };

  const getScoreBg = (score: number | undefined) => {
    if (score === undefined) return 'bg-slate-800';
    if (score >= 7) return 'bg-green-950 border-green-800';
    if (score >= 4) return 'bg-amber-950 border-amber-800';
    return 'bg-red-950 border-red-800';
  };

  const renderScoreCircle = (
    label: string,
    score: number | undefined
  ) => (
    <div className={`flex flex-col items-center p-4 rounded-lg border ${getScoreBg(score)}`}>
      <span className="text-xs text-slate-400 mb-2">{label}</span>
      <span className={`text-4xl font-bold ${getScoreColor(score)}`}>
        {score ?? '—'}
      </span>
      <span className="text-xs text-slate-500 mt-1">/10</span>
    </div>
  );

  const renderComponentRow = (
    key: keyof ApgarComponents,
    value1min: number | undefined,
    value5min: number | undefined
  ) => {
    const meta = COMPONENT_LABELS[key];
    return (
      <tr key={key} className="border-b border-slate-800">
        <td className="py-2 text-xs text-slate-400">{meta.label}</td>
        <td className="py-2 text-center">
          {value1min !== undefined && (
            <span className={`text-xs font-mono px-2 py-0.5 rounded ${
              value1min === 2 ? 'bg-green-950 text-green-400' :
              value1min === 1 ? 'bg-amber-950 text-amber-400' :
              'bg-red-950 text-red-400'
            }`}>
              {value1min} - {meta.descriptions[value1min]}
            </span>
          )}
        </td>
        <td className="py-2 text-center">
          {value5min !== undefined && (
            <span className={`text-xs font-mono px-2 py-0.5 rounded ${
              value5min === 2 ? 'bg-green-950 text-green-400' :
              value5min === 1 ? 'bg-amber-950 text-amber-400' :
              'bg-red-950 text-red-400'
            }`}>
              {value5min} - {meta.descriptions[value5min]}
            </span>
          )}
        </td>
      </tr>
    );
  };

  return (
    <div className="bg-slate-900 rounded-lg p-4">
      <h3 className="text-sm font-semibold text-slate-300 mb-4">
        Score d'Apgar — Évaluation Néonatale
      </h3>

      {/* Score circles */}
      <div className="grid grid-cols-2 gap-4 mb-4">
        {renderScoreCircle('APGAR 1 min', apgar1min?.total)}
        {renderScoreCircle('APGAR 5 min', apgar5min?.total)}
      </div>

      {/* ML Prediction (before delivery) */}
      {predicted && (
        <div className="mb-4 p-3 bg-slate-800 rounded-lg">
          <div className="flex items-center justify-between">
            <span className="text-xs text-slate-400">
              🤖 Prédiction ML (pré-natal)
            </span>
            <span className={`text-xs font-mono ${
              predicted.probability_low >= 0.5 ? 'text-red-400' : 'text-green-400'
            }`}>
              P(Apgar&lt;7) = {(predicted.probability_low * 100).toFixed(1)}%
              <span className="text-slate-500 ml-1">
                (conf: {(predicted.confidence * 100).toFixed(0)}%)
              </span>
            </span>
          </div>
        </div>
      )}

      {/* Component detail table */}
      {(apgar1min || apgar5min) && (
        <table className="w-full">
          <thead>
            <tr className="border-b border-slate-700">
              <th className="text-left text-xs text-slate-500 pb-2">Composante</th>
              <th className="text-center text-xs text-slate-500 pb-2">1 min</th>
              <th className="text-center text-xs text-slate-500 pb-2">5 min</th>
            </tr>
          </thead>
          <tbody>
            {(Object.keys(COMPONENT_LABELS) as Array<keyof ApgarComponents>).map(key =>
              renderComponentRow(
                key,
                apgar1min?.components[key],
                apgar5min?.components[key]
              )
            )}
          </tbody>
        </table>
      )}

      <div className="mt-3 pt-2 border-t border-slate-800">
        <span className="text-[10px] text-slate-500">
          Réf: [Virginia Apgar 1952] [StatPearls APGAR] [5]
        </span>
      </div>
    </div>
  );
}
typescriptCopy// ============================================================================
// src/components/compliance/HumanValidationModal.tsx
// ============================================================================

'use client';

import React, { useState, useEffect, useRef } from 'react';

interface HumanValidationModalProps {
  validation: {
    id: string;
    agentSource: string;
    condition: string;
    severity: 'CRITICAL' | 'HIGH' | 'MEDIUM';
    summary: string;
    metrics: Record<string, any>;
    recommendation: string;
    timestamp: string;
    timeoutSeconds: number;
  };
  onApprove: (decision: { approved: true; notes?: string }) => void;
  onReject: (reason: string) => void;
}

export function HumanValidationModal({
  validation,
  onApprove,
  onReject
}: HumanValidationModalProps) {
  const [notes, setNotes] = useState('');
  const [rejectReason, setRejectReason] = useState('');
  const [showReject, setShowReject] = useState(false);
  const [remainingSeconds, setRemainingSeconds] = useState(validation.timeoutSeconds);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  useEffect(() => {
    // Play alert sound on mount
    audioRef.current = new Audio(
      validation.severity === 'CRITICAL'
        ? '/sounds/alert-critical.mp3'
        : '/sounds/alert-high.mp3'
    );
    audioRef.current.loop = true;
    audioRef.current.play().catch(() => {});

    return () => {
      audioRef.current?.pause();
    };
  }, [validation.severity]);

  useEffect(() => {
    const timer = setInterval(() => {
      setRemainingSeconds(prev => {
        if (prev <= 1) {
          clearInterval(timer);
          // Auto-escalate
          return 0;
        }
        return prev - 1;
      });
    }, 1000);
    return () => clearInterval(timer);
  }, []);

  const severityStyles = {
    CRITICAL: 'border-red-500 bg-red-950/80',
    HIGH: 'border-amber-500 bg-amber-950/80',
    MEDIUM: 'border-yellow-500 bg-yellow-950/80',
  };

  const severityIcons = {
    CRITICAL: '🚨',
    HIGH: '⚠️',
    MEDIUM: '⚡',
  };

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/70 backdrop-blur-sm">
      <div className={`max-w-lg w-full mx-4 rounded-xl border-2 p-6 shadow-2xl ${
        severityStyles[validation.severity]
      }`}>
        {/* Header */}
        <div className="flex items-center justify-between mb-4">
          <div className="flex items-center gap-2">
            <span className="text-2xl">{severityIcons[validation.severity]}</span>
            <h2 className="text-lg font-bold text-white">
              VALIDATION HUMAINE REQUISE
            </h2>
          </div>
          <div className={`px-3 py-1 rounded-full text-xs font-bold ${
            remainingSeconds < 30 ? 'bg-red-600 animate-pulse' : 'bg-slate-700'
          } text-white`}>
            ⏱ {Math.floor(remainingSeconds / 60)}:{String(remainingSeconds % 60).padStart(2, '0')}
          </div>
        </div>

        {/* Content */}
        <div className="space-y-3 mb-6">
          <div className="text-xs text-slate-300">
            <strong>Agent:</strong> {validation.agentSource}
          </div>
          <div className="text-xs text-slate-300">
            <strong>Condition:</strong> {validation.condition}
          </div>
          <div className="bg-slate-900/50 rounded-lg p-3 text-sm text-white">
            {validation.summary}
          </div>
          <div className="bg-slate-900/50 rounded-lg p-3">
            <span className="text-xs text-cyan-400 font-semibold">
              Recommandation IA:
            </span>
            <p className="text-sm text-white mt-1">
              {validation.recommendation}
            </p>
          </div>
        </div>

        {/* Actions */}
        {!showReject ? (
          <div className="flex gap-3">
            <button
              onClick={() => {
                audioRef.current?.pause();
                onApprove({ approved: true, notes: notes || undefined });
              }}
              className="flex-1 bg-green-600 hover:bg-green-500 text-white font-bold 
                         py-3 rounded-lg transition-colors text-sm"
            >
              ✅ VALIDER & POURSUIVRE
            </button>
            <button
              onClick={() => setShowReject(true)}
              className="flex-1 bg-red-700 hover:bg-red-600 text-white font-bold 
                         py-3 rounded-lg transition-colors text-sm"
            >
              ❌ REJETER / OVERRIDE
            </button>
          </div>
        ) : (
          <div className="space-y-3">
            <textarea
              value={rejectReason}
              onChange={(e) => setRejectReason(e.target.value)}
              placeholder="Motif du rejet (obligatoire pour audit)..."
              className="w-full bg-slate-800 border border-slate-600 rounded-lg p-3 
                         text-sm text-white placeholder-slate-500 resize-none"
              rows={3}
              required
            />
            <div className="flex gap-3">
              <button
                onClick={() => setShowReject(false)}
                className="flex-1 bg-slate-700 hover:bg-slate-600 text-white 
                           py-2 rounded-lg text-sm"
              >
                ← Retour
              </button>
              <button
                onClick={() => {
                  if (rejectReason.trim()) {
                    audioRef.current?.pause();
                    onReject(rejectReason);
                  }
                }}
                disabled={!rejectReason.trim()}
                className="flex-1 bg-red-600 hover:bg-red-500 disabled:bg-slate-700 
                           disabled:cursor-not-allowed text-white font-bold
                           py-2 rounded-lg text-sm"
              >
                Confirmer le rejet
              </button>
            </div>
          </div>
        )}

        {/* Notes (optional) */}
        {!showReject && (
          <textarea
            value={notes}
            onChange={(e) => setNotes(e.target.value)}
            placeholder="Notes cliniques (optionnel)..."
            className="w-full mt-3 bg-slate-900/50 border border-slate-700 rounded-lg 
                       p-2 text-xs text-white placeholder-slate-600 resize-none"
            rows={2}
          />
        )}

        <p className="text-[10px] text-slate-500 mt-3 text-center">
          Cette décision sera enregistrée dans l'audit trail (SHA-256) 
          conformément au EU AI Act et MDR 2017/745.
        </p>
      </div>
    </div>
  );
}
typescriptCopy// ============================================================================
// src/hooks/useAgentPipeline.ts — Hook Orchestration Pipeline Agents
// ============================================================================

'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
import type { AgentPipelineOutput, PipelineStatus, HumanReviewDecision } from '@/types/agents';

const API_BASE = process.env.NEXT_PUBLIC_API_BASE || 'http://localhost:8000';
const WS_BASE = process.env.NEXT_PUBLIC_WS_BASE || 'ws://localhost:8000';

export function useAgentPipeline(patientId: string) {
  const [pipelineOutput, setPipelineOutput] = useState<AgentPipelineOutput | null>(null);
  const [pipelineStatus, setPipelineStatus] = useState<PipelineStatus>('idle');
  const [error, setError] = useState<string | null>(null);
  const wsRef = useRef<WebSocket | null>(null);

  // WebSocket connection for real-time pipeline updates
  useEffect(() => {
    if (!patientId) return;

    const ws = new WebSocket(`${WS_BASE}/ws/v2/pipeline/${patientId}`);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('[Pipeline WS] Connected');
      setPipelineStatus('connected');
    };

    ws.onmessage = (event) => {
      try {
        const message = JSON.parse(event.data);
        
        switch (message.type) {
          case 'pipeline_started':
            setPipelineStatus('running');
            break;
            
          case 'agent_output':
            setPipelineOutput(prev => ({
              ...prev,
              [message.agentId]: message.output,
              lastUpdate: new Date().toISOString(),
            } as AgentPipelineOutput));
            break;
            
          case 'human_review_required':
            setPipelineStatus('awaiting_human');
            setPipelineOutput(prev => ({
              ...prev,
              humanReviewRequired: true,
              humanReviewDetails: message.details,
            } as AgentPipelineOutput));
            break;
            
          case 'pipeline_complete':
            setPipelineStatus('complete');
            setPipelineOutput(prev => ({
              ...prev,
              ...message.finalOutput,
              completedAt: new Date().toISOString(),
                   } as AgentPipelineOutput));
            break;
            
          case 'pipeline_error':
            setPipelineStatus('error');
            setError(message.error);
            break;
            
          case 'agent_metrics_update':
            setPipelineOutput(prev => ({
              ...prev,
              aggregatedMetrics: {
                ...(prev?.aggregatedMetrics || {}),
                [message.agentId]: message.metrics,
              },
              lastMetricsUpdate: new Date().toISOString(),
            } as AgentPipelineOutput));
            break;

          case 'alert':
            setPipelineOutput(prev => ({
              ...prev,
              alerts: [...(prev?.alerts || []), message.alert],
            } as AgentPipelineOutput));
            break;

          case 'ctg_realtime':
            setPipelineOutput(prev => ({
              ...prev,
              ctg: {
                ...(prev?.ctg || {}),
                ...message.ctgData,
              },
            } as AgentPipelineOutput));
            break;

          default:
            console.warn('[Pipeline WS] Unknown message type:', message.type);
        }
      } catch (e) {
        console.error('[Pipeline WS] Parse error:', e);
      }
    };

    ws.onerror = (event) => {
      console.error('[Pipeline WS] Error:', event);
      setPipelineStatus('error');
      setError('WebSocket connection error');
    };

    ws.onclose = (event) => {
      console.log('[Pipeline WS] Closed:', event.code, event.reason);
      setPipelineStatus('disconnected');
      
      // Auto-reconnect after 3 seconds
      setTimeout(() => {
        if (wsRef.current?.readyState === WebSocket.CLOSED) {
          console.log('[Pipeline WS] Reconnecting...');
          // Reconnection logic handled by effect re-run
        }
      }, 3000);
    };

    return () => {
      ws.close(1000, 'Component unmount');
      wsRef.current = null;
    };
  }, [patientId]);

  // Trigger full pipeline execution
  const triggerPipeline = useCallback(async (options?: {
    includeQuantum?: boolean;
    forceRefresh?: boolean;
    specificAgents?: string[];
  }) => {
    try {
      setPipelineStatus('running');
      setError(null);

      const response = await fetch(`${API_BASE}/api/v2/pipeline/execute`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${getAuthToken()}`,
        },
        body: JSON.stringify({
          patientId,
          options: {
            includeQuantum: options?.includeQuantum ?? false,
            forceRefresh: options?.forceRefresh ?? false,
            specificAgents: options?.specificAgents,
          },
        }),
      });

      if (!response.ok) {
        throw new Error(`Pipeline trigger failed: ${response.status}`);
      }

      const result = await response.json();
      return result;
    } catch (e) {
      setPipelineStatus('error');
      setError(e instanceof Error ? e.message : 'Unknown error');
      throw e;
    }
  }, [patientId]);

  // Acknowledge human review decision
  const acknowledgeHumanReview = useCallback(async (
    reviewId: string,
    decision: HumanReviewDecision
  ) => {
    try {
      const response = await fetch(`${API_BASE}/api/v2/pipeline/human-review`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${getAuthToken()}`,
        },
        body: JSON.stringify({
          reviewId,
          patientId,
          decision: {
            approved: decision.approved,
            reason: decision.reason,
            notes: decision.notes,
            clinicianId: getCurrentClinicianId(),
            timestamp: new Date().toISOString(),
          },
        }),
      });

      if (!response.ok) {
        throw new Error(`Human review acknowledgment failed: ${response.status}`);
      }

      setPipelineOutput(prev => ({
        ...prev,
        humanReviewRequired: false,
        humanReviewDetails: null,
        humanDecision: decision,
      } as AgentPipelineOutput));

      setPipelineStatus('running'); // Pipeline resumes

      return await response.json();
    } catch (e) {
      setError(e instanceof Error ? e.message : 'Review acknowledgment failed');
      throw e;
    }
  }, [patientId]);

  return {
    pipelineOutput,
    pipelineStatus,
    error,
    triggerPipeline,
    acknowledgeHumanReview,
  };
}

// Helper functions
function getAuthToken(): string {
  // SMART on FHIR OAuth2 token retrieval
  return sessionStorage.getItem('smart_token') || '';
}

function getCurrentClinicianId(): string {
  return sessionStorage.getItem('clinician_id') || 'unknown';
}
typescriptCopy// ============================================================================
// src/hooks/useCTGStream.ts — Hook Streaming CTG Temps Réel
// ============================================================================

'use client';

import { useState, useEffect, useRef, useCallback } from 'react';

interface CTGDataPoint {
  time: number;
  fhr: number;
  toco: number;
}

interface CTGStreamState {
  fhrBuffer: Array<{ time: number; value: number }>;
  tocoBuffer: Array<{ time: number; value: number }>;
  currentFHR: number | null;
  currentToco: number | null;
  connected: boolean;
  sampleRate: number;
  bufferDurationMinutes: number;
}

const MAX_BUFFER_POINTS = 30 * 60 * 4; // 30 minutes at 4Hz

export function useCTGStream(patientId: string, bufferMinutes: number = 30) {
  const [state, setState] = useState<CTGStreamState>({
    fhrBuffer: [],
    tocoBuffer: [],
    currentFHR: null,
    currentToco: null,
    connected: false,
    sampleRate: 4,
    bufferDurationMinutes: bufferMinutes,
  });

  const wsRef = useRef<WebSocket | null>(null);
  const bufferRef = useRef<{ fhr: CTGDataPoint[]; toco: CTGDataPoint[] }>({
    fhr: [],
    toco: [],
  });

  // Batch update interval for performance
  const updateIntervalRef = useRef<NodeJS.Timeout | null>(null);

  useEffect(() => {
    if (!patientId) return;

    const WS_BASE = process.env.NEXT_PUBLIC_WS_BASE || 'ws://localhost:8000';
    const ws = new WebSocket(`${WS_BASE}/ws/v2/ctg-stream/${patientId}`);
    wsRef.current = ws;

    ws.binaryType = 'arraybuffer'; // For efficient binary CTG data

    ws.onopen = () => {
      setState(prev => ({ ...prev, connected: true }));
      
      // Start batch update timer (update UI every 250ms for smooth rendering)
      updateIntervalRef.current = setInterval(() => {
        const cutoff = Date.now() - bufferMinutes * 60 * 1000;
        
        setState(prev => ({
          ...prev,
          fhrBuffer: bufferRef.current.fhr
            .filter(p => p.time >= cutoff)
            .map(p => ({ time: p.time, value: p.fhr })),
          tocoBuffer: bufferRef.current.toco
            .filter(p => p.time >= cutoff)
            .map(p => ({ time: p.time, value: p.toco })),
          currentFHR: bufferRef.current.fhr.length > 0
            ? bufferRef.current.fhr[bufferRef.current.fhr.length - 1].fhr
            : null,
          currentToco: bufferRef.current.toco.length > 0
            ? bufferRef.current.toco[bufferRef.current.toco.length - 1].toco
            : null,
        }));
      }, 250);
    };

    ws.onmessage = (event) => {
      try {
        if (event.data instanceof ArrayBuffer) {
          // Binary protocol: [timestamp(8)][fhr(4)][toco(4)] per sample
          const view = new DataView(event.data);
          const numSamples = event.data.byteLength / 16;
          
          for (let i = 0; i < numSamples; i++) {
            const offset = i * 16;
            const timestamp = Number(view.getBigUint64(offset, true));
            const fhr = view.getFloat32(offset + 8, true);
            const toco = view.getFloat32(offset + 12, true);
            
            const point: CTGDataPoint = { time: timestamp, fhr, toco };
            bufferRef.current.fhr.push(point);
            bufferRef.current.toco.push(point);
          }
          
          // Trim buffer
          if (bufferRef.current.fhr.length > MAX_BUFFER_POINTS) {
            bufferRef.current.fhr = bufferRef.current.fhr.slice(-MAX_BUFFER_POINTS);
            bufferRef.current.toco = bufferRef.current.toco.slice(-MAX_BUFFER_POINTS);
          }
        } else {
          // JSON fallback
          const data = JSON.parse(event.data);
          if (data.type === 'ctg_sample') {
            const point: CTGDataPoint = {
              time: data.timestamp,
              fhr: data.fhr,
              toco: data.toco,
            };
            bufferRef.current.fhr.push(point);
            bufferRef.current.toco.push(point);
          }
        }
      } catch (e) {
        console.error('[CTG Stream] Parse error:', e);
      }
    };

    ws.onclose = () => {
      setState(prev => ({ ...prev, connected: false }));
    };

    ws.onerror = (err) => {
      console.error('[CTG Stream] WebSocket error:', err);
      setState(prev => ({ ...prev, connected: false }));
    };

    return () => {
      if (updateIntervalRef.current) {
        clearInterval(updateIntervalRef.current);
      }
      ws.close(1000, 'Unmount');
    };
  }, [patientId, bufferMinutes]);

  const clearBuffer = useCallback(() => {
    bufferRef.current = { fhr: [], toco: [] };
    setState(prev => ({
      ...prev,
      fhrBuffer: [],
      tocoBuffer: [],
      currentFHR: null,
      currentToco: null,
    }));
  }, []);

  return {
    ...state,
    clearBuffer,
  };
}
typescriptCopy// ============================================================================
// src/lib/fhir-client.ts — Client FHIR R4
// ============================================================================

import type { Bundle, Observation, Patient, RiskAssessment } from '@/types/fhir';

const FHIR_BASE = process.env.NEXT_PUBLIC_FHIR_BASE || 'http://localhost:8080/fhir';

interface FHIRClientConfig {
  baseUrl: string;
  authToken?: string;
  timeout?: number;
}

export class FHIRClient {
  private baseUrl: string;
  private authToken: string | null;
  private timeout: number;

  constructor(config?: Partial<FHIRClientConfig>) {
    this.baseUrl = config?.baseUrl || FHIR_BASE;
    this.authToken = config?.authToken || null;
    this.timeout = config?.timeout || 10000;
  }

  private async request<T>(path: string, options?: RequestInit): Promise<T> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      const headers: Record<string, string> = {
        'Accept': 'application/fhir+json',
        'Content-Type': 'application/fhir+json',
      };
      if (this.authToken) {
        headers['Authorization'] = `Bearer ${this.authToken}`;
      }

      const response = await fetch(`${this.baseUrl}${path}`, {
        ...options,
        headers: { ...headers, ...(options?.headers as Record<string, string>) },
        signal: controller.signal,
      });

      if (!response.ok) {
        const errorBody = await response.text();
        throw new FHIRError(response.status, errorBody, path);
      }

      return await response.json();
    } finally {
      clearTimeout(timeoutId);
    }
  }

  // Patient operations
  async getPatient(id: string): Promise<Patient> {
    return this.request<Patient>(`/Patient/${id}`);
  }

  // Observations (vital signs, CTG, labs)
  async getObservations(
    patientId: string,
    params?: {
      category?: string;
      code?: string;
      date?: string;
      _count?: number;
      _sort?: string;
    }
  ): Promise<Bundle<Observation>> {
    const searchParams = new URLSearchParams({
      subject: `Patient/${patientId}`,
      ...(params?.category && { category: params.category }),
      ...(params?.code && { code: params.code }),
      ...(params?.date && { date: params.date }),
      ...(params?._count && { _count: String(params._count) }),
      _sort: params?._sort || '-date',
    });
    return this.request<Bundle<Observation>>(`/Observation?${searchParams}`);
  }

  // Get latest CTG observations
  async getLatestCTG(patientId: string): Promise<Observation[]> {
    const bundle = await this.getObservations(patientId, {
      code: 'http://loinc.org|76477-9', // FHR LOINC code
      _count: 100,
      _sort: '-date',
    });
    return bundle.entry?.map(e => e.resource) || [];
  }

  // Get Bishop score observations
  async getBishopScore(patientId: string): Promise<Observation | null> {
    const bundle = await this.getObservations(patientId, {
      code: 'http://snomed.info/sct|364312004', // Cervical assessment
      _count: 1,
      _sort: '-date',
    });
    return bundle.entry?.[0]?.resource || null;
  }

  // Risk Assessments
  async getRiskAssessments(
    patientId: string,
    condition?: string
  ): Promise<Bundle<RiskAssessment>> {
    const searchParams = new URLSearchParams({
      subject: `Patient/${patientId}`,
      ...(condition && { condition }),
      _sort: '-date',
    });
    return this.request<Bundle<RiskAssessment>>(`/RiskAssessment?${searchParams}`);
  }

  // Create/Update Observation (from agent output)
  async createObservation(observation: Observation): Promise<Observation> {
    return this.request<Observation>('/Observation', {
      method: 'POST',
      body: JSON.stringify(observation),
    });
  }

  // FHIR Subscription for real-time
  async createSubscription(
    criteria: string,
    channelType: 'websocket' | 'rest-hook',
    endpoint: string
  ): Promise<any> {
    const subscription = {
      resourceType: 'Subscription',
      status: 'requested',
      criteria,
      channel: {
        type: channelType,
        endpoint,
        payload: 'application/fhir+json',
      },
    };
    return this.request('/Subscription', {
      method: 'POST',
      body: JSON.stringify(subscription),
    });
  }

  // Medication Administrations
  async getMedicationAdministrations(patientId: string): Promise<Bundle<any>> {
    return this.request(`/MedicationAdministration?subject=Patient/${patientId}&_sort=-effective-time`);
  }

  // Diagnostic Reports (echography, labs)
  async getDiagnosticReports(
    patientId: string,
    category?: string
  ): Promise<Bundle<any>> {
    const params = new URLSearchParams({
      subject: `Patient/${patientId}`,
      ...(category && { category }),
      _sort: '-date',
    });
    return this.request(`/DiagnosticReport?${params}`);
  }

  setAuthToken(token: string) {
    this.authToken = token;
  }
}

class FHIRError extends Error {
  constructor(
    public status: number,
    public body: string,
    public path: string
  ) {
    super(`FHIR Error ${status} on ${path}: ${body}`);
    this.name = 'FHIRError';
  }
}

// Singleton instance
export const fhirClient = new FHIRClient();
typescriptCopy// ============================================================================
// src/types/agents.ts — Types TypeScript pour le Pipeline d'Agents
// ============================================================================

export type PipelineStatus =
  | 'idle'
  | 'connected'
  | 'running'
  | 'awaiting_human'
  | 'complete'
  | 'error'
  | 'disconnected';

export type AlertPriority = 'CRITICAL' | 'HIGH' | 'MEDIUM' | 'LOW';
export type FIGOClassification = 'Normal' | 'Suspect' | 'Pathologique';
export type RiskLevel = 'Faible' | 'Modéré' | 'Élevé' | 'Critique';
export type LaborPhase = 'Latente' | 'Active' | 'Transition' | 'Expulsion';
export type PartogramPosition = 'Avant ligne alerte' | 'Entre alerte et action' | 'Après ligne action';

export interface BishopScore {
  total: number;
  components: {
    dilation: number;
    effacement: number;
    consistency: number;
    position: number;
    station: number;
  };
  interpretation: string;
  provenance: string;
  timestamp: string;
}

export interface CTGAnalysis {
  figoClass: FIGOClassification;
  figoConfidence: number;
  baseline: { value: number; unit: string; ci: string };
  variabilitySTV: { value: number; unit: string; ci: string };
  variabilityLTV: { value: number; unit: string; ci: string };
  accelerations: number;
  decelerations: {
    early: number;
    late: number;
    variable: number;
    prolonged: number;
  };
  decelerationMarkers: Array<{
    startTime: number;
    endTime: number;
    type: 'early' | 'late' | 'variable' | 'prolonged';
    severity: 'mild' | 'moderate' | 'severe';
  }>;
  contractions: { frequency: number; unit: string };
  fetalDistressScore: number;
  metrics: Record<string, any>;
  narrativeSummary: string;
  situationReport: string;
}

export interface LaborAnalysis {
  bishopScore: BishopScore;
  laborPhase: LaborPhase;
  dilationRate: { value: number; unit: string; ci: string };
  partogramPosition: PartogramPosition;
  partogramData: Array<{
    time: number;
    dilation: number;
    descent: number;
  }>;
  stagnationDetected: boolean;
  stagnationDuration?: number;
  contractionDynamics: {
    frequency: number;
    durationMean: number;
    montevideoUnits?: number;
  };
  narrativeSummary: string;
  situationReport: string;
}

export interface RiskAnalysis {
  cesareanRisk: number;
  cesareanRiskCI: string;
  fetalDistressRisk: number;
  pphRisk: number;
  combinedRiskLevel: RiskLevel;
  shapValues: Array<{
    name: string;
    value: number;
    featureValue: string;
    direction: 'increase' | 'decrease';
  }>;
  baseRisk: number;
  monteCarloScenarios?: {
    nSimulations: number;
    bestScenario: string;
    worstScenario: string;
    medianOutcome: string;
  };
  narrativeSummary: string;
  situationReport: string;
}

export interface NeonatalAnalysis {
  apgar1min?: {
    total: number;
    components: {
      appearance: number;
      pulse: number;
      grimace: number;
      activity: number;
      respiration: number;
    };
  };
  apgar5min?: {
    total: number;
    components: {
      appearance: number;
      pulse: number;
      grimace: number;
      activity: number;
      respiration: number;
    };
  };
  predictedApgar?: {
    probability_low: number;
    confidence: number;
  };
  birthWeight?: number;
  birthWeightPercentile?: number;
  cordPH?: number;
  kmcEligible: boolean;
  kmcStartTime?: string;
  narrativeSummary: string;
  situationReport: string;
}

export interface PolygraphResult {
  globalConfidence: number;
  hallucinationRisk: number;
  documentsFound: number;
  credibilityScore: number;
  conflictsIdentified: number;
  verificationDetails: Array<{
    claim: string;
    verified: boolean;
    source: string;
    confidence: number;
  }>;
  narrativeSummary: string;
}

export interface ComplianceReport {
  agentsInvoked: number;
  agentStatuses: Record<string, 'OK' | 'WARNING' | 'ERROR' | 'HALTED'>;
  gdprCompliant: boolean;
  euAiActCompliant: boolean;
  humanInterventionsRequired: number;
  humanInterventionDetails: Array<{
    agentSource: string;
    reason: string;
    status: 'pending' | 'approved' | 'rejected';
  }>;
  auditEntries: number;
  narrativeSummary: string;
}

export interface Alert {
  id: string;
  priority: AlertPriority;
  source: string;
  message: string;
  timestamp: string;
  acknowledged: boolean;
  acknowledgedBy?: string;
  acknowledgedAt?: string;
}

export interface HumanReviewDecision {
  approved: boolean;
  reason?: string;
  notes?: string;
  clinicianId?: string;
  timestamp?: string;
}

export interface AgentPipelineOutput {
  // Agent-specific outputs
  ctg?: CTGAnalysis;
  labor?: LaborAnalysis;
  risks?: RiskAnalysis;
  neonatal?: NeonatalAnalysis;
  polygraph?: PolygraphResult;
  compliance?: ComplianceReport;
  
  // Clinical narrative
  clinicalNarrative?: {
    sections: Array<{ title: string; content: string }>;
    fullText: string;
    citations: Array<{ id: number; text: string; url?: string }>;
  };
  
  // Aggregated metrics (JSON dashboard)
  aggregatedMetrics?: Record<string, any>;
  
  // Alerts
  alerts?: Alert[];
  
  // Human-in-the-loop
  humanReviewRequired?: boolean;
  humanReviewDetails?: {
    id: string;
    agentSource: string;
    condition: string;
    severity: AlertPriority;
    summary: string;
    metrics: Record<string, any>;
    recommendation: string;
    timestamp: string;
    timeoutSeconds: number;
  } | null;
  humanDecision?: HumanReviewDecision;
  
  // Audit
  audit?: {
    entries: Array<{
      timestamp: string;
      agentId: string;
      action: string;
      inputHash: string;
      outputHash: string;
      modelUsed: string;
    }>;
  };
  
  // Timestamps
  lastUpdate?: string;
  lastMetricsUpdate?: string;
  completedAt?: string;
}

3. INSTRUCTIONS DE DÉVELOPPEMENT CURSOR — Fichier .cursorrules
markdownCopy# ============================================================================
# .cursor/rules/obstetric-ai.mdc
# Règles Cursor pour le Système Agentique d'Intelligence Obstétricale
# ============================================================================

---
description: Règles de développement pour le système agentique de santé
  fœtale et intelligence obstétricale. Couvre le backend Python (FastAPI),
  le frontend Next.js/React, les modèles ML, l'intégration FHIR R4,
  et la conformité réglementaire (EU AI Act, MDR, RGPD).
globs:
  - "**/*.ts"
  - "**/*.tsx"
  - "**/*.py"
  - "**/*.yaml"
  - "**/*.yml"
  - "**/*.json"
alwaysApply: true
---

## CONTEXTE DU PROJET

Tu travailles sur un **système agentique d'intelligence obstétricale** —
une plateforme d'IA médicale à haut risque (EU AI Act Annexe III) pour:

- La surveillance fœto-maternelle en temps réel (CTG, partogramme, Bishop)
- La prédiction de risques obstétricaux (césarienne, détresse fœtale, RCIU, pré-éclampsie)
- Le suivi néonatal immédiat (Apgar, Kangaroo Mother Care)
- La génération de rapports cliniques explicables avec citations

**CLASSIFICATION: Dispositif Médical Classe IIb — Chaque ligne de code peut
impacter la vie d'une mère et de son enfant.**

## ARCHITECTURE TECHNIQUE

### Stack Backend
- **Language**: Python 3.12+
- **Framework API**: FastAPI 0.110+ avec async/await
- **Orchestration agents**: Apache Airflow 2.9 + NATS JetStream
- **Message bus**: NATS JetStream (inter-agent communication)
- **FHIR Server**: HAPI FHIR R4 (Java) — interaction via REST
- **Base de données**: PostgreSQL 16 (Patroni HA) + Redis 7 (cache)
- **Vector store**: pgvector (embeddings connaissances médicales)
- **Feature store**: Feast (online: Redis, offline: PostgreSQL)
- **ML Frameworks**: PyTorch 2.4, XGBoost 2.1, LightGBM 4.4, scikit-learn 1.5, PyMC 5
- **ML Ops**: MLflow 2.x, Kubeflow Pipelines, Evidently AI
- **Model serving**: TorchServe, ONNX Runtime, FastAPI endpoints
- **Containerisation**: Docker + Kubernetes (Helm + ArgoCD)
- **Monitoring**: Prometheus + Grafana + ELK + Jaeger (OpenTelemetry)

### Stack Frontend
- **Framework**: Next.js 15 (App Router)
- **Language**: TypeScript 5.5+ (strict mode)
- **UI**: Tailwind CSS 3.4 + composants custom
- **Graphiques**: Recharts (CTG, partogramme, SHAP), D3.js (custom viz)
- **État**: Zustand (stores) + React Query (server state)
- **WebSocket**: Native WebSocket API avec reconnection automatique
- **FHIR Client**: Custom TypeScript client (src/lib/fhir-client.ts)
- **Tests**: Vitest + React Testing Library + Playwright (E2E)

### Modèles LLM (Multi-Provider Routing)
- **Claude Opus 4**: Raisonnement clinique complexe, narration (primary)
- **Claude Sonnet 4**: Analyses rapides, monitoring temps réel
- **Claude 4.5 Sonnet**: Recherche approfondie, vérification polygraphe
- **GPT-4o**: Analyse multimodale (images écho, tracés CTG visuels)
- **o3**: Raisonnement avancé cas complexes
- **Mistral Large**: Souveraineté EU, conversations, backup
- **IBM Granite 3.3**: Extraction FHIR, terminologie médicale, fine-tuning

### Modèles ML Spécialisés
- **ctg_classifier**: 1D-CNN + BiLSTM + Attention (PyTorch) — Classification FIGO
- **cesarean_risk_predictor**: XGBoost — Risque césarienne urgente
- **apgar_predictor**: Random Forest + Logistic Regression — Prédiction Apgar bas
- **rciu_detector**: LightGBM + Neural Network Ensemble — Détection RCIU
- **preeclampsia_risk_model**: Bayesian Logistic Regression (PyMC) — Risque PE
- **ultrasound_quality_checker**: ResNet-50 fine-tuned — Qualité coupes écho

## RÈGLES IMPÉRATIVES (SÉCURITÉ PATIENT)

### 🚨 RÈGLES CRITIQUES — JAMAIS ENFREINDRE

1. **JAMAIS** de diagnostic autonome. Toute sortie doit être une
   "suggestion" ou "évaluation" nécessitant validation humaine.

2. **JAMAIS** de prescription automatique de médicament ou d'acte invasif.

3. **TOUJOURS** inclure un mécanisme human-in-the-loop pour:
   - Classification CTG "Pathologique"
   - Apgar 5 min ≤ 6
   - Risque combiné "Élevé" ou "Critique"
   - Pré-éclampsie "Sévère" ou HELLP
   - Toute toxicité médicamenteuse détectée

4. **TOUJOURS** logger dans l'audit trail (SHA-256 hash chain):
   - Chaque appel LLM (prompt, réponse, modèle, version, latence)
   - Chaque prédiction ML (features, prédiction, confiance)
   - Chaque décision humaine (approbation/rejet, identité, timestamp)
   - Chaque alerte émise et son acquittement

5. **TOUJOURS** citer les sources dans les sorties narratives:
   Format: [Auteur, Année, Source, Niveau de preuve]

6. **TOUJOURS** fournir un intervalle de confiance pour toute
   valeur numérique prédite.

7. **JAMAIS** exposer de données patient non anonymisées en dehors
   du périmètre sécurisé (chiffrement AES-256-GCM au repos,
   TLS 1.3 en transit).

8. **TOUJOURS** implémenter des bornes physiologiques pour rejeter
   les données aberrantes (FHR: 60-220 bpm, TA sys: 60-250 mmHg, etc.)

### 🏥 CONVENTIONS MÉDICALES

- Utilise la terminologie FHIR R4 pour toutes les ressources
- Utilise SNOMED-CT, ICD-11, LOINC pour le codage
- Respecte les guidelines: FIGO 2015 (CTG), OMS (partogramme),
  HAS/CNGOF (obstétrique FR), NICE CG190, ACOG
- Score de Bishop sur /13 (pas /10)
- Apgar sur /10 (5 composantes × 0-2)
- Poids fœtal estimé avec formule Hadlock 4-parameter
- Courbes de croissance: INTERGROWTH-21st ou Hadlock

## CONVENTIONS DE CODE

### Python (Backend)

```python
# Style: PEP 8 + type hints obligatoires
# Docstrings: Google style
# Async: utiliser async/await partout sauf calculs CPU-bound

from typing import Optional
from pydantic import BaseModel, Field
from fastapi import APIRouter, Depends, HTTPException

class CTGAnalysisRequest(BaseModel):
    """Requête d'analyse CTG."""
    patient_id: str = Field(..., description="FHIR Patient ID")
    fhr_signal: list[float] = Field(..., description="Signal FHR en Hz")
    toco_signal: list[float] = Field(..., description="Signal tocogramme")
    sample_rate_hz: float = Field(4.0, description="Fréquence échantillonnage")

class CTGAnalysisResponse(BaseModel):
    """Réponse d'analyse CTG avec classification FIGO."""
    figo_classification: str  # "Normal" | "Suspect" | "Pathologique"
    confidence: float = Field(..., ge=0.0, le=1.0)
    narrative_summary: str
    metrics: dict
    situation_report: str
    sources: list[str]
    audit_hash: str

# Tous les endpoints doivent:
# 1. Valider les entrées avec Pydantic
# 2. Logger dans l'audit trail
# 3. Retourner des réponses FHIR-compatibles
# 4. Gérer les erreurs avec des codes HTTP appropriés
# 5. Inclure des timeouts explicites
TypeScript (Frontend)
typescriptCopy// Strict mode obligatoire
// Nommage: PascalCase composants, camelCase fonctions/variables
// Hooks custom: préfixe "use"
// Types: fichier séparé dans src/types/

// Composants: functional components avec React.FC
// Props: interface dédiée (pas de `any`)
// État: Zustand pour global, useState pour local
// Data fetching: React Query (useQuery/useMutation)
// WebSocket: hook custom avec reconnection automatique

// ACCESSIBILITÉ:
// - aria-labels sur tous les éléments interactifs
// - Rôles ARIA pour les alertes (role="alert" pour critiques)
// - Contrast ratio AA minimum
// - Keyboard navigation complète

// PERFORMANCE:
// - React.memo pour composants lourds (CTGChart)
// - useMemo/useCallback pour calculs/handlers coûteux
// - Batch updates pour streaming data (requestAnimationFrame)
// - Virtualisation pour listes longues (react-window)
Tests
Copy# Backend: pytest + pytest-asyncio
# Coverage minimum: 90% pour agents, 80% pour utils
# Tests obligatoires:
# - Bornes physiologiques (toutes les valeurs limites)
# - Human-in-the-loop triggers (chaque condition)
# - Audit trail integrity (hash chain)
# - FHIR schema validation
# - Fallback model routing
# - Timeout handling

# Frontend: Vitest + React Testing Library
# Tests obligatoires:
# - Affichage correct des alertes critiques
# - Modal validation humaine (approve/reject flow)
# - CTG chart avec données streaming
# - Score Bishop rendu correct
# - Apgar score all components
# - Accessibility (axe-core)

# E2E: Playwright
# Scénarios critiques:
# - Workflow complet: données → agents → rapport → validation
# - Alerte critique CTG → modal → acquittement
# - Déconnexion WebSocket → reconnection → récupération état
STRUCTURE DES AGENTS (Convention de développement)
Chaque agent DOIT implémenter l'interface suivante:
pythonCopyfrom abc import ABC, abstractmethod
from typing import Any

class BaseObstetricAgent(ABC):
    """Interface de base pour tous les agents obstétricaux."""
    
    agent_id: str
    agent_name: str
    description: str
    
    @abstractmethod
    async def process(self, inputs: dict[str, Any]) -> AgentOutput:
        """Traitement principal de l'agent."""
        ...
    
    @abstractmethod
    async def validate_inputs(self, inputs: dict[str, Any]) -> bool:
        """Validation des entrées (bornes physiologiques, schéma)."""
        ...
    
    @abstractmethod
    def get_human_review_conditions(self) -> list[HumanReviewCondition]:
        """Conditions déclenchant une revue humaine."""
        ...
    
    @abstractmethod
    def get_fhir_output_type(self) -> str:
        """Type de ressource FHIR en sortie."""
        ...
    
    async def log_audit(self, entry: AuditEntry) -> str:
        """Log dans l'audit trail avec hash SHA-256."""
        ...
Chaque sortie d'agent DOIT contenir:

narrative_summary (max 300 mots, markdown, avec citations)
critical_metrics (dict avec value, unit, CI, provenance)
situation_report (alerte level + action requise)
json_dashboard (métriques structurées pour le dashboard)
audit_hash (SHA-256 de l'entrée + sortie)

GESTION DES ERREURS
pythonCopy# Hiérarchie d'erreurs:
# CriticalSafetyError → halt_pipeline + emergency_notification
# AgentProcessingError → retry_with_fallback + log
# DataValidationError → reject_input + log
# ModelInferenceError → use_fallback_model + log
# TimeoutError → skip_with_warning + log
# FHIRError → retry + log

# TOUJOURS: fail-safe (conservative defaults)
# JAMAIS: fail-silent (toute erreur doit être loggée et visible)
DÉPLOIEMENT
yamlCopy# Docker: multi-stage builds, images minimales (distroless)
# Kubernetes:
#   - Resources limits obligatoires
#   - Health checks (liveness + readiness)
#   - Network policies (deny-all default)
#   - Secrets via External Secrets Operator
# CI/CD:
#   - Pre-commit: linting + type-checking + security scan
#   - PR: tests unitaires + intégration + SAST (Snyk/Trivy)
#   - Merge: tests E2E + performance benchmarks
#   - Deploy staging: clinical validation checklist
#   - Deploy prod: approval gates (ML Lead + Clinical + Regulatory)
COMMANDES UTILES
bashCopy# Backend
cd backend
poetry install
poetry run pytest --cov=agents --cov-report=html
poetry run uvicorn main:app --reload --port 8000

# Frontend
cd frontend
pnpm install
pnpm dev          # Next.js dev server
pnpm test         # Vitest
pnpm test:e2e     # Playwright
pnpm build        # Production build
pnpm lint         # ESLint + TypeScript check

# ML
cd ml
poetry run python -m pytest tests/
poetry run mlflow ui --port 5000
poetry run python train_ctg_classifier.py --config configs/ctg_v2.yaml

# Docker
docker compose -f docker-compose.dev.yml up
docker compose -f docker-compose.prod.yml up -d

# Kubernetes
helm upgrade --install obs-ai ./charts/obstetric-ai -n obs-ai-prod
kubectl get pods -n obs-ai-prod
FICHIERS DE RÉFÉRENCE IMPORTANTS

system.yaml — Configuration complète du système (CE FICHIER)
src/types/agents.ts — Types TypeScript de tous les agents
src/lib/fhir-client.ts — Client FHIR R4
backend/agents/base.py — Classe de base des agents
backend/orchestrator/pipeline.py — Orchestration du pipeline
ml/configs/ — Configurations des modèles ML
docs/clinical-validation/ — Documentation validation clinique
docs/regulatory/ — Documentation réglementaire (EU AI Act, MDR)

RAPPEL FINAL
Ce système traite des vies humaines. Chaque décision de code doit être
prise avec la rigueur d'un dispositif médical certifié. En cas de doute
entre performance et sécurité, choisis TOUJOURS la sécurité.
Priorité absolue: Sécurité du fœtus et de la mère.
Copy
---

## 4. BACKEND PYTHON — Squelette des Agents

```python
# ============================================================================
# backend/agents/base.py — Classe de Base pour Tous les Agents
# ============================================================================

from abc import ABC, abstractmethod
from datetime import datetime, timezone
from hashlib import sha256
from typing import Any, Optional
from enum import Enum
from dataclasses import dataclass, field

from pydantic import BaseModel, Field
import structlog
import json

logger = structlog.get_logger()


class AlertPriority(str, Enum):
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"


class AgentStatus(str, Enum):
    OK = "OK"
    WARNING = "WARNING"
    ERROR = "ERROR"
    HALTED = "HALTED"
    AWAITING_HUMAN = "AWAITING_HUMAN"


@dataclass
class HumanReviewCondition:
    """Condition déclenchant une revue humaine obligatoire."""
    condition_expression: str
    priority: AlertPriority
    message_template: str
    timeout_seconds: int = 120
    escalation_chain: list[str] = field(default_factory=lambda: [
        "sage_femme_garde", "obstetricien_garde", "chef_service"
    ])


class MetricValue(BaseModel):
    """Métrique individuelle avec provenance et confiance."""
    name: str
    value: Any
    unit: Optional[str] = None
    confidence_interval: Optional[str] = None
    provenance: str
    timestamp: str = Field(
        default_factory=lambda: datetime.now(timezone.utc).isoformat()
    )


class AgentOutput(BaseModel):
    """Sortie standardisée de tout agent obstétrical."""
    agent_id: str
    agent_name: str
    status: AgentStatus = AgentStatus.OK
    
    # Narratif (max 300 mots)
    narrative_summary: str = Field(
        ...,
        max_length=3000,
        description="Résumé narratif (~300 mots) avec citations [source]"
    )
    
    # Métriques critiques
    critical_metrics: list[MetricValue] = Field(default_factory=list)
    
    # Rapport de situation
    situation_report: str = ""
    alert_level: Optional[AlertPriority] = None
    
    # JSON Dashboard
    json_dashboard: dict[str, Any] = Field(default_factory=dict)
    
    # Human-in-the-loop
    human_review_required: bool = False
    human_review_details: Optional[dict[str, Any]] = None
    
    # Audit
    audit_hash: str = ""
    input_hash: str = ""
    model_used: Optional[str] = None
    model_version: Optional[str] = None
    processing_time_ms: float = 0.0
    
    # FHIR output
    fhir_resources: list[dict[str, Any]] = Field(default_factory=list)
    
    # Sources citées
    sources: list[str] = Field(default_factory=list)
    
    # Timestamp
    timestamp: str = Field(
        default_factory=lambda: datetime.now(timezone.utc).isoformat()
    )


class AuditEntry(BaseModel):
    """Entrée d'audit trail avec chaîne de hashes."""
    timestamp: str = Field(
        default_factory=lambda: datetime.now(timezone.utc).isoformat()
    )
    agent_id: str
    action_type: str
    input_hash: str
    output_hash: str
    model_used: Optional[str] = None
    model_version: Optional[str] = None
    confidence_scores: Optional[dict[str, float]] = None
    human_decision: Optional[dict[str, Any]] = None
    latency_ms: float = 0.0
    error_details: Optional[str] = None
    previous_entry_hash: str = ""
    entry_hash: str = ""

    def compute_hash(self) -> str:
        """Calcule le SHA-256 de cette entrée d'audit."""
        content = json.dumps({
            "timestamp": self.timestamp,
            "agent_id": self.agent_id,
            "action_type": self.action_type,
            "input_hash": self.input_hash,
            "output_hash": self.output_hash,
            "model_used": self.model_used,
            "previous_entry_hash": self.previous_entry_hash,
        }, sort_keys=True)
        return sha256(content.encode()).hexdigest()


class BaseObstetricAgent(ABC):
    """
    Classe de base abstraite pour tous les agents obstétricaux.
    
    Chaque agent DOIT implémenter:
    - process(): traitement principal
    - validate_inputs(): validation des entrées
    - get_human_review_conditions(): conditions HITL
    - get_fhir_output_type(): type FHIR de sortie
    
    Chaque agent REÇOIT automatiquement:
    - Logging structuré
    - Audit trail
    - Gestion d'erreurs fail-safe
    - Routage LLM multi-modèles
    """

    def __init__(
        self,
        agent_id: str,
        agent_name: str,
        description: str,
        llm_router: "LLMRouter",
        audit_store: "AuditStore",
        fhir_client: "FHIRClient",
    ):
        self.agent_id = agent_id
        self.agent_name = agent_name
        self.description = description
        self.llm_router = llm_router
        self.audit_store = audit_store
        self.fhir_client = fhir_client
        self.logger = logger.bind(agent_id=agent_id)

    async def execute(self, inputs: dict[str, Any]) -> AgentOutput:
        """
        Point d'entrée principal avec gestion d'erreurs,
        audit trail, et vérification HITL.
        """
        start_time = datetime.now(timezone.utc)
        input_hash = sha256(
            json.dumps(inputs, sort_keys=True, default=str).encode()
        ).hexdigest()

        try:
            # 1. Validate inputs
            self.logger.info("Validating inputs", input_hash=input_hash)
            if not await self.validate_inputs(inputs):
                raise DataValidationError(
                    f"Input validation failed for agent {self.agent_id}"
                )

            # 2. Process
            self.logger.info("Processing", input_hash=input_hash)
            output = await self.process(inputs)
            output.input_hash = input_hash

            # 3. Compute output hash
            output_content = output.narrative_summary + json.dumps(
                [m.model_dump() for m in output.critical_metrics],
                sort_keys=True
            )
            output.audit_hash = sha256(output_content.encode()).hexdigest()

            # 4. Check human review conditions
            for condition in self.get_human_review_conditions():
                if self._evaluate_condition(condition, output):
                    output.human_review_required = True
                    output.alert_level = condition.priority
                    output.human_review_details = {
                        "id": f"review_{self.agent_id}_{int(start_time.timestamp())}",
                        "agentSource": self.agent_name,
                        "condition": condition.condition_expression,
                        "severity": condition.priority.value,
                        "summary": output.situation_report,
                        "metrics": {m.name: m.value for m in output.critical_metrics},
                        "recommendation": output.situation_report,
                        "timestamp": start_time.isoformat(),
                        "timeoutSeconds": condition.timeout_seconds,
                    }
                    self.logger.warning(
                        "Human review required",
                        condition=condition.condition_expression,
                        priority=condition.priority.value,
                    )
                    break

            # 5. Compute processing time
            end_time = datetime.now(timezone.utc)
            output.processing_time_ms = (
                end_time - start_time
            ).total_seconds() * 1000

            # 6. Log audit entry
            await self._log_audit(
                action_type="process_complete",
                input_hash=input_hash,
                output_hash=output.audit_hash,
                model_used=output.model_used,
                model_version=output.model_version,
                latency_ms=output.processing_time_ms,
                confidence_scores={
                    m.name: m.value
                    for m in output.critical_metrics
                    if isinstance(m.value, (int, float))
                },
            )

            # 7. Write FHIR resources
            for fhir_resource in output.fhir_resources:
                try:
                    await self.fhir_client.create_resource(fhir_resource)
                except Exception as e:
                    self.logger.error(
                        "FHIR write failed",
                        error=str(e),
                        resource_type=fhir_resource.get("resourceType")
                    )

            self.logger.info(
                "Processing complete",
                status=output.status.value,
                processing_time_ms=output.processing_time_ms,
                human_review=output.human_review_required,
            )
            return output

        except DataValidationError as e:
            self.logger.error("Data validation error", error=str(e))
            await self._log_audit(
                action_type="validation_error",
                input_hash=input_hash,
                output_hash="",
                error_details=str(e),
                latency_ms=(datetime.now(timezone.utc) - start_time).total_seconds() * 1000,
            )
            return self._create_error_output(str(e), AgentStatus.ERROR)

        except CriticalSafetyError as e:
            self.logger.critical("CRITICAL SAFETY ERROR", error=str(e))
            await self._log_audit(
                action_type="critical_safety_error",
                input_hash=input_hash,
                output_hash="",
                error_details=str(e),
                latency_ms=(datetime.now(timezone.utc) - start_time).total_seconds() * 1000,
            )
            output = self._create_error_output(str(e), AgentStatus.HALTED)
            output.human_review_required = True
            output.alert_level = AlertPriority.CRITICAL
            return output

        except Exception as e:
            self.logger.error("Unexpected error", error=str(e), exc_info=True)
            await self._log_audit(
                action_type="unexpected_error",
                input_hash=input_hash,
                output_hash="",
                error_details=str(e),
                latency_ms=(datetime.now(timezone.utc) - start_time).total_seconds() * 1000,
            )
            return self._create_error_output(str(e), AgentStatus.ERROR)

    @abstractmethod
    async def process(self, inputs: dict[str, Any]) -> AgentOutput:
        """Traitement principal de l'agent. À implémenter."""
        ...

    @abstractmethod
    async def validate_inputs(self, inputs: dict[str, Any]) -> bool:
        """Validation des entrées. À implémenter."""
        ...

    @abstractmethod
    def get_human_review_conditions(self) -> list[HumanReviewCondition]:
        """Conditions de revue humaine. À implémenter."""
        ...

    @abstractmethod
    def get_fhir_output_type(self) -> str:
        """Type de ressource FHIR en sortie. À implémenter."""
        ...

    def _evaluate_condition(
        self, condition: HumanReviewCondition, output: AgentOutput
    ) -> bool:
        """Évalue si une condition HITL est remplie."""
        # Simple evaluation — in production, use a proper expression evaluator
        metrics_dict = {m.name: m.value for m in output.critical_metrics}
        try:
            return eval(
                condition.condition_expression,
                {"__builtins__": {}},
                metrics_dict
            )
        except Exception:
            return False

    def _create_error_output(self, error_msg: str, status: AgentStatus) -> AgentOutput:
        """Crée une sortie d'erreur fail-safe."""
        return AgentOutput(
            agent_id=self.agent_id,
            agent_name=self.agent_name,
            status=status,
            narrative_summary=(
                f"⚠️ L'agent {self.agent_name} a rencontré une erreur: {error_msg}. "
                f"Les données de cet agent ne sont pas disponibles. "
                f"Veuillez vous fier au jugement clinique et aux autres sources."
            ),
            situation_report=f"ERREUR AGENT: {error_msg}. Revue humaine recommandée.",
            alert_level=AlertPriority.HIGH,
            sources=[],
        )

    async def _log_audit(self, **kwargs) -> None:
        """Log une entrée d'audit avec chaîne de hashes."""
        try:
            previous_hash = await self.audit_store.get_last_hash(self.agent_id)
            entry = AuditEntry(
                agent_id=self.agent_id,
                previous_entry_hash=previous_hash or "",
                **kwargs,
            )
            entry.entry_hash = entry.compute_hash()
            await self.audit_store.store(entry)
        except Exception as e:
            self.logger.error("Audit log failed", error=str(e))


class DataValidationError(Exception):
    """Erreur de validation des données d'entrée."""
    pass


class CriticalSafetyError(Exception):
    """Erreur critique de sécurité patient — arrêt immédiat."""
    pass
pythonCopy# ============================================================================
# backend/agents/ctg_monitor.py — Agent de Monitoring CTG
# ============================================================================

from typing import Any
import numpy as np

from agents.base import (
    BaseObstetricAgent, AgentOutput, AgentStatus, MetricValue,
    HumanReviewCondition, AlertPriority, DataValidationError,
    CriticalSafetyError,
)


class CTGMonitorAgent(BaseObstetricAgent):
    """
    Agent de surveillance CTG en temps réel.
    
    Analyse la fréquence cardiaque fœtale (FHR) et le tocogramme.
    Classification FIGO 2015 (Normal/Suspect/Pathologique).
    Utilise le modèle ML ctg_classifier combiné avec l'analyse LLM.
    """

    # Physiological bounds for FHR
    FHR_MIN = 60
    FHR_MAX = 220
    TOCO_MIN = 0
    TOCO_MAX = 100

    def __init__(self, llm_router, audit_store, fhir_client, ctg_model):
        super().__init__(
            agent_id="CTGMonitorAgent",
            agent_name="CTG Monitor Agent",
            description="Surveillance CTG et classification FIGO du rythme fœtal",
            llm_router=llm_router,
            audit_store=audit_store,
            fhir_client=fhir_client,
        )
        self.ctg_model = ctg_model  # ML model for CTG classification

    async def validate_inputs(self, inputs: dict[str, Any]) -> bool:
        """Validate CTG signal data."""
        fhr_signal = inputs.get("fhr_signal")
        toco_signal = inputs.get("toco_signal")
        sample_rate = inputs.get("sample_rate_hz", 4.0)

        if fhr_signal is None or len(fhr_signal) == 0:
            raise DataValidationError("FHR signal is empty or missing")
        if toco_signal is None or len(toco_signal) == 0:
            raise DataValidationError("Toco signal is empty or missing")

        # Check physiological bounds
        fhr_array = np.array(fhr_signal)
        valid_fhr = fhr_array[(fhr_array >= self.FHR_MIN) & (fhr_array <= self.FHR_MAX)]
        
        if len(valid_fhr) < len(fhr_array) * 0.5:
            raise DataValidationError(
                f"More than 50% of FHR values outside physiological range "
                f"[{self.FHR_MIN}-{self.FHR_MAX} bpm]. Signal quality too low."
            )

        if sample_rate not in [1.0, 2.0, 4.0]:
            raise DataValidationError(
                f"Unsupported sample rate: {sample_rate}Hz. Expected 1, 2, or 4 Hz."
            )

        return True

    async def process(self, inputs: dict[str, Any]) -> AgentOutput:
        """Process CTG data and generate FIGO classification."""
        fhr_signal = np.array(inputs["fhr_signal"])
        toco_signal = np.array(inputs["toco_signal"])
        sample_rate = inputs.get("sample_rate_hz", 4.0)
        maternal_context = inputs.get("maternal_context", {})

        # --- Step 1: ML Model Prediction ---
        ml_result = await self.ctg_model.predict({
            "fhr": fhr_signal,
            "toco": toco_signal,
            "sample_rate": sample_rate,
        })

        figo_class = ml_result["classification"]  # Normal/Suspect/Pathologique
        figo_confidence = ml_result["confidence"]
        fetal_distress_score = ml_result["distress_probability"]
        deceleration_markers = ml_result.get("deceleration_markers", [])

        # --- Step 2: Feature Extraction ---
        features = self._extract_ctg_features(fhr_signal, toco_signal, sample_rate)

        # --- Step 3: LLM Interpretation ---
        llm_prompt = self._build_llm_prompt(features, ml_result, maternal_context)
        llm_response = await self.llm_router.route_and_call(
            task="ctg_analysis",
            prompt=llm_prompt,
            preferred_model="claude-sonnet-4",
            temperature=0.15,
            max_tokens=1024,
        )

        narrative = llm_response["content"]
        model_used = llm_response["model_used"]
        model_version = llm_response["model_version"]

        # --- Step 4: Build Metrics ---
        metrics = [
            MetricValue(
                name="FHR Baseline",
                value=round(features["baseline_bpm"], 1),
                unit="bpm",
                confidence_interval="±5 bpm",
                provenance="Capteur CTG (moyenne mobile 10 min)",
            ),
            MetricValue(
                name="Variabilité STV",
                value=round(features["stv_ms"], 1),
                unit="ms",
                confidence_interval="±1 ms",
                provenance="Analyse signal CTG (Dawes-Redman)",
            ),
            MetricValue(
                name="Variabilité LTV",
                value=round(features["ltv_bpm"], 1),
                unit="bpm",
                confidence_interval="±2 bpm",
                provenance="Analyse bande passante CTG",
            ),
            MetricValue(
                name="Classification FIGO",
                value=figo_class,
                unit="catégorie",
                provenance="FIGO Intrapartum Monitoring Guidelines 2015",
            ),
            MetricValue(
                name="Confiance classification",
                value=round(figo_confidence, 3),
                unit="probabilité",
                provenance=f"Modèle ctg_classifier (AUC={ml_result.get('model_auc', 'N/A')})",
            ),
            MetricValue(
                name="Score détresse fœtale ML",
                value=round(fetal_distress_score, 3),
                unit="probabilité 0-1",
                confidence_interval="IC95%",
                provenance="Modèle ctg_classifier v2.1",
            ),
            MetricValue(
                name="Accélérations",
                value=features["accelerations_count"],
                unit="count/20min",
                provenance="Détection automatique (>15bpm, >15s)",
            ),
            MetricValue(
                name="Décélérations tardives",
                value=features["late_decelerations_count"],
                unit="count",
                provenance="Classification ML + critères FIGO",
            ),
            MetricValue(
                name="Contractions utérines",
                value=features["contractions_per_10min"],
                unit="count/10min",
                provenance="Tocogramme",
            ),
        ]

        # --- Step 5: Situation Report ---
        if figo_class == "Pathologique":
            situation_report = (
                f"ALERTE CRITIQUE: CTG classifié PATHOLOGIQUE "
                f"(confiance: {figo_confidence:.1%}). "
                f"Décélérations tardives: {features['late_decelerations_count']}. "
                f"Score détresse fœtale: {fetal_distress_score:.1%}. "
                f"INTERVENTION HUMAINE OBLIGATOIRE. "
                f"Préparer éventuelle extraction en urgence. "
                f"[Réf: FIGO 2015, Ayres-de-Campos et al.]"
            )
            alert_level = AlertPriority.CRITICAL
        elif figo_class == "Suspect":
            situation_report = (
                f"CTG classifié SUSPECT (confiance: {figo_confidence:.1%}). "
                f"Surveillance rapprochée recommandée. "
                f"Réévaluer dans 15 minutes. "
                f"[Réf: FIGO 2015]"
            )
            alert_level = AlertPriority.HIGH
        else:
            situation_report = (
                f"CTG NORMAL (confiance: {figo_confidence:.1%}). "
                f"Aucune escalade requise. Continuer monitoring standard. "
                f"[Réf: FIGO 2015]"
            )
            alert_level = None

        # --- Step 6: FHIR Resource ---
        fhir_observation = self._create_fhir_observation(
            features, figo_class, figo_confidence, fetal_distress_score
        )

        return AgentOutput(
            agent_id=self.agent_id,
            agent_name=self.agent_name,
            status=AgentStatus.OK,
            narrative_summary=narrative,
            critical_metrics=metrics,
            situation_report=situation_report,
            alert_level=alert_level,
            json_dashboard={
                "figo_classification": figo_class,
                "figo_confidence": figo_confidence,
                "fetal_distress_score": fetal_distress_score,
                "baseline_bpm": features["baseline_bpm"],
                "stv_ms": features["stv_ms"],
                "ltv_bpm": features["ltv_bpm"],
                "accelerations": features["accelerations_count"],
                "decelerations": {
                    "early": features["early_decelerations_count"],
                    "late": features["late_decelerations_count"],
                    "variable": features["variable_decelerations_count"],
                    "prolonged": features["prolonged_decelerations_count"],
                },
                "contractions_per_10min": features["contractions_per_10min"],
                "deceleration_markers": deceleration_markers,
                "signal_quality": features["signal_quality"],
                "analysis_window_minutes": features["window_minutes"],
            },
            human_review_required=(figo_class == "Pathologique"),
            model_used=model_used,
            model_version=model_version,
            fhir_resources=[fhir_observation],
            sources=[
                "[FIGO, 2015, Intrapartum Fetal Monitoring Guidelines, Niveau A]",
                "[Ayres-de-Campos et al., 2015, IJGO, Consensus]",
                "[NICE CG190, 2023, Intrapartum Care, Niveau 1++]",
                f"[Modèle ctg_classifier v2.1, AUC={ml_result.get('model_auc', 'N/A')}]",
            ],
        )

    def get_human_review_conditions(self) -> list[HumanReviewCondition]:
        return [
            HumanReviewCondition(
                condition_expression=(
                    "locals().get('Classification FIGO') == 'Pathologique'"
                ),
                priority=AlertPriority.CRITICAL,
                message_template=(
                    "ALERTE CTG PATHOLOGIQUE — Classification FIGO pathologique "
                    "détectée. Validation obstétricien OBLIGATOIRE."
                ),
                timeout_seconds=120,
            ),
            HumanReviewCondition(
                condition_expression=(
                    "locals().get('Score détresse fœtale ML', 0) >= 0.8"
                ),
                priority=AlertPriority.CRITICAL,
                message_template=(
                    "ALERTE DÉTRESSE FŒTALE — Score ML de détresse ≥ 0.8. "
                    "Vérification clinique immédiate requise."
                ),
                timeout_seconds=60,
            ),
        ]

    def get_fhir_output_type(self) -> str:
        return "Observation"

    def _extract_ctg_features(
        self, fhr: np.ndarray, toco: np.ndarray, sr: float
    ) -> dict:
        """Extract CTG features from raw signals."""
        # Filter valid FHR values
        valid_mask = (fhr >= self.FHR_MIN) & (fhr <= self.FHR_MAX)
        valid_fhr = fhr[valid_mask]

        window_minutes = len(fhr) / sr / 60

        # Baseline (10-minute moving average)
        window_size = int(10 * 60 * sr)
        if len(valid_fhr) >= window_size:
            baseline = np.median(valid_fhr[-window_size:])
        else:
            baseline = np.median(valid_fhr) if len(valid_fhr) > 0 else 140.0

        # STV (Short-Term Variability) in ms
        if len(valid_fhr) > 1:
            rr_intervals = 60000.0 / valid_fhr  # Convert to ms
            stv = np.mean(np.abs(np.diff(rr_intervals)))
        else:
            stv = 0.0

        # LTV (Long-Term Variability) - amplitude of oscillations
        if len(valid_fhr) >= int(sr * 60):
            # 1-minute segments
            segment_size = int(sr * 60)
            segments = [
                valid_fhr[i:i + segment_size]
                for i in range(0, len(valid_fhr) - segment_size + 1, segment_size)
            ]
            ltv = np.mean([
                np.max(seg) - np.min(seg) for seg in segments if len(seg) > 0
            ]) if segments else 0.0
        else:
            ltv = 0.0

        # Simplified acceleration/deceleration detection
        # (In production, use the ML model's detailed output)
        accelerations = self._detect_accelerations(valid_fhr, sr)
        early_decels = 0  # Placeholder
        late_decels = 0
        variable_decels = 0
        prolonged_decels = 0

        # Contraction detection from toco
        contractions = self._detect_contractions(toco, sr)

        return {
            "baseline_bpm": float(baseline),
            "stv_ms": float(stv),
            "ltv_bpm": float(ltv),
            "accelerations_count": accelerations,
            "early_decelerations_count": early_decels,
            "late_decelerations_count": late_decels,
            "variable_decelerations_count": variable_decels,
            "prolonged_decelerations_count": prolonged_decels,
            "contractions_per_10min": contractions,
            "signal_quality": float(np.sum(valid_mask) / len(fhr)),
            "window_minutes": round(window_minutes, 1),
        }

    def _detect_accelerations(self, fhr: np.ndarray, sr: float) -> int:
        """Detect FHR accelerations (>15bpm above baseline for >15s)."""
        if len(fhr) < int(15 * sr):
            return 0
        baseline = np.median(fhr)
        above = fhr > (baseline + 15)
        # Count consecutive segments > 15s
        changes = np.diff(above.astype(int))
        starts = np.where(changes == 1)[0]
        ends = np.where(changes == -1)[0]
        count = 0
        for s in starts:
            matching_ends = ends[ends > s]
            if len(matching_ends) > 0:
                duration = (matching_ends[0] - s) / sr
                if duration >= 15:
                    count += 1
        return count

    def _detect_contractions(self, toco: np.ndarray, sr: float) -> float:
        """Estimate contractions per 10 minutes from tocogram."""
        if len(toco) < int(60 * sr):
            return 0.0
        # Simple peak detection
        threshold = np.percentile(toco, 75)
        above = toco > threshold
        changes = np.diff(above.astype(int))
        peaks = np.sum(changes == 1)
        duration_minutes = len(toco) / sr / 60
        if duration_minutes > 0:
            return round(peaks / duration_minutes * 10, 1)
        return 0.0

    def _build_llm_prompt(
        self, features: dict, ml_result: dict, maternal_context: dict
    ) -> str:
        """Build the LLM prompt for CTG interpretation."""
        return f"""Tu es un expert en cardiotocographie fœtale. Analyse les données
CTG suivantes et fournis une interprétation selon les critères FIGO 2015.

DONNÉES CTG:
- Baseline FHR: {features['baseline_bpm']:.1f} bpm
- Variabilité STV: {features['stv_ms']:.1f} ms
- Variabilité LTV: {features['ltv_bpm']:.1f} bpm
- Accélérations (20 min): {features['accelerations_count']}
- Décélérations tardives: {features['late_decelerations_count']}
- Décélérations variables: {features['variable_decelerations_count']}
- Contractions/10min: {features['contractions_per_10min']}
- Qualité signal: {features['signal_quality']:.1%}
- Fenêtre d'analyse: {features['window_minutes']} minutes

RÉSULTATS ML:
- Classification: {ml_result['classification']}
- Confiance: {ml_result['confidence']:.1%}
- Score détresse: {ml_result['distress_probability']:.1%}

CONTEXTE MATERNEL:
{_format_context(maternal_context)}

Fournis un résumé narratif (max 300 mots) avec:
1. Interprétation du tracé CTG selon FIGO 2015
2. Points d'attention spécifiques
3. Tendance sur la fenêtre d'analyse
4. Recommandation clinique si applicable

Cite tes sources: [FIGO 2015], [Ayres-de-Campos et al., 2015].
En cas de doute, privilégie TOUJOURS la sécurité du fœtus."""

    def _create_fhir_observation(
        self,
        features: dict,
        figo_class: str,
        confidence: float,
        distress_score: float,
    ) -> dict:
        """Create a FHIR Observation resource for CTG analysis."""
        return {
            "resourceType": "Observation",
            "status": "final",
            "category": [{
                "coding": [{
                    "system": "http://terminology.hl7.org/CodeSystem/observation-category",
                    "code": "exam",
                    "display": "Exam",
                }]
            }],
            "code": {
                "coding": [{
                    "system": "http://loinc.org",
                    "code": "76477-9",
                    "display": "Fetal Heart Rate Monitoring",
                }]
            },
            "component": [
                {
                    "code": {"text": "FHR Baseline"},
                    "valueQuantity": {
                        "value": features["baseline_bpm"],
                        "unit": "bpm",
                        "system": "http://unitsofmeasure.org",
                        "code": "/min",
                    },
                },
                {
                    "code": {"text": "FIGO Classification"},
                    "valueString": figo_class,
                },
                {
                    "code": {"text": "Classification Confidence"},
                    "valueQuantity": {
                        "value": confidence,
                        "unit": "probability",
                    },
                },
                {
                    "code": {"text": "Fetal Distress Score"},
                    "valueQuantity": {
                        "value": distress_score,
                        "unit": "probability",
                    },
                },
            ],
        }


def _format_context(ctx: dict) -> str:
    """Format maternal context for LLM prompt."""
    if not ctx:
        return "Non disponible"
    lines = []
    for key, value in ctx.items():
        lines.append(f"- {key}: {value}")
    return "\n".join(lines)
pythonCopy# ============================================================================
# backend/agents/llm_router.py — Routeur Multi-Modèles LLM
# ============================================================================

from typing import Any, Optional
from enum import Enum
import asyncio
import time

import structlog
from anthropic import AsyncAnthropic
from openai import AsyncOpenAI

logger = structlog.get_logger()


class LLMProvider(str, Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    MISTRAL = "mistral"
    IBM = "ibm"


class ModelConfig:
    def __init__(
        self,
        model_id: str,
        provider: LLMProvider,
        version: str,
        cost_tier: str,
        latency_target_ms: int,
        fallback: Optional[str] = None,
    ):
        self.model_id = model_id
        self.provider = provider
        self.version = version
        self.cost_tier = cost_tier
        self.latency_target_ms = latency_target_ms
        self.fallback = fallback


# Model registry
MODELS = {
    "claude-opus-4": ModelConfig(
        model_id="claude-opus-4-20250514",
        provider=LLMProvider.ANTHROPIC,
        version="claude-opus-4-20250514",
        cost_tier="premium",
        latency_target_ms=5000,
        fallback="claude-sonnet-4",
    ),
    "claude-sonnet-4": ModelConfig(
        model_id="claude-sonnet-4-20250514",
        provider=LLMProvider.ANTHROPIC,
        version="claude-sonnet-4-20250514",
        cost_tier="standard",
        latency_target_ms=1500,
        fallback="mistral-large",
    ),
    "claude-4.5-sonnet": ModelConfig(
        model_id="claude-4-5-sonnet-20250514",
        provider=LLMProvider.ANTHROPIC,
        version="claude-4-5-sonnet-20250514",
        cost_tier="premium",
        latency_target_ms=8000,
        fallback="claude-opus-4",
    ),
    "gpt
    "gpt-4o": ModelConfig(
        model_id="gpt-4o",
        provider=LLMProvider.OPENAI,
        version="gpt-4o-2025-latest",
        cost_tier="premium",
        latency_target_ms=3000,
        fallback="claude-opus-4",
    ),
    "o3": ModelConfig(
        model_id="o3",
        provider=LLMProvider.OPENAI,
        version="o3-2025-04-16",
        cost_tier="ultra-premium",
        latency_target_ms=15000,
        fallback="claude-opus-4",
    ),
    "mistral-large": ModelConfig(
        model_id="mistral-large-latest",
        provider=LLMProvider.MISTRAL,
        version="mistral-large-2025-latest",
        cost_tier="standard",
        latency_target_ms=2000,
        fallback="claude-sonnet-4",
    ),
    "ibm-granite-medical": ModelConfig(
        model_id="granite-3.3-8b-instruct",
        provider=LLMProvider.IBM,
        version="granite-3.3-8b-instruct",
        cost_tier="low",
        latency_target_ms=500,
        fallback="mistral-large",
    ),
}

# Routing rules: task -> preferred model
ROUTING_RULES = {
    "ctg_analysis": "claude-sonnet-4",
    "clinical_narrative": "claude-opus-4",
    "research_verification": "claude-4.5-sonnet",
    "multimodal_image": "gpt-4o",
    "complex_reasoning": "o3",
    "fhir_extraction": "ibm-granite-medical",
    "user_engagement": "mistral-large",
    "symbolic_reasoning": "claude-opus-4",
    "risk_analysis": "claude-opus-4",
    "therapeutic_monitoring": "claude-sonnet-4",
    "neonatal_assessment": "claude-sonnet-4",
    "preeclampsia_analysis": "claude-opus-4",
    "rciu_analysis": "claude-opus-4",
    "bishop_partogram": "claude-sonnet-4",
    "quantum_optimization": "o3",
    "compliance_check": "mistral-large",
    "default": "claude-opus-4",
}


class CircuitBreaker:
    """Circuit breaker pattern for LLM providers."""

    def __init__(self, failure_threshold: int = 3, reset_timeout: float = 60.0):
        self.failure_threshold = failure_threshold
        self.reset_timeout = reset_timeout
        self._failures: dict[str, int] = {}
        self._last_failure_time: dict[str, float] = {}
        self._state: dict[str, str] = {}  # "closed", "open", "half-open"

    def is_available(self, model_key: str) -> bool:
        state = self._state.get(model_key, "closed")
        if state == "closed":
            return True
        if state == "open":
            elapsed = time.time() - self._last_failure_time.get(model_key, 0)
            if elapsed >= self.reset_timeout:
                self._state[model_key] = "half-open"
                return True
            return False
        if state == "half-open":
            return True
        return False

    def record_success(self, model_key: str):
        self._failures[model_key] = 0
        self._state[model_key] = "closed"

    def record_failure(self, model_key: str):
        self._failures[model_key] = self._failures.get(model_key, 0) + 1
        self._last_failure_time[model_key] = time.time()
        if self._failures[model_key] >= self.failure_threshold:
            self._state[model_key] = "open"
            logger.warning(
                "Circuit breaker OPEN for model",
                model=model_key,
                failures=self._failures[model_key],
            )


class LLMRouter:
    """
    Routeur intelligent multi-modèles LLM.

    Sélectionne le modèle optimal en fonction de la tâche,
    de la latence requise, de la complexité, et de la disponibilité.
    Gère les fallbacks automatiques et le circuit breaking.
    """

    def __init__(
        self,
        anthropic_api_key: str,
        openai_api_key: str,
        mistral_api_key: Optional[str] = None,
        ibm_api_key: Optional[str] = None,
        ibm_endpoint: Optional[str] = None,
    ):
        self.anthropic_client = AsyncAnthropic(api_key=anthropic_api_key)
        self.openai_client = AsyncOpenAI(api_key=openai_api_key)
        self.mistral_api_key = mistral_api_key
        self.ibm_api_key = ibm_api_key
        self.ibm_endpoint = ibm_endpoint
        self.circuit_breaker = CircuitBreaker()
        self.logger = logger.bind(component="llm_router")

        # Metrics
        self._call_counts: dict[str, int] = {}
        self._total_latency: dict[str, float] = {}
        self._error_counts: dict[str, int] = {}

    def select_model(
        self,
        task: str,
        preferred_model: Optional[str] = None,
        urgency: str = "normal",
        complexity: str = "medium",
        has_images: bool = False,
        data_sovereignty_eu: bool = False,
    ) -> str:
        """
        Sélectionne le meilleur modèle selon les critères.

        Priority order:
        1. If images -> gpt-4o
        2. If EU sovereignty required -> mistral-large
        3. If urgency == critical -> claude-sonnet-4 (fastest)
        4. If complexity == high -> o3
        5. Preferred model if specified
        6. Task-based routing
        7. Default: claude-opus-4
        """
        if has_images:
            candidate = "gpt-4o"
        elif data_sovereignty_eu:
            candidate = "mistral-large"
        elif urgency == "critical":
            candidate = "claude-sonnet-4"
        elif complexity == "high" and task in ("complex_reasoning", "quantum_optimization"):
            candidate = "o3"
        elif preferred_model and preferred_model in MODELS:
            candidate = preferred_model
        else:
            candidate = ROUTING_RULES.get(task, ROUTING_RULES["default"])

        # Check circuit breaker and fallback if needed
        if self.circuit_breaker.is_available(candidate):
            return candidate

        # Fallback chain
        fallback_chain = self._get_fallback_chain(candidate)
        for fallback in fallback_chain:
            if self.circuit_breaker.is_available(fallback):
                self.logger.warning(
                    "Using fallback model",
                    original=candidate,
                    fallback=fallback,
                    reason="circuit_breaker_open",
                )
                return fallback

        # Last resort
        self.logger.error(
            "All models unavailable, using default",
            task=task,
        )
        return "claude-opus-4"

    def _get_fallback_chain(self, model_key: str, max_depth: int = 4) -> list[str]:
        """Build fallback chain from model config."""
        chain = []
        current = model_key
        visited = set()
        while current and current not in visited and len(chain) < max_depth:
            visited.add(current)
            config = MODELS.get(current)
            if config and config.fallback:
                chain.append(config.fallback)
                current = config.fallback
            else:
                break
        # Add global fallbacks
        for fb in ["claude-opus-4", "claude-sonnet-4", "mistral-large", "ibm-granite-medical"]:
            if fb not in chain and fb != model_key:
                chain.append(fb)
        return chain

    async def route_and_call(
        self,
        task: str,
        prompt: str,
        preferred_model: Optional[str] = None,
        system_prompt: Optional[str] = None,
        temperature: float = 0.2,
        max_tokens: int = 2048,
        top_p: float = 0.9,
        images: Optional[list[dict]] = None,
        urgency: str = "normal",
        complexity: str = "medium",
        data_sovereignty_eu: bool = False,
        extended_thinking: bool = False,
        thinking_budget: int = 10000,
    ) -> dict[str, Any]:
        """
        Route and call the appropriate LLM.

        Returns dict with:
        - content: str (response text)
        - model_used: str
        - model_version: str
        - latency_ms: float
        - tokens_used: dict
        - thinking: str (if extended thinking)
        """
        model_key = self.select_model(
            task=task,
            preferred_model=preferred_model,
            urgency=urgency,
            complexity=complexity,
            has_images=bool(images),
            data_sovereignty_eu=data_sovereignty_eu,
        )

        # Try selected model, then fallbacks
        attempts = [model_key] + self._get_fallback_chain(model_key)

        last_error = None
        for attempt_model in attempts:
            if not self.circuit_breaker.is_available(attempt_model):
                continue

            try:
                start = time.monotonic()
                result = await self._call_model(
                    model_key=attempt_model,
                    prompt=prompt,
                    system_prompt=system_prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    top_p=top_p,
                    images=images,
                    extended_thinking=extended_thinking,
                    thinking_budget=thinking_budget,
                )
                latency_ms = (time.monotonic() - start) * 1000

                self.circuit_breaker.record_success(attempt_model)
                self._record_metrics(attempt_model, latency_ms, success=True)

                config = MODELS[attempt_model]
                result["model_used"] = attempt_model
                result["model_version"] = config.version
                result["latency_ms"] = latency_ms

                if attempt_model != model_key:
                    result["fallback_used"] = True
                    result["original_model"] = model_key

                self.logger.info(
                    "LLM call successful",
                    model=attempt_model,
                    task=task,
                    latency_ms=round(latency_ms, 1),
                    tokens=result.get("tokens_used", {}),
                )
                return result

            except Exception as e:
                last_error = e
                self.circuit_breaker.record_failure(attempt_model)
                self._record_metrics(attempt_model, 0, success=False)
                self.logger.error(
                    "LLM call failed",
                    model=attempt_model,
                    task=task,
                    error=str(e),
                )
                continue

        # All attempts failed
        raise LLMRouterError(
            f"All LLM models failed for task '{task}'. "
            f"Last error: {last_error}"
        )

    async def _call_model(
        self,
        model_key: str,
        prompt: str,
        system_prompt: Optional[str],
        temperature: float,
        max_tokens: int,
        top_p: float,
        images: Optional[list[dict]],
        extended_thinking: bool,
        thinking_budget: int,
    ) -> dict[str, Any]:
        """Dispatch to appropriate provider."""
        config = MODELS[model_key]

        if config.provider == LLMProvider.ANTHROPIC:
            return await self._call_anthropic(
                config, prompt, system_prompt, temperature,
                max_tokens, top_p, images, extended_thinking, thinking_budget,
            )
        elif config.provider == LLMProvider.OPENAI:
            return await self._call_openai(
                config, prompt, system_prompt, temperature,
                max_tokens, top_p, images, extended_thinking,
            )
        elif config.provider == LLMProvider.MISTRAL:
            return await self._call_mistral(
                config, prompt, system_prompt, temperature,
                max_tokens, top_p,
            )
        elif config.provider == LLMProvider.IBM:
            return await self._call_ibm_granite(
                config, prompt, system_prompt, temperature,
                max_tokens, top_p,
            )
        else:
            raise ValueError(f"Unknown provider: {config.provider}")

    async def _call_anthropic(
        self, config, prompt, system_prompt, temperature,
        max_tokens, top_p, images, extended_thinking, thinking_budget,
    ) -> dict[str, Any]:
        """Call Anthropic Claude models."""
        messages = []

        # Build user message content
        content_parts = []
        if images:
            for img in images:
                content_parts.append({
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": img["media_type"],
                        "data": img["data"],
                    },
                })
        content_parts.append({"type": "text", "text": prompt})

        messages.append({"role": "user", "content": content_parts})

        # Build kwargs
        kwargs: dict[str, Any] = {
            "model": config.model_id,
            "messages": messages,
            "max_tokens": max_tokens,
        }
        if system_prompt:
            kwargs["system"] = system_prompt

        # Extended thinking for Claude Opus 4 / Sonnet 4
        if extended_thinking:
            kwargs["temperature"] = 1.0  # Required for extended thinking
            kwargs["thinking"] = {
                "type": "enabled",
                "budget_tokens": thinking_budget,
            }
        else:
            kwargs["temperature"] = temperature
            kwargs["top_p"] = top_p

        response = await self.anthropic_client.messages.create(**kwargs)

        # Extract content and thinking
        content_text = ""
        thinking_text = ""
        for block in response.content:
            if block.type == "thinking":
                thinking_text = block.thinking
            elif block.type == "text":
                content_text = block.text

        return {
            "content": content_text,
            "thinking": thinking_text,
            "tokens_used": {
                "input": response.usage.input_tokens,
                "output": response.usage.output_tokens,
            },
            "stop_reason": response.stop_reason,
        }

    async def _call_openai(
        self, config, prompt, system_prompt, temperature,
        max_tokens, top_p, images, extended_thinking,
    ) -> dict[str, Any]:
        """Call OpenAI GPT/o-series models."""
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # Build user message
        if images:
            content_parts = []
            for img in images:
                content_parts.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{img['media_type']};base64,{img['data']}",
                        "detail": "high",
                    },
                })
            content_parts.append({"type": "text", "text": prompt})
            messages.append({"role": "user", "content": content_parts})
        else:
            messages.append({"role": "user", "content": prompt})

        kwargs: dict[str, Any] = {
            "model": config.model_id,
            "messages": messages,
        }

        # o3 model uses different API params
        if config.model_id.startswith("o"):
            kwargs["max_completion_tokens"] = max_tokens
            if extended_thinking:
                kwargs["reasoning_effort"] = "high"
        else:
            kwargs["temperature"] = temperature
            kwargs["max_tokens"] = max_tokens
            kwargs["top_p"] = top_p

        response = await self.openai_client.chat.completions.create(**kwargs)

        choice = response.choices[0]
        return {
            "content": choice.message.content or "",
            "thinking": "",  # OpenAI doesn't expose reasoning traces
            "tokens_used": {
                "input": response.usage.prompt_tokens if response.usage else 0,
                "output": response.usage.completion_tokens if response.usage else 0,
            },
            "stop_reason": choice.finish_reason,
        }

    async def _call_mistral(
        self, config, prompt, system_prompt, temperature,
        max_tokens, top_p,
    ) -> dict[str, Any]:
        """Call Mistral models via HTTP API."""
        import httpx

        headers = {
            "Authorization": f"Bearer {self.mistral_api_key}",
            "Content-Type": "application/json",
        }

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        payload = {
            "model": config.model_id,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": top_p,
        }

        async with httpx.AsyncClient(timeout=30.0) as client:
            resp = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers=headers,
                json=payload,
            )
            resp.raise_for_status()
            data = resp.json()

        choice = data["choices"][0]
        usage = data.get("usage", {})
        return {
            "content": choice["message"]["content"],
            "thinking": "",
            "tokens_used": {
                "input": usage.get("prompt_tokens", 0),
                "output": usage.get("completion_tokens", 0),
            },
            "stop_reason": choice.get("finish_reason", "stop"),
        }

    async def _call_ibm_granite(
        self, config, prompt, system_prompt, temperature,
        max_tokens, top_p,
    ) -> dict[str, Any]:
        """Call IBM Granite models (on-premise or IBM Cloud)."""
        import httpx

        endpoint = self.ibm_endpoint or "https://us-south.ml.cloud.ibm.com"
        headers = {
            "Authorization": f"Bearer {self.ibm_api_key}",
            "Content-Type": "application/json",
        }

        full_prompt = ""
        if system_prompt:
            full_prompt += f"<|system|>\n{system_prompt}\n"
        full_prompt += f"<|user|>\n{prompt}\n<|assistant|>\n"

        payload = {
            "model_id": config.model_id,
            "input": full_prompt,
            "parameters": {
                "temperature": temperature,
                "max_new_tokens": max_tokens,
                "top_p": top_p,
            },
        }

        async with httpx.AsyncClient(timeout=15.0) as client:
            resp = await client.post(
                f"{endpoint}/ml/v1/text/generation?version=2024-03-14",
                headers=headers,
                json=payload,
            )
            resp.raise_for_status()
            data = resp.json()

        results = data.get("results", [{}])
        generated_text = results[0].get("generated_text", "") if results else ""
        tokens = results[0].get("generated_token_count", 0) if results else 0

        return {
            "content": generated_text.strip(),
            "thinking": "",
            "tokens_used": {
                "input": results[0].get("input_token_count", 0) if results else 0,
                "output": tokens,
            },
            "stop_reason": results[0].get("stop_reason", "max_tokens") if results else "error",
        }

    def _record_metrics(self, model_key: str, latency_ms: float, success: bool):
        """Record metrics for monitoring."""
        self._call_counts[model_key] = self._call_counts.get(model_key, 0) + 1
        if success:
            self._total_latency[model_key] = (
                self._total_latency.get(model_key, 0.0) + latency_ms
            )
        else:
            self._error_counts[model_key] = self._error_counts.get(model_key, 0) + 1

    def get_metrics(self) -> dict[str, Any]:
        """Return current metrics for Prometheus/Grafana."""
        metrics = {}
        for model_key in MODELS:
            calls = self._call_counts.get(model_key, 0)
            errors = self._error_counts.get(model_key, 0)
            total_lat = self._total_latency.get(model_key, 0.0)
            metrics[model_key] = {
                "total_calls": calls,
                "total_errors": errors,
                "error_rate": errors / calls if calls > 0 else 0,
                "avg_latency_ms": total_lat / (calls - errors) if (calls - errors) > 0 else 0,
                "circuit_breaker_state": self.circuit_breaker._state.get(model_key, "closed"),
            }
        return metrics


class LLMRouterError(Exception):
    """All LLM providers exhausted."""
    pass
pythonCopy# ============================================================================
# backend/orchestrator/pipeline.py — Orchestrateur du Pipeline d'Agents
# ============================================================================

import asyncio
from typing import Any, Optional
from datetime import datetime, timezone
from dataclasses import dataclass

import structlog
import nats
from nats.js import JetStreamContext

from agents.base import (
    BaseObstetricAgent, AgentOutput, AgentStatus,
    AlertPriority, AuditEntry,
)

logger = structlog.get_logger()


@dataclass
class PipelinePhase:
    name: str
    agents: list[str]
    parallel: bool
    depends_on: list[str]
    timeout_seconds: int
    human_checkpoint: bool = False
    optional: bool = False
    trigger_condition: Optional[str] = None


PIPELINE_PHASES = [
    PipelinePhase(
        name="phase_1_ingestion",
        agents=["StreamingGatewayAgent"],
        parallel=True,
        depends_on=[],
        timeout_seconds=5,
    ),
    PipelinePhase(
        name="phase_2_specialized_analysis",
        agents=[
            "CTGMonitorAgent",
            "BishopPartogramAgent",
            "RCIURiskAgent",
            "PreeclampsiaRiskAgent",
            "TherapeuticMonitoringAgent",
        ],
        parallel=True,
        depends_on=["phase_1_ingestion"],
        timeout_seconds=30,
    ),
    PipelinePhase(
        name="phase_3_risk_synthesis",
        agents=["MotherBabyRiskAgent"],
        parallel=False,
        depends_on=["phase_2_specialized_analysis"],
        timeout_seconds=20,
        human_checkpoint=True,
    ),
    PipelinePhase(
        name="phase_4_verification",
        agents=[
            "ResearchPolygraphAgent",
            "SymbolicReasoningAgent",
        ],
        parallel=True,
        depends_on=["phase_3_risk_synthesis"],
        timeout_seconds=45,
    ),
    PipelinePhase(
        name="phase_5_optimization",
        agents=["QuantumBirthOptimizerAgent"],
        parallel=False,
        depends_on=["phase_4_verification"],
        timeout_seconds=120,
        optional=True,
        trigger_condition="complex_case OR manual_request",
    ),
    PipelinePhase(
        name="phase_6_compliance",
        agents=["CoordinationComplianceAgent"],
        parallel=False,
        depends_on=["phase_4_verification"],
        timeout_seconds=15,
        human_checkpoint=True,
    ),
    PipelinePhase(
        name="phase_7_narrative",
        agents=["ClinicalNarrativeAgent"],
        parallel=False,
        depends_on=["phase_6_compliance"],
        timeout_seconds=30,
    ),
    PipelinePhase(
        name="phase_8_engagement",
        agents=["UserEngagementAgent"],
        parallel=False,
        depends_on=["phase_7_narrative"],
        timeout_seconds=0,  # Continuous
    ),
]


class ObstetricPipelineOrchestrator:
    """
    Orchestrateur principal du pipeline d'agents obstétricaux.

    Gère l'exécution séquentielle/parallèle des phases,
    les points de contrôle humains, les timeouts, les fallbacks,
    et la publication temps réel des résultats via NATS JetStream.
    """

    def __init__(
        self,
        agents: dict[str, BaseObstetricAgent],
        nats_url: str = "nats://localhost:4222",
    ):
        self.agents = agents
        self.nats_url = nats_url
        self.nc: Optional[nats.NATS] = None
        self.js: Optional[JetStreamContext] = None
        self.logger = logger.bind(component="pipeline_orchestrator")
        
        # State
        self._phase_outputs: dict[str, dict[str, AgentOutput]] = {}
        self._human_review_events: asyncio.Queue = asyncio.Queue()
        self._pipeline_running: bool = False

    async def connect(self):
        """Connect to NATS JetStream."""
        self.nc = await nats.connect(self.nats_url)
        self.js = self.nc.jetstream()
        
        # Create streams
        try:
            await self.js.add_stream(
                name="obstetric-pipeline",
                subjects=[
                    "pipeline.>",
                    "agent.>",
                    "alert.>",
                    "human-review.>",
                ],
                retention="limits",
                max_msgs=100000,
                max_age=86400_000_000_000,  # 24h in nanoseconds
            )
        except Exception:
            pass  # Stream may already exist

        self.logger.info("Connected to NATS JetStream")

    async def disconnect(self):
        """Disconnect from NATS."""
        if self.nc:
            await self.nc.close()

    async def execute_pipeline(
        self,
        patient_id: str,
        initial_data: dict[str, Any],
        options: Optional[dict[str, Any]] = None,
    ) -> dict[str, AgentOutput]:
        """
        Execute the full agent pipeline for a patient.

        Returns aggregated outputs from all agents.
        """
        options = options or {}
        self._pipeline_running = True
        self._phase_outputs = {}
        all_outputs: dict[str, AgentOutput] = {}

        pipeline_start = datetime.now(timezone.utc)
        self.logger.info(
            "Pipeline started",
            patient_id=patient_id,
            phases=len(PIPELINE_PHASES),
        )

        # Publish pipeline start event
        await self._publish_event(patient_id, "pipeline_started", {
            "patient_id": patient_id,
            "timestamp": pipeline_start.isoformat(),
            "phases": [p.name for p in PIPELINE_PHASES],
        })

        # Accumulate context for downstream agents
        pipeline_context = {"initial_data": initial_data}

        try:
            for phase in PIPELINE_PHASES:
                # Check optional phase trigger
                if phase.optional:
                    should_run = self._evaluate_phase_trigger(
                        phase.trigger_condition, options, all_outputs
                    )
                    if not should_run:
                        self.logger.info(
                            "Skipping optional phase",
                            phase=phase.name,
                            reason="trigger_condition_not_met",
                        )
                        continue

                # Check dependencies
                for dep in phase.depends_on:
                    if dep not in self._phase_outputs:
                        self.logger.error(
                            "Phase dependency not met",
                            phase=phase.name,
                            missing_dependency=dep,
                        )
                        raise PipelineError(
                            f"Dependency {dep} not met for {phase.name}"
                        )

                self.logger.info("Executing phase", phase=phase.name)
                await self._publish_event(patient_id, "phase_started", {
                    "phase": phase.name,
                    "agents": phase.agents,
                    "parallel": phase.parallel,
                })

                # Execute agents in phase
                phase_outputs = await self._execute_phase(
                    phase=phase,
                    patient_id=patient_id,
                    context=pipeline_context,
                    all_outputs=all_outputs,
                )

                self._phase_outputs[phase.name] = phase_outputs
                all_outputs.update(phase_outputs)

                # Update context with phase outputs
                for agent_id, output in phase_outputs.items():
                    pipeline_context[agent_id] = {
                        "narrative": output.narrative_summary,
                        "metrics": {
                            m.name: {"value": m.value, "unit": m.unit}
                            for m in output.critical_metrics
                        },
                        "situation": output.situation_report,
                        "dashboard": output.json_dashboard,
                    }

                # Publish agent outputs
                for agent_id, output in phase_outputs.items():
                    await self._publish_event(patient_id, "agent_output", {
                        "agentId": agent_id,
                        "output": output.model_dump(),
                    })

                    # Check for alerts
                    if output.alert_level in (AlertPriority.CRITICAL, AlertPriority.HIGH):
                        await self._publish_event(patient_id, "alert", {
                            "alert": {
                                "id": f"alert_{agent_id}_{int(datetime.now(timezone.utc).timestamp())}",
                                "priority": output.alert_level.value,
                                "source": agent_id,
                                "message": output.situation_report,
                                "timestamp": datetime.now(timezone.utc).isoformat(),
                                "acknowledged": False,
                            }
                        })

                # Human checkpoint
                if phase.human_checkpoint:
                    needs_human = any(
                        o.human_review_required
                        for o in phase_outputs.values()
                    )
                    if needs_human:
                        self.logger.warning(
                            "Human review required — pipeline paused",
                            phase=phase.name,
                        )

                        # Find the agent that triggered the review
                        review_output = next(
                            o for o in phase_outputs.values()
                            if o.human_review_required
                        )

                        await self._publish_event(
                            patient_id,
                            "human_review_required",
                            {"details": review_output.human_review_details},
                        )

                        # Wait for human decision
                        decision = await self._wait_for_human_decision(
                            patient_id=patient_id,
                            review_details=review_output.human_review_details,
                            timeout_seconds=300,
                        )

                        if not decision.get("approved", False):
                            self.logger.info(
                                "Human rejected — pipeline adjusted",
                                phase=phase.name,
                                reason=decision.get("reason", "no reason"),
                            )
                            # Continue but flag in context
                            pipeline_context["human_override"] = decision

                self.logger.info(
                    "Phase complete",
                    phase=phase.name,
                    agents_completed=len(phase_outputs),
                )

        except PipelineError as e:
            self.logger.error("Pipeline error", error=str(e))
            await self._publish_event(patient_id, "pipeline_error", {
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat(),
            })
            raise

        except Exception as e:
            self.logger.error("Unexpected pipeline error", error=str(e), exc_info=True)
            await self._publish_event(patient_id, "pipeline_error", {
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat(),
            })
            raise

        finally:
            self._pipeline_running = False

        # Pipeline complete
        pipeline_end = datetime.now(timezone.utc)
        duration_ms = (pipeline_end - pipeline_start).total_seconds() * 1000

        final_output = self._build_final_output(all_outputs)
        await self._publish_event(patient_id, "pipeline_complete", {
            "finalOutput": final_output,
            "duration_ms": duration_ms,
            "agents_executed": len(all_outputs),
            "timestamp": pipeline_end.isoformat(),
        })

        self.logger.info(
            "Pipeline complete",
            patient_id=patient_id,
            duration_ms=round(duration_ms, 1),
            agents_executed=len(all_outputs),
        )

        return all_outputs

    async def _execute_phase(
        self,
        phase: PipelinePhase,
        patient_id: str,
        context: dict[str, Any],
        all_outputs: dict[str, AgentOutput],
    ) -> dict[str, AgentOutput]:
        """Execute all agents in a phase (parallel or sequential)."""
        outputs: dict[str, AgentOutput] = {}

        if phase.parallel:
            # Run agents in parallel
            tasks = {}
            for agent_id in phase.agents:
                agent = self.agents.get(agent_id)
                if agent is None:
                    self.logger.warning(
                        "Agent not found, skipping",
                        agent_id=agent_id,
                    )
                    continue

                agent_inputs = self._prepare_agent_inputs(
                    agent_id, context, all_outputs
                )
                tasks[agent_id] = asyncio.create_task(
                    self._execute_agent_with_timeout(
                        agent, agent_inputs, phase.timeout_seconds
                    )
                )

            # Wait for all
            if tasks:
                results = await asyncio.gather(
                    *tasks.values(),
                    return_exceptions=True,
                )
                for agent_id, result in zip(tasks.keys(), results):
                    if isinstance(result, Exception):
                        self.logger.error(
                            "Agent failed in parallel phase",
                            agent_id=agent_id,
                            error=str(result),
                        )
                        outputs[agent_id] = self._create_fallback_output(
                            agent_id, str(result)
                        )
                    else:
                        outputs[agent_id] = result
        else:
            # Run agents sequentially
            for agent_id in phase.agents:
                agent = self.agents.get(agent_id)
                if agent is None:
                    continue

                agent_inputs = self._prepare_agent_inputs(
                    agent_id, context, all_outputs
                )
                try:
                    output = await self._execute_agent_with_timeout(
                        agent, agent_inputs, phase.timeout_seconds
                    )
                    outputs[agent_id] = output
                    # Update context for next agent in sequence
                    context[agent_id] = {
                        "narrative": output.narrative_summary,
                        "metrics": {
                            m.name: {"value": m.value, "unit": m.unit}
                            for m in output.critical_metrics
                        },
                    }
                except Exception as e:
                    self.logger.error(
                        "Agent failed in sequential phase",
                        agent_id=agent_id,
                        error=str(e),
                    )
                    outputs[agent_id] = self._create_fallback_output(
                        agent_id, str(e)
                    )

        return outputs

    async def _execute_agent_with_timeout(
        self,
        agent: BaseObstetricAgent,
        inputs: dict[str, Any],
        timeout_seconds: int,
    ) -> AgentOutput:
        """Execute an agent with timeout."""
        if timeout_seconds <= 0:
            return await agent.execute(inputs)

        try:
            return await asyncio.wait_for(
                agent.execute(inputs),
                timeout=timeout_seconds,
            )
        except asyncio.TimeoutError:
            self.logger.warning(
                "Agent timed out",
                agent_id=agent.agent_id,
                timeout_seconds=timeout_seconds,
            )
            return self._create_fallback_output(
                agent.agent_id,
                f"Timeout after {timeout_seconds}s",
            )

    def _prepare_agent_inputs(
        self,
        agent_id: str,
        context: dict[str, Any],
        all_outputs: dict[str, AgentOutput],
    ) -> dict[str, Any]:
        """Prepare inputs for a specific agent from pipeline context."""
        # Each agent receives the full context + specific upstream outputs
        inputs = {
            "context": context,
            "upstream_outputs": {
                aid: {
                    "narrative": o.narrative_summary,
                    "metrics": {
                        m.name: {"value": m.value, "unit": m.unit, "ci": m.confidence_interval}
                        for m in o.critical_metrics
                    },
                    "situation_report": o.situation_report,
                    "dashboard": o.json_dashboard,
                    "status": o.status.value,
                }
                for aid, o in all_outputs.items()
            },
        }
        if "initial_data" in context:
            inputs["patient_data"] = context["initial_data"]
        return inputs

    async def _wait_for_human_decision(
        self,
        patient_id: str,
        review_details: Optional[dict],
        timeout_seconds: int = 300,
    ) -> dict[str, Any]:
        """Wait for human decision via NATS subscription."""
        subject = f"human-review.{patient_id}.decision"
        
        try:
            sub = await self.nc.subscribe(subject)
            msg = await asyncio.wait_for(
                sub.next_msg(timeout=timeout_seconds),
                timeout=timeout_seconds + 5,
            )
            await sub.unsubscribe()
            
            import json
            return json.loads(msg.data.decode())
            
        except (asyncio.TimeoutError, Exception) as e:
            self.logger.warning(
                "Human review timeout — escalating",
                patient_id=patient_id,
                timeout_seconds=timeout_seconds,
            )
            # On timeout, escalate but don't block pipeline
            await self._publish_event(patient_id, "alert", {
                "alert": {
                    "id": f"escalation_{int(datetime.now(timezone.utc).timestamp())}",
                    "priority": "CRITICAL",
                    "source": "PipelineOrchestrator",
                    "message": (
                        "ESCALATION: Validation humaine non reçue dans le délai. "
                        "Pipeline en attente. Contact chef de garde immédiat."
                    ),
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "acknowledged": False,
                }
            })
            # Return a cautious default
            return {
                "approved": True,
                "reason": "auto_escalated_timeout",
                "notes": "Timeout — auto-approved with escalation alert",
            }

    async def _publish_event(
        self, patient_id: str, event_type: str, data: dict
    ):
        """Publish event to NATS JetStream for real-time frontend updates."""
        if self.js:
            import json
            subject = f"pipeline.{patient_id}.{event_type}"
            payload = json.dumps({
                "type": event_type,
                "patient_id": patient_id,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                **data,
            }).encode()
            try:
                await self.js.publish(subject, payload)
            except Exception as e:
                self.logger.error(
                    "Failed to publish event",
                    subject=subject,
                    error=str(e),
                )

    def _build_final_output(
        self, all_outputs: dict[str, AgentOutput]
    ) -> dict[str, Any]:
        """Build the final aggregated output for the frontend."""
        return {
            "aggregatedMetrics": {
                agent_id: {
                    "status": output.status.value,
                    "metrics": {
                        m.name: {
                            "value": m.value,
                            "unit": m.unit,
                            "ci": m.confidence_interval,
                            "provenance": m.provenance,
                        }
                        for m in output.critical_metrics
                    },
                    "alertLevel": output.alert_level.value if output.alert_level else None,
                    "situationReport": output.situation_report,
                }
                for agent_id, output in all_outputs.items()
            },
            "riskFlags": [
                {
                    "priority": output.alert_level.value,
                    "flag": output.situation_report,
                    "source": agent_id,
                }
                for agent_id, output in all_outputs.items()
                if output.alert_level in (AlertPriority.CRITICAL, AlertPriority.HIGH)
            ],
            "clinicalNarrative": all_outputs.get(
                "ClinicalNarrativeAgent", AgentOutput(
                    agent_id="missing",
                    agent_name="missing",
                    narrative_summary="Rapport non disponible",
                )
            ).narrative_summary,
        }

    def _create_fallback_output(self, agent_id: str, error: str) -> AgentOutput:
        """Create a safe fallback output when an agent fails."""
        return AgentOutput(
            agent_id=agent_id,
            agent_name=agent_id,
            status=AgentStatus.ERROR,
            narrative_summary=(
                f"⚠️ L'agent {agent_id} n'a pas pu fournir de résultat "
                f"({error}). Veuillez vous fier au jugement clinique. "
                f"Les données de cet agent ne sont pas disponibles pour "
                f"cette itération du pipeline."
            ),
            situation_report=f"AGENT INDISPONIBLE: {agent_id} — {error}",
            alert_level=AlertPriority.MEDIUM,
        )

    def _evaluate_phase_trigger(
        self,
        condition: Optional[str],
        options: dict,
        outputs: dict[str, AgentOutput],
    ) -> bool:
        """Evaluate if an optional phase should run."""
        if not condition:
            return True
        if "manual_request" in condition and options.get("includeQuantum"):
            return True
        if "complex_case" in condition:
            # Check if any agent flagged high/critical risk
            for output in outputs.values():
                if output.alert_level in (AlertPriority.CRITICAL, AlertPriority.HIGH):
                    return True
        return False


class PipelineError(Exception):
    """Pipeline execution error."""
    pass
pythonCopy# ============================================================================
# backend/main.py — Point d'entrée FastAPI
# ============================================================================

import os
from contextlib import asynccontextmanager

import structlog
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Any, Optional

from agents.llm_router import LLMRouter
from orchestrator.pipeline import ObstetricPipelineOrchestrator

logger = structlog.get_logger()


# ---- Lifespan ----
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application startup and shutdown."""
    logger.info("Starting Obstetric AI System...")
    
    # Initialize LLM Router
    app.state.llm_router = LLMRouter(
        anthropic_api_key=os.environ["ANTHROPIC_API_KEY"],
        openai_api_key=os.environ["OPENAI_API_KEY"],
        mistral_api_key=os.environ.get("MISTRAL_API_KEY"),
        ibm_api_key=os.environ.get("IBM_API_KEY"),
        ibm_endpoint=os.environ.get("IBM_ENDPOINT"),
    )
    
    # Initialize Pipeline Orchestrator
    # (agents would be registered here in production)
    app.state.orchestrator = ObstetricPipelineOrchestrator(
        agents={},  # Populated during agent registration
        nats_url=os.environ.get("NATS_URL", "nats://localhost:4222"),
    )
    await app.state.orchestrator.connect()
    
    logger.info("Obstetric AI System ready")
    yield
    
    # Shutdown
    await app.state.orchestrator.disconnect()
    logger.info("Obstetric AI System shutdown complete")


# ---- App ----
app = FastAPI(
    title="Obstetric Intelligence System API",
    description=(
        "API pour le système agentique d'intelligence obstétricale. "
        "Dispositif médical classe IIb — EU AI Act haut risque."
    ),
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/api/docs",
    redoc_url="/api/redoc",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Frontend dev
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ---- Request/Response Models ----
class PipelineExecuteRequest(BaseModel):
    patient_id: str = Field(..., description="FHIR Patient ID")
    options: Optional[dict[str, Any]] = Field(
        default_factory=dict,
        description="Pipeline options (includeQuantum, forceRefresh, etc.)",
    )


class HumanReviewRequest(BaseModel):
    review_id: str
    patient_id: str
    decision: dict[str, Any] = Field(
        ...,
        description="Decision: {approved: bool, reason?: str, notes?: str}",
    )


# ---- REST Endpoints ----
@app.post("/api/v2/pipeline/execute")
async def execute_pipeline(request: PipelineExecuteRequest):
    """Trigger full agent pipeline for a patient."""
    try:
        # In production, fetch initial data from FHIR server
        initial_data = {}  # Would be populated from FHIR
        
        outputs = await app.state.orchestrator.execute_pipeline(
            patient_id=request.patient_id,
            initial_data=initial_data,
            options=request.options,
        )
        
        return {
            "status": "complete",
            "patient_id": request.patient_id,
            "agents_executed": len(outputs),
            "outputs": {
                aid: o.model_dump() for aid, o in outputs.items()
            },
        }
    except Exception as e:
        logger.error("Pipeline execution failed", error=str(e), exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v2/pipeline/human-review")
async def submit_human_review(request: HumanReviewRequest):
    """Submit human review decision for a paused pipeline."""
    try:
        import json
        nc = app.state.orchestrator.nc
        subject = f"human-review.{request.patient_id}.decision"
        await nc.publish(
            subject,
            json.dumps(request.decision).encode(),
        )
        return {"status": "decision_submitted", "review_id": request.review_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v2/health")
async def health_check():
    """System health check."""
    return {
        "status": "healthy",
        "system": "obstetric-fetal-intelligence-system",
        "version": "2.0.0",
        "llm_metrics": app.state.llm_router.get_metrics(),
    }


# ---- WebSocket Endpoints ----
@app.websocket("/ws/v2/pipeline/{patient_id}")
async def pipeline_websocket(websocket: WebSocket, patient_id: str):
    """Real-time pipeline updates via WebSocket."""
    await websocket.accept()
    logger.info("WebSocket connected", patient_id=patient_id)

    nc = app.state.orchestrator.nc
    subject = f"pipeline.{patient_id}.>"

    try:
        sub = await nc.subscribe(subject)
        
        while True:
            try:
                msg = await sub.next_msg(timeout=30.0)
                await websocket.send_text(msg.data.decode())
            except TimeoutError:
                # Send keepalive
                await websocket.send_json({"type": "keepalive"})
                
    except WebSocketDisconnect:
        logger.info("WebSocket disconnected", patient_id=patient_id)
    except Exception as e:
        logger.error("WebSocket error", error=str(e))
    finally:
        try:
            await sub.unsubscribe()
        except Exception:
            pass


@app.websocket("/ws/v2/ctg-stream/{patient_id}")
async def ctg_stream_websocket(websocket: WebSocket, patient_id: str):
    """Real-time CTG data streaming via WebSocket."""
    await websocket.accept()
    logger.info("CTG stream connected", patient_id=patient_id)

    nc = app.state.orchestrator.nc
    subject = f"agent.{patient_id}.ctg_data"

    try:
        sub = await nc.subscribe(subject)
        
        while True:
            try:
                msg = await sub.next_msg(timeout=5.0)
                await websocket.send_bytes(msg.data)
            except TimeoutError:
                await websocket.send_json({"type": "ctg_keepalive"})

    except WebSocketDisconnect:
        logger.info("CTG stream disconnected", patient_id=patient_id)
    except Exception as e:
        logger.error("CTG stream error", error=str(e))
    finally:
        try:
            await sub.unsubscribe()
        except Exception:
            pass


# ---- Agent-specific REST endpoints ----
@app.post("/api/v2/ctg-monitor")
async def ctg_monitor_endpoint(data: dict[str, Any]):
    """Direct CTG analysis endpoint."""
    agent = app.state.orchestrator.agents.get("CTGMonitorAgent")
    if not agent:
        raise HTTPException(status_code=503, detail="CTG Monitor Agent not available")
    output = await agent.execute(data)
    return output.model_dump()


@app.post("/api/v2/bishop-partogram")
async def bishop_partogram_endpoint(data: dict[str, Any]):
    """Direct Bishop/Partogram analysis endpoint."""
    agent = app.state.orchestrator.agents.get("BishopPartogramAgent")
    if not agent:
        raise HTTPException(status_code=503, detail="Bishop Agent not available")
    output = await agent.execute(data)
    return output.model_dump()


@app.post("/api/v2/rciu-risk")
async def rciu_risk_endpoint(data: dict[str, Any]):
    """Direct RCIU risk assessment endpoint."""
    agent = app.state.orchestrator.agents.get("RCIURiskAgent")
    if not agent:
        raise HTTPException(status_code=503, detail="RCIU Agent not available")
    output = await agent.execute(data)
    return output.model_dump()


@app.post("/api/v2/apgar-transition")
async def apgar_transition_endpoint(data: dict[str, Any]):
    """Direct Apgar assessment endpoint."""
    agent = app.state.orchestrator.agents.get("ApgarTransitionAgent")
    if not agent:
        raise HTTPException(status_code=503, detail="Apgar Agent not available")
    output = await agent.execute(data)
    return output.model_dump()

5. DOCKER COMPOSE — Environnement de Développement
yamlCopy# ============================================================================
# docker-compose.dev.yml — Environnement de Développement Complet
# ============================================================================

version: "3.9"

services:
  # --- Backend API ---
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - IBM_API_KEY=${IBM_API_KEY}
      - IBM_ENDPOINT=${IBM_ENDPOINT}
      - NATS_URL=nats://nats:4222
      - FHIR_BASE_URL=http://fhir-server:8080/fhir
      - DATABASE_URL=postgresql://obsai:obsai_secure@postgres:5432/obstetric_ai
      - REDIS_URL=redis://redis:6379/0
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - LOG_LEVEL=DEBUG
    depends_on:
      - postgres
      - redis
      - nats
      - fhir-server
    volumes:
      - ./backend:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # --- Frontend ---
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_BASE=http://localhost:8000
      - NEXT_PUBLIC_WS_BASE=ws://localhost:8000
      - NEXT_PUBLIC_FHIR_BASE=http://localhost:8080/fhir
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: pnpm dev

  # --- PostgreSQL ---
  postgres:
    image: pgvector/pgvector:pg16
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: obstetric_ai
      POSTGRES_USER: obsai
      POSTGRES_PASSWORD: obsai_secure
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/db/init.sql:/docker-entrypoint-initdb.d/init.sql

  # --- Redis ---
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # --- NATS JetStream ---
  nats:
    image: nats:2.10-alpine
    ports:
      - "4222:4222"
      - "8222:8222"  # Monitoring
    command: "--jetstream --store_dir /data/jetstream"
    volumes:
      - nats_data:/data

  # --- HAPI FHIR Server ---
  fhir-server:
    image: hapiproject/hapi:latest
    ports:
      - "8080:8080"
    environment:
      - hapi.fhir.default_encoding=json
      - hapi.fhir.fhir_version=R4
      - hapi.fhir.subscription.resthook_enabled=true
      - hapi.fhir.subscription.websocket_enabled=true
      - spring.datasource.url=jdbc:postgresql://postgres:5432/obstetric_ai
      - spring.datasource.username=obsai
      - spring.datasource.password=obsai_secure
      - spring.datasource.driverClassName=org.postgresql.Driver
    depends_on:
      - postgres

  # --- MLflow ---
  mlflow:
    image: ghcr.io/mlflow/mlflow:2.16.0
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://obsai:obsai_secure@postgres:5432/mlflow
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlflow-artifacts/
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    depends_on:
      - postgres
      - minio
    command: >
      mlflow server 
      --host 0.0.0.0 
      --port 5000
      --backend-store-uri postgresql://obsai:obsai_secure@postgres:5432/mlflow
      --default-artifact-root s3://mlflow-artifacts/

  # --- MinIO (S3 compatible object storage) ---
  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"

  # --- Grafana (Monitoring) ---
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources

  # --- Prometheus ---
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

volumes:
  postgres_data:
  redis_data:
  nats_data:
  minio_data:
  grafana_data:
  prometheus_data:
Copy# ============================================================================
# .env.example — Variables d'environnement
# ============================================================================

# LLM API Keys
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx
MISTRAL_API_KEY=xxxxxxxxxxxxxxxxxxxxx
IBM_API_KEY=xxxxxxxxxxxxxxxxxxxxx
IBM_ENDPOINT=https://us-south.ml.cloud.ibm.com

# Database
DATABASE_URL=postgresql://obsai:obsai_secure@localhost:5432/obstetric_ai

# FHIR
FHIR_BASE_URL=http://localhost:8080/fhir

# NATS
NATS_URL=nats://localhost:4222

# Redis
REDIS_URL=redis://localhost:6379/0

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000

# Frontend
NEXT_PUBLIC_API_BASE=http://localhost:8000
NEXT_PUBLIC_WS_BASE=ws://localhost:8000
NEXT_PUBLIC_FHIR_BASE=http://localhost:8080/fhir

6. PACKAGE.JSON FRONTEND
jsonCopy{
  "name": "obstetric-ai-dashboard",
  "version": "2.0.0",
  "private": true,
  "description": "Dashboard d'Intelligence Obstétricale — Système Agentique Santé Fœtale",
  "scripts": {
    "dev": "next dev --port 3000",
    "build": "next build",
    "start": "next start",
    "lint": "next lint && tsc --noEmit",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "test:e2e": "playwright test",
    "test:e2e:ui": "playwright test --ui"
  },
  "dependencies": {
    "next": "^15.0.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "recharts": "^2.12.0",
    "zustand": "^4.5.0",
    "@tanstack/react-query": "^5.50.0",
    "date-fns": "^3.6.0",
    "clsx": "^2.1.0",
    "tailwind-merge": "^2.3.0"
  },
  "devDependencies": {
    "typescript": "^5.5.0",
    "@types/react": "^19.0.0",
    "@types/node": "^22.0.0",
    "tailwindcss": "^3.4.0",
    "postcss": "^8.4.0",
    "autoprefixer": "^10.4.0",
    "vitest": "^2.0.0",
    "@testing-library/react": "^16.0.0",
    "@testing-library/jest-dom": "^6.4.0",
    "@playwright/test": "^1.45.0",
    "eslint": "^9.0.0",
    "eslint-config-next": "^15.0.0"
  }
}

7. RÉSUMÉ DES INSTRUCTIONS CURSOR
Pour démarrer le développement dans Cursor :
Copy1. OUVRIR LE PROJET:
   cursor obstetric-ai-dashboard/

2. LE FICHIER .cursor/rules/obstetric-ai.mdc sera chargé automatiquement
   et guidera toutes les suggestions de Cursor.

3. ORDRE DE DÉVELOPPEMENT RECOMMANDÉ:

   Phase 1 — Infrastructure (Semaine 1-2):
   ├── docker-compose.dev.yml (services de base)
   ├── backend/main.py (FastAPI skeleton)
   ├── backend/agents/base.py (BaseObstetricAgent)
   ├── backend/agents/llm_router.py (Multi-model router)
   └── backend/orchestrator/pipeline.py (Pipeline orchestrator)

   Phase 2 — Agents Core (Semaine 3-5):
   ├── backend/agents/streaming_gateway.py
   ├── backend/agents/ctg_monitor.py (+ ctg_classifier ML model)
   ├── backend/agents/bishop_partogram.py
   ├── backend/agents/rciu_risk.py (+ rciu_detector ML model)
   ├── backend/agents/preeclampsia_risk.py
   ├── backend/agents/therapeutic_monitoring.py
   └── backend/agents/mother_baby_risk.py (+ cesarean_risk ML model)

   Phase 3 — Agents Avancés (Semaine 6-7):
   ├── backend/agents/research_polygraph.py
   ├── backend/agents/symbolic_reasoning.py
   ├── backend/agents/quantum_optimizer.py
   ├── backend/agents/coordination_compliance.py
   ├── backend/agents/clinical_narrative.py
   └── backend/agents/user_engagement.py

   Phase 4 — Frontend (Semaine 8-10):
   ├── src/app/ (Pages Next.js)
   ├── src/components/ (Tous les composants React)
   ├── src/hooks/ (Hooks custom WebSocket, FHIR, Pipeline)
   ├── src/lib/ (Clients FHIR, agent, WebSocket)
   └── src/types/ (Types TypeScript)

   Phase 5 — ML Models (Semaine 11-13):
   ├── ml/models/ctg_classifier/ (train + serve)
   ├── ml/models/cesarean_risk/ (train + serve)
   ├── ml/models/apgar_predictor/ (train + serve)
   ├── ml/models/rciu_detector/ (train + serve)
   └── ml/models/preeclampsia_risk/ (train + serve)

   Phase 6 — Tests & Conformité (Semaine 14-16):
   ├── tests/unit/ (pytest + vitest)
   ├── tests/integration/ (pipeline E2E)
   ├── tests/e2e/ (Playwright)
   ├── docs/clinical-validation/
   └── docs/regulatory/ (EU AI Act, MDR documentation)

4. COMMANDES CURSOR UTILES:
   - "Implémente l'agent CTGMonitorAgent selon le YAML system"
   - "Crée le composant CTGChart avec streaming temps réel"
   - "Ajoute le human-in-the-loop pour la classification pathologique"
   - "Implémente le routage multi-modèles LLM avec fallback"
   - "Crée les tests pour les bornes physiologiques du CTG"

5. RAPPEL: Chaque PR doit passer:
   ✅ Tests unitaires (>90% coverage agents)
   ✅ Type-checking (mypy + TypeScript strict)
   ✅ Linting (ruff + eslint)
   ✅ Security scan (trivy/snyk)
   ✅ FHIR schema validation
   ✅ Audit trail integrity check
   Fonctionnalités Révolutionnaires vers l'Intelligence Artificielle Médicale Générale (IAMG) en Obstétrique
Vision : Du CDS Spécialisé vers l'Intelligence Obstétricale Générale

1. CONSCIENCE SITUATIONNELLE FŒTALE CONTINUE (Fetal Digital Twin)
Le concept : Un jumeau numérique vivant du fœtus
yamlCopy# ============================================================================
# FONCTIONNALITÉ 1: FETAL DIGITAL TWIN — Jumeau Numérique Fœtal
# ============================================================================

feature:
  id: "fetal-digital-twin"
  name: "Conscience Situationnelle Fœtale Continue"
  maturity: "breakthrough"
  timeline: "18-36 months"
  
  description: >
    Contrairement aux systèmes actuels qui analysent des snapshots 
    (un tracé CTG, une écho, un labo), le Fetal Digital Twin maintient
    un modèle physiologique CONTINU et PRÉDICTIF du fœtus en temps réel.
    
    Il ne se contente pas de classifier "Normal/Pathologique" — il SIMULE
    l'état métabolique complet du fœtus seconde par seconde :
    - pH sanguin fœtal estimé en continu (sans prélèvement invasif)
    - Réserve en oxygène cérébrale (oxygénation tissulaire prédite)
    - État du système nerveux autonome fœtal (maturation neurologique)
    - Réponse au stress (axe hypothalamo-hypophyso-surrénalien fœtal)
    - Trajectoire de croissance dynamique (pas juste un percentile statique)
    
    Le jumeau numérique APPREND du fœtus spécifique au fil de la grossesse,
    calibrant ses modèles sur les données individuelles, et devient de plus
    en plus précis à mesure que la grossesse avance.

  architecture:
    core_model:
      type: "Physics-Informed Neural Network (PINN) + Neural ODE"
      description: >
        Combine les équations différentielles de la physiologie fœtale
        (modèles de Gunn, Bennet, van den Berg) avec l'apprentissage
        profond. Le réseau apprend à résoudre les EDOs de la physiologie
        cardiovasculaire fœtale tout en s'ajustant aux données réelles.
      
      physiological_equations:
        - name: "Modèle cardiovasculaire fœtal"
          description: >
            Système d'EDOs décrivant la pression artérielle fœtale,
            le débit cardiaque, la résistance vasculaire placentaire,
            et les échanges gazeux O2/CO2 transplacentaires.
          variables:
            - "P_a(t): Pression artérielle fœtale"
            - "Q_c(t): Débit cardiaque fœtal"
            - "R_p(t): Résistance placentaire"
            - "pO2_f(t): Pression partielle O2 fœtale"
            - "pH_f(t): pH sanguin fœtal"
            - "BE(t): Base excess fœtal"
            - "Lactate_f(t): Lactates fœtaux"

        - name: "Modèle neuro-autonome fœtal"
          description: >
            Interaction sympathique/parasympathique contrôlant la
            variabilité du rythme cardiaque. Permet d'inférer la
            maturation du SNA à partir de la micro-variabilité FHR.
          variables:
            - "SNS(t): Tonus sympathique"
            - "PNS(t): Tonus parasympathique"
            - "BRS(t): Sensibilité du baroréflexe"

      neural_ode_component:
        framework: "torchdiffeq"
        architecture: >
          Le Neural ODE apprend les termes résiduels (non capturés 
          par la physique connue) de la dynamique fœtale. Il permet
          au modèle de s'adapter aux particularités de CHAQUE fœtus.
        training: "Online learning avec données patient en continu"

    state_estimation:
      method: "Ensemble Kalman Filter (EnKF) + Particle Filter"
      description: >
        Fusionner en temps réel les observations (FHR, variabilité,
        Doppler, mouvements fœtaux) avec les prédictions du modèle
        pour estimer l'état caché (pH, pO2, état neurologique).
      update_frequency: "Chaque battement cardiaque (≈2-3 Hz)"
      uncertainty_quantification: "Distribution complète de l'état (pas juste un point)"

    calibration:
      method: "Bayesian Personalization"
      description: >
        Les paramètres du modèle (résistance placentaire, sensibilité
        du baroréflexe, etc.) sont calibrés pour CHAQUE fœtus à partir
        des données longitudinales de la grossesse. Un fœtus avec un
        RCIU aura un profil paramétrique différent d'un fœtus eutrophe.
      prior: "Population-level priors from 100,000+ pregnancies"
      update: "Sequential Bayesian update at each visit"

  capabilities:
    continuous_ph_estimation:
      description: >
        Estimation du pH fœtal en CONTINU à partir du CTG seul,
        sans nécessiter de prélèvement au scalp. Le modèle utilise
        les patterns de variabilité et de décélérations pour inférer
        le pH avec une précision de ±0.05 unités.
      clinical_impact: >
        Réduit de 70% les prélèvements invasifs au scalp fœtal
        tout en maintenant la détection des acidoses. Permet une
        surveillance non-invasive continue de l'équilibre acido-basique.
      validation: "Prospective study needed (target: n=5000)"

    predictive_decompensation:
      description: >
        Le jumeau numérique ne se contente pas de détecter la détresse
        fœtale — il la PRÉDIT 20-45 minutes AVANT qu'elle ne devienne
        cliniquement apparente. En simulant la trajectoire physiologique,
        il identifie quand le fœtus approche de ses limites de compensation.
      mechanism: >
        Le modèle calcule en continu la "réserve d'adaptation" du fœtus :
        capacité restante à maintenir l'homéostasie face au stress.
        Quand cette réserve descend sous un seuil critique, l'alerte
        est émise AVANT la décompensation.
      clinical_impact: >
        Potentiel de réduire l'encéphalopathie hypoxique-ischémique 
        de 40-60% en permettant une extraction plus précoce.

    neurological_maturation_tracking:
      description: >
        Suivi en temps réel de la maturation du système nerveux autonome
        fœtal via l'analyse de la micro-variabilité FHR (domaine 
        fréquentiel : HF/LF ratio). Permet d'évaluer le bien-être
        neurologique et de détecter précocement les atteintes.
      biomarkers:
        - "Complexité du signal FHR (Approximate Entropy)"
        - "Analyse multifractale de la variabilité"
        - "Couplage cœur-mouvement fœtal"

    growth_trajectory_prediction:
      description: >
        Au lieu de percentiles statiques (mesurés une fois par mois),
        le jumeau numérique modélise la TRAJECTOIRE de croissance
        et prédit le poids à la naissance avec une précision de ±150g
        (vs ±300g pour les formules d'échographie standard).
      method: "Gaussian Process regression avec covariables maternelles"

  visualization:
    3d_fetal_avatar:
      description: >
        Représentation 3D du fœtus avec code couleur en temps réel:
        - Vert: physiologie normale
        - Jaune: stress modéré, compensation active
        - Orange: réserve limitée, surveillance rapprochée
        - Rouge: décompensation imminente, intervention urgente
        
        L'avatar montre visuellement l'oxygénation cérébrale estimée,
        les mouvements respiratoires, et l'activité cardiaque.
      technology: "Three.js / WebGPU avec shaders personnalisés"
      update_rate: "30 fps"

2. RAISONNEMENT CLINIQUE MULTI-MODAL ÉMERGENT
Le concept : Un LLM qui "voit, entend et raisonne" comme un obstétricien senior
yamlCopy# ============================================================================
# FONCTIONNALITÉ 2: MULTIMODAL CLINICAL REASONING ENGINE
# ============================================================================

feature:
  id: "multimodal-reasoning-engine"
  name: "Moteur de Raisonnement Clinique Multi-Modal Émergent"
  maturity: "near-breakthrough"
  timeline: "12-24 months"

  description: >
    Les systèmes actuels traitent les données en silos : un modèle pour
    le CTG, un autre pour l'échographie, un troisième pour les labos.
    
    Cette fonctionnalité crée un raisonnement UNIFIÉ qui fusionne 
    SIMULTANÉMENT toutes les modalités — exactement comme un obstétricien
    expert qui regarde le moniteur, palpe le ventre, lit les résultats,
    et intègre tout dans un jugement clinique holistique.
    
    La différence avec l'IA actuelle : le système ne fait pas juste
    de la "fusion de données" — il développe une COMPRÉHENSION
    CONTEXTUELLE de la situation clinique, avec capacité de raisonnement
    contrefactuel ("que se passerait-il si...").

  architecture:
    unified_embedding_space:
      description: >
        Toutes les modalités sont projetées dans un espace d'embedding
        commun via des encodeurs spécialisés, puis un Transformer
        cross-modal fusionne les représentations.
      
      encoders:
        ctg_encoder:
          type: "Temporal Transformer"
          input: "Signal CTG brut (4Hz, multi-canal)"
          output: "Embedding 512-dim par fenêtre de 30s"
          pretraining: "Self-supervised sur 500K heures de CTG"
          
        ultrasound_encoder:
          type: "Vision Transformer (ViT-L/14)"
          input: "Images/vidéos échographiques"
          output: "Embedding 768-dim par image"
          pretraining: "CLIP-style sur 2M images écho annotées"
          capabilities:
            - "Reconnaissance automatique des plans de coupe"
            - "Mesures biométriques automatiques"
            - "Détection d'anomalies morphologiques"
            - "Analyse Doppler spectrale automatique"
            
        text_encoder:
          type: "Medical BERT fine-tuned"
          input: "Notes cliniques, compte-rendus, anamnèse"
          output: "Embedding 768-dim"
          pretraining: "PubMedBERT + obstetric corpus (5M documents)"
          
        lab_encoder:
          type: "Tabular Transformer"
          input: "Résultats de laboratoire (séries temporelles)"
          output: "Embedding 256-dim"
          normalization: "Z-score par référence gestational-age-specific"
          
        voice_encoder:
          type: "Whisper-Medical fine-tuned"
          input: "Audio de la salle de naissance"
          output: "Transcription + embedding 512-dim"
          capabilities:
            - "Transcription des échanges médicaux en temps réel"
            - "Détection du stress dans la voix de l'équipe"
            - "Reconnaissance des cris du nouveau-né (Apgar audio)"
            - "Capture des instructions verbales (ordres d'urgence)"

      cross_modal_fusion:
        type: "Perceiver IO + Cross-Attention Transformer"
        description: >
          Architecture inspirée de Perceiver qui peut gérer un nombre
          arbitraire de modalités avec attention croisée. Les modalités
          s'informent mutuellement : le CTG influence l'interprétation
          de l'échographie et vice versa.
        attention_mechanism: "Multi-Head Cross-Modal Attention (24 heads)"
        latent_space: "256 latent tokens, 1024-dim"

  capabilities:
    holistic_situation_understanding:
      description: >
        Le système comprend la SITUATION globale, pas juste les données.
        Exemple : si le CTG montre des décélérations variables ET que
        l'échographie montre un oligoamnios ET que le dossier mentionne
        une rupture des membranes depuis 18h — le système comprend que
        c'est une compression du cordon sur fond d'oligoamnios post-RPM,
        et non une souffrance placentaire. La recommandation sera
        différente (amnio-infusion vs césarienne urgente).
      
    contrefactual_reasoning:
      description: >
        "Que se passerait-il si on administrait l'ocytocine maintenant ?"
        "Quel serait le risque si on attendait encore 2 heures ?"
        
        Le système peut simuler des scénarios cliniques hypothétiques
        en utilisant son modèle interne de la physiologie. Il ne prédit
        pas juste le risque ACTUEL mais évalue l'impact de chaque
        DÉCISION potentielle.
      
      implementation:
        method: "Causal Inference + Structural Causal Models"
        framework: "DoWhy + EconML"
        training: "Observational data + natural experiments from clinical practice"
      
      clinical_examples:
        - scenario: "Impact de l'administration d'ocytocine"
          query: "Si on augmente l'ocytocine de 2 mUI/min, quelle est la probabilité que le travail progresse vs hyperstimulation ?"
          output: >
            Simulation sur 10000 trajectoires:
            - 62% progression satisfaisante (dilatation +1cm en 2h)
            - 23% pas d'effet significatif
            - 12% hypercinésie utérine (>5 ctx/10min)
            - 3% détresse fœtale nécessitant arrêt
            Recommandation : augmentation raisonnable avec monitoring renforcé.
            [Réf: Wei et al., 2023, Cochrane; Modèle causal v2.1]

        - scenario: "Timing de la césarienne"
          query: "Quel est le moment optimal pour décider d'une césarienne ?"
          output: >
            Analyse coût-bénéfice temporelle:
            - Maintenant: 95% succès chirurgical, Apgar estimé 8
            - Dans 1h: 88% succès, Apgar estimé 7 (si évolution défavorable)
            - Dans 2h: 75% succès, risque Apgar <5 = 15%
            Fenêtre optimale: 30-60 minutes. Au-delà, risque exponentiel.

    emergent_pattern_recognition:
      description: >
        Le système détecte des patterns JAMAIS DÉCRITS dans la littérature
        en combinant des signaux faibles de multiples modalités.
        
        Exemple réel potentiel : une combinaison subtile de
        micro-variabilité FHR + ratio cérébro-placentaire borderline +
        légère élévation des transaminases maternelles pourrait prédire
        une décompensation 48h avant les signes cliniques — un pattern
        trop complexe pour être détecté par un humain ou un algorithme
        classique, mais identifiable par le modèle multi-modal entraîné
        sur des millions de grossesses.
      
      implementation:
        method: "Contrastive Learning + Anomaly Detection"
        novelty_detection: >
          Le système maintient un "modèle du normal" et détecte les
          déviations statistiquement significatives, même si elles
          ne correspondent à aucune pathologie connue. Il les signale
          comme "pattern inhabituel méritant attention" plutôt que
          de forcer un diagnostic.
        
        discovery_pipeline:
          - step: "Détection de pattern inconnu"
          - step: "Vérification que ce n'est pas un artefact"
          - step: "Recherche dans la littérature de patterns similaires"
          - step: "Si nouveau : stockage pour analyse rétrospective"
          - step: "Si récurrent et corrélé à un outcome : publication"

    clinical_voice_assistant:
      description: >
        L'obstétricien parle au système pendant l'accouchement, les
        mains occupées. Le système comprend le contexte, répond
        vocalement, et met à jour son analyse en temps réel.
        
        "Dis-moi comment va le bébé" → résumé vocal de 15 secondes
        "Compare avec les dernières 30 minutes" → analyse de tendance
        "Prépare le rapport pour la mère" → génération adaptée
      
      technology:
        stt: "Whisper-v4 fine-tuned medical French"
        tts: "XTTS-v2 voice-cloned to clinical tone"
        nlu: "Claude Opus 4 with clinical context"
        response_latency: "< 2 seconds end-to-end"

3. MÉMOIRE OBSTÉTRICALE COLLECTIVE ET APPRENTISSAGE FÉDÉRÉ
Le concept : L'IA qui apprend de chaque accouchement de chaque hôpital
yamlCopy# ============================================================================
# FONCTIONNALITÉ 3: COLLECTIVE OBSTETRIC MEMORY & FEDERATED LEARNING
# ============================================================================

feature:
  id: "collective-obstetric-memory"
  name: "Mémoire Obstétricale Collective et Apprentissage Fédéré"
  maturity: "advanced_research"
  timeline: "24-48 months"

  description: >
    Chaque accouchement est une leçon. Actuellement, cette leçon est
    perdue ou confinée à l'expérience d'un seul praticien. 
    
    La Mémoire Obstétricale Collective permet à l'IA d'APPRENDRE en
    continu de CHAQUE accouchement dans CHAQUE hôpital participant,
    sans jamais partager les données patient brutes (apprentissage fédéré).
    
    Après 1 million d'accouchements, le système aura "vu" plus de cas
    que n'importe quel obstétricien en 100 vies. Il développera une
    intuition clinique impossible à atteindre humainement.

  architecture:
    federated_learning:
      framework: "NVIDIA FLARE + Flower"
      topology: "Hierarchical (hospital → regional → national → international)"
      
      privacy_guarantees:
        differential_privacy:
          mechanism: "Rényi Differential Privacy (RDP)"
          epsilon: 1.0
          delta: 1e-5
          description: >
            Garantie mathématique : impossible de déterminer si un
            patient spécifique a contribué à l'entraînement.
        
        secure_aggregation:
          method: "Secure Multi-Party Computation (SMPC)"
          description: >
            Les gradients de chaque hôpital sont chiffrés avant
            agrégation. Le serveur central ne voit JAMAIS les gradients
            individuels, seulement le résultat agrégé.
        
        data_never_leaves:
          description: >
            Les données patient restent dans l'hôpital d'origine.
            Seuls les paramètres du modèle (gradients chiffrés) transitent.
            Conformité RGPD intégrale.

      training_protocol:
        frequency: "Hebdomadaire (asynchrone)"
        min_participants: 5
        convergence: "FedAvg avec momentum + adaptive learning rate"
        validation: "Holdout set local (jamais partagé)"

    case_based_reasoning:
      description: >
        En plus de l'apprentissage statistique, le système maintient
        une base de CAS indexés (anonymisés) avec leurs OUTCOMES.
        Pour un nouveau cas, il retrouve les cas les plus similaires
        et leurs dénouements, permettant un raisonnement par analogie.
      
      similarity_engine:
        method: "Hierarchical Navigable Small World (HNSW) graph"
        embedding: "Clinical case embedding (multi-modal)"
        dimensions: 1024
        index_size: "10M+ cases"
        search_latency: "< 50ms for top-100 neighbors"
      
      anonymization: >
        Chaque cas stocké est k-anonymisé (k=10) et l-diversifié.
        Les données temporelles sont perturbées (±48h).
        Les données géographiques sont supprimées.
        Impossible de remonter à un patient.
      
      clinical_example:
        query: >
          Patiente 34 ans, G1P0, 39+2 SA, diabète gestationnel
          sous insuline, Bishop 4, CTG suspect avec variabilité
          réduite, estimation pondérale 4200g (>95e percentile).
        
        retrieval: >
          847 cas similaires retrouvés (similarité > 0.85):
          - 52% ont eu un accouchement vaginal spontané
          - 28% césarienne pour travail stagnant
          - 12% césarienne pour macrosomie (dystocie épaules)
          - 8% extraction instrumentale
          
          Parmi les 12% avec dystocie des épaules:
          - Facteur le plus discriminant: EPF > 4500g ET Bishop < 5
          - 90% ont eu une issue favorable avec manœuvres
          - 10% ont nécessité des gestes d'urgence
          
          Recommandation data-driven: Étant donné l'EPF à 4200g (non
          >4500g) et le Bishop défavorable, proposer déclenchement avec
          monitoring renforcé. Risque dystocie épaules estimé à 8%
          (vs 3% population générale). Prévenir équipe néonat.
          
          [Basé sur 847 cas similaires, 23 hôpitaux, 2019-2025]

    temporal_knowledge_evolution:
      description: >
        Le système suit l'ÉVOLUTION des connaissances dans le temps.
        Il détecte quand une pratique devient obsolète ou quand une
        nouvelle preuve émerge, et ajuste ses recommandations.
      
      example: >
        "Note d'évolution des connaissances: La recommandation de
        monitoring continu pour toutes les grossesses à bas risque
        est remise en question par 3 essais récents (2024-2025).
        La pratique d'auscultation intermittente structurée montre
        des résultats équivalents avec moins d'interventions.
        Score de confiance de la recommandation 'monitoring continu':
        passé de 0.92 (2020) à 0.71 (2025). Signalé pour discussion."

    rare_event_detection:
      description: >
        Les événements rares (embolie amniotique, rupture utérine,
        inversion utérine) sont presque impossibles à prédire car
        trop peu fréquents dans un seul hôpital. Mais avec des
        données fédérées de 1000+ hôpitaux, le système accumule
        assez de cas pour développer des alertes précoces.
      
      approach: >
        Méta-apprentissage few-shot : le modèle apprend à reconnaître
        des pathologies rares à partir de quelques exemples seulement,
        en exploitant les représentations apprises sur les cas courants.
      
      target_events:
        - "Embolie amniotique (1/40,000) → pré-alerte 10 min avant"
        - "Rupture utérine (0.5-1%) → pré-alerte 30 min avant"
        - "HELLP syndrome → pré-alerte 24h avant"
        - "Chorioamnionite infraclinique → pré-alerte 6h avant"

4. PLANIFICATION THÉRAPEUTIQUE AUTONOME (Agentic Treatment Planning)
Le concept : L'IA qui élabore un plan de soins complet et adaptatif
yamlCopy# ============================================================================
# FONCTIONNALITÉ 4: AUTONOMOUS THERAPEUTIC PLANNING ENGINE
# ============================================================================

feature:
  id: "autonomous-treatment-planning"
  name: "Planification Thérapeutique Autonome et Adaptative"
  maturity: "advanced"
  timeline: "18-30 months"

  description: >
    Au-delà de l'alerte et de la suggestion ponctuelle, le système
    élabore un PLAN THÉRAPEUTIQUE COMPLET, personnalisé, multi-étapes,
    avec des points de décision conditionnels. Il anticipe les
    différentes trajectoires possibles et prépare des plans de
    contingence pour chacune.
    
    C'est la différence entre un GPS qui dit "tournez à droite" et
    un GPS qui planifie l'ensemble du trajet avec des alternatives
    en cas de bouchon.

  architecture:
    planning_engine:
      type: "Hierarchical Task Network (HTN) + Monte Carlo Tree Search"
      description: >
        Combine la planification hiérarchique (décomposition d'objectifs
        en sous-objectifs) avec l'exploration Monte Carlo (simulation
        de trajectoires possibles pour trouver le plan optimal).

      objective_hierarchy:
        primary: "Naissance d'un enfant en bonne santé (Apgar ≥ 7 à 5 min)"
        secondary:
          - "Accouchement vaginal si possible et sûr"
          - "Minimisation de la douleur maternelle"
          - "Minimisation des interventions invasives"
          - "Prévention des complications hémorragiques"
          - "Optimisation du lien mère-enfant précoce"
        constraints:
          - "Sécurité maternelle non négociable"
          - "Sécurité fœtale non négociable"
          - "Respect du consentement parental"
          - "Conformité aux guidelines applicables"

      decision_tree:
        description: >
          Arbre de décision dynamique qui s'adapte en temps réel.
          Chaque nœud est un point de décision clinique avec des
          branches conditionnelles basées sur l'évolution.

    adaptive_protocols:
      description: >
        Les protocoles ne sont pas statiques — ils s'adaptent en
        temps réel à la réponse de la patiente. Le système ajuste
        le plan à chaque nouvelle donnée.

      example_protocol:
        name: "Protocole adaptatif de gestion du travail stagnant"
        
        initial_assessment:
          conditions:
            - "Dilatation stagnante ≥ 2h en phase active"
            - "CTG Normal ou Suspect (pas Pathologique)"
            - "Pas de contre-indication à poursuite"
          
        plan_tree:
          step_1:
            action: "Amniotomie si membranes intactes"
            expected_response: "Progression dans 1-2h"
            monitor: "Dilatation + CTG toutes les 30 min"
            if_success: "step_monitoring"
            if_failure: "step_2"
            timeout_hours: 2
            
          step_2:
            action: "Ocytocine — protocole progressif"
            initial_dose: "2 mUI/min"
            increment: "+2 mUI/min toutes les 20 min"
            max_dose: "20 mUI/min (primipare), 12 mUI/min (multipare)"
            expected_response: "≥3 contractions/10min, durée 40-60s"
            monitor:
              - "CTG continu (alerte si tachysystole >5 ctx/10min)"
              - "Dilatation horaire"
              - "Bien-être maternel (douleur, TA)"
            
            adaptive_rules:
              - condition: "Tachysystole détectée"
                action: "Réduire ocytocine de 50%, position latérale gauche"
                reassess: "15 minutes"
              
              - condition: "Décélérations tardives apparues"
                action: "STOP ocytocine, O2 8L/min, DLG, remplissage"
                escalation: "Appel obstétricien immédiat"
                contingency: "Préparer bloc pour césarienne urgente"
              
              - condition: "Progression ≥1 cm/h reprise"
                action: "Maintenir dose, continuer monitoring"
              
              - condition: "Pas de progression après 4h ocytocine max"
                action: "Discussion césarienne pour dystocie"
                shared_decision: true
                present_to_patient:
                  benefits: "Extraction sûre, fin du travail prolongé"
                  risks: "Chirurgie, récupération plus longue, impact utérus futur"
                  alternatives: "Attente supplémentaire (risque infection augmente)"

            if_success: "step_monitoring"
            if_failure_4h: "step_3_cesarean_discussion"
            
          step_3_cesarean_discussion:
            action: "Préparer césarienne non urgente"
            pre_operative:
              - "Bilan pré-opératoire (NFS, coag, groupe)"
              - "Consultation anesthésie si pas encore faite"
              - "Consentement éclairé"
              - "Antibioprophylaxie (céfazoline 2g IV)"
              - "Prévention hypothermie nouveau-né"
            
            neonatal_preparation:
              - "Alerte pédiatre"
              - "Préparation table réanimation"
              - "Si RCIU: préparer transfert NICU"
            
            post_operative_plan:
              - "Peau-à-peau en salle d'opération si possible"
              - "Mise au sein dans l'heure"
              - "Thromboprophylaxie H6"
              - "Surveillance hémorragique renforcée 2h"

          step_monitoring:
            action: "Monitoring de phase terminale du travail"
            thresholds:
              - "Dilatation complète: préparation expulsion"
              - "Efforts expulsifs: max 30 min (primipare), 20 min (multi)"
              - "CTG pathologique: extraction instrumentale ou césarienne"

    pharmacological_optimizer:
      description: >
        Optimisation en temps réel de la pharmacologie obstétricale.
        Le système ajuste les doses en fonction de la pharmacocinétique
        individuelle (poids, fonction rénale, interactions) et de la
        réponse observée.
      
      medications_managed:
        - name: "Ocytocine"
          pk_model: "Two-compartment with receptor desensitization"
          optimization: "Bayesian adaptive dosing"
          
        - name: "Sulfate de magnésium"
          pk_model: "One-compartment renal clearance"
          therapeutic_window: "2.0-3.5 mmol/L"
          toxicity_monitoring: "Real-time magnesemia estimation from clinical signs"
          
        - name: "Nifédipine (tocolyse)"
          pk_model: "First-order absorption, hepatic metabolism"
          optimization: "Target trough concentration"
          
        - name: "Bétaméthasone (maturation pulmonaire)"
          timing_optimizer: >
            Calcul du timing optimal d'administration pour maximiser
            l'effet sur la maturation pulmonaire fœtale, en tenant
            compte du risque d'accouchement imminent.

    resource_orchestration:
      description: >
        Le système coordonne les ressources hospitalières en anticipation:
        réserve de bloc opératoire, disponibilité du pédiatre,
        préparation des produits sanguins, allocation de lit NICU.
      
      anticipatory_actions:
        - trigger: "Risque césarienne > 50%"
          action: "Réserver créneau bloc 'prioritaire' sous 2h"
          
        - trigger: "Risque HPP > 30%"
          action: "Commander culots globulaires compatibles + fibrinogène"
          
        - trigger: "Prématurité < 34 SA probable sous 48h"
          action: "Vérifier disponibilité lit NICU, alerter transfert si nécessaire"
          
        - trigger: "Nouveau-né RCIU sévère attendu"
          action: "Préparer incubateur, matériel réanimation, glycémie capillaire"

5. PRÉDICTION ÉPIGÉNÉTIQUE ET SANTÉ TRANSGÉNÉRATIONNELLE
Le concept : Prédire l'impact à long terme des conditions périnatales
yamlCopy# ============================================================================
# FONCTIONNALITÉ 5: EPIGENETIC & TRANSGENERATIONAL HEALTH PREDICTION
# ============================================================================

feature:
  id: "epigenetic-transgenerational"
  name: "Prédiction Épigénétique et Santé Transgénérationnelle"
  maturity: "frontier_research"
  timeline: "36-60 months"

  description: >
    Les conditions de la grossesse et de l'accouchement programment
    l'épigénome du nouveau-né, avec des conséquences sur sa santé
    TOUTE SA VIE et potentiellement celle de ses enfants.
    
    L'hypothèse de Barker (origines développementales des maladies)
    est maintenant bien documentée : un RCIU augmente le risque de
    diabète de type 2 de 50% à l'âge adulte. L'hypoxie périnatale
    modifie l'expression génique pour des décennies.
    
    Ce module prédit les conséquences LONG TERME des événements
    périnataux et recommande des interventions préventives pour
    atténuer les risques épigénétiques.

  architecture:
    epigenetic_risk_model:
      type: "Graph Neural Network (GNN) + Transformer"
      description: >
        Modèle qui prédit les modifications épigénétiques probables
        (méthylation de l'ADN, modifications des histones) à partir
        des conditions périnatales, et estime leur impact sur les
        trajectoires de santé futures.
      
      inputs:
        perinatal_conditions:
          - "RCIU severity and duration"
          - "Hypoxia duration and severity (estimated from CTG/pH)"
          - "Gestational age at birth"
          - "Mode of delivery"
          - "Maternal stress levels (cortisol proxy)"
          - "Maternal nutrition status"
          - "Medications administered (corticoids, etc.)"
          - "Inflammation markers (CRP, IL-6 if available)"
          
        genomic_context:
          - "Known maternal/fetal genotypes (if available)"
          - "Family history of metabolic/cardiovascular disease"
          - "Ethnic/population background (for epigenetic baselines)"
      
      outputs:
        epigenetic_risk_profile:
          - pathway: "Metabolic programming"
            risk_factors:
              - "Obesity childhood risk: +X% vs baseline"
              - "Type 2 diabetes adult risk: +X% vs baseline"
              - "Metabolic syndrome risk: +X% vs baseline"
            modifiable_factors:
              - "Breastfeeding (reduces risk by 15-30%)"
              - "Appropriate complementary feeding timing"
              - "Physical activity in childhood"
              
          - pathway: "Cardiovascular programming"
            risk_factors:
              - "Hypertension adult risk: +X%"
              - "Coronary heart disease risk: +X%"
            modifiable_factors:
              - "Salt restriction in infancy"
              - "Omega-3 supplementation"
              
          - pathway: "Neurodevelopmental programming"
            risk_factors:
              - "Cognitive development trajectory"
              - "ADHD risk: +X%"
              - "Anxiety/depression vulnerability: +X%"
            modifiable_factors:
              - "Kangaroo Mother Care (proven neuroprotective)"
              - "Enriched sensory environment"
              - "Secure attachment promotion"
              - "Early intervention if delay detected"

          - pathway: "Immune programming"
            risk_factors:
              - "Atopy/allergy risk: +X%"
              - "Autoimmune disease risk: +X%"
            modifiable_factors:
              - "Breastfeeding duration"
              - "Microbiome optimization (vaginal birth, skin-to-skin)"
              - "Appropriate antibiotic stewardship"

    intervention_recommendation_engine:
      description: >
        Pour chaque risque épigénétique identifié, le système génère
        des recommandations d'intervention PROACTIVE couvrant les
        premières années de vie, avec un calendrier personnalisé.
      
      output_example:
        title: "Plan de suivi épigénétique personnalisé"
        patient: "Nouveau-né, RCIU sévère (poids 1800g à 36 SA)"
        
        immediate_postnatal:
          - "KMC ≥ 8h/jour minimum 6 semaines [OMS 2022]"
          - "Allaitement maternel exclusif objectif 6 mois"
          - "Fer et vitamine D dès J15"
          - "Contact peau-à-peau maximal (neuroprotection)"
        
        first_year:
          - "Suivi croissance mensuel (courbe INTERGROWTH rattrapage)"
          - "Développement neuromoteur: évaluation trimestrielle"
          - "Introduction alimentation complémentaire à 6 mois (pas avant)"
          - "Limiter exposition antibiotiques (microbiome)"
        
        childhood_2_5_years:
          - "Dépistage surpoids/obésité annuel (IMC)"
          - "Glycémie à jeun si rattrapage pondéral excessif"
          - "Évaluation développementale standardisée (ASQ-3)"
          - "Encourager activité physique ≥ 60 min/jour"
        
        long_term_monitoring:
          - "Profil lipidique à 5 ans puis tous les 3 ans"
          - "Tension artérielle annuelle dès 3 ans"
          - "HbA1c si facteurs de risque à l'adolescence"
          - "Consultation génétique si antécédents familiaux"

    research_discovery:
      description: >
        Le système contribue activement à la recherche en identifiant
        des corrélations périnatal-outcome à long terme dans les données
        fédérées anonymisées. Potentiel de découvertes majeures en
        programmation fœtale.

6. INTELLIGENCE ÉMOTIONNELLE ET SOUTIEN PSYCHOLOGIQUE
Le concept : L'IA qui comprend et soutient l'expérience humaine de la naissance
yamlCopy# ============================================================================
# FONCTIONNALITÉ 6: EMOTIONAL INTELLIGENCE & PSYCHOLOGICAL SUPPORT
# ============================================================================

feature:
  id: "emotional-intelligence"
  name: "Intelligence Émotionnelle Obstétricale"
  maturity: "innovative"
  timeline: "12-24 months"

  description: >
    La naissance est l'événement le plus émotionnel d'une vie.
    La peur, l'anxiété, la douleur, l'espoir, l'amour — tout se
    mélange. Les systèmes IA actuels ignorent cette dimension.
    
    L'Intelligence Émotionnelle Obstétricale comprend l'état
    psychologique de la mère et de l'équipe soignante, adapte
    sa communication, détecte la détresse psychologique, et
    contribue à une expérience de naissance positive — tout en
    améliorant les outcomes cliniques (le stress maternel impacte
    directement la physiologie du travail et le bien-être fœtal).

  capabilities:
    maternal_stress_monitoring:
      description: >
        Détection en temps réel du stress maternel via des biomarqueurs
        non-invasifs et des signaux comportementaux.
      
      signals:
        physiological:
          - "Variabilité de la fréquence cardiaque maternelle (HRV)"
          - "Conductance cutanée (si capteur EDA disponible)"
          - "Pattern respiratoire"
          - "Tension artérielle réactive vs basale"
        behavioral:
          - "Analyse vocale (prosodie, fréquence fondamentale)"
          - "Expressions faciales (si caméra consentie)"
          - "Mouvements et agitation"
        contextual:
          - "Durée du travail (fatigue)"
          - "Score de douleur déclaré"
          - "Événements stressants récents (alarmes, complications)"
      
      stress_index:
        range: "0-10"
        impact_on_labor: >
          Un stress maternel élevé (index > 7) est associé à:
          - Augmentation du cortisol → vasoconstriction utérine
          - Diminution de l'ocytocine endogène → travail plus lent
          - Augmentation des catécholamines → décélérations FHR
          - Perception accrue de la douleur
          
          L'IA peut recommander des interventions non-pharmacologiques
          AVANT que le stress n'impacte le travail.

      interventions_suggested:
        - stress_level: "moderate (5-7)"
          suggestions:
            - "Proposition de repositionnement (ballon, déambulation)"
            - "Techniques de respiration guidée (audio)"
            - "Musique apaisante personnalisée"
            - "Massage si accompagnant disponible"
            - "Communication rassurante adaptée"
            
        - stress_level: "high (7-9)"
          suggestions:
            - "Évaluation de la douleur et ajustement analgésie"
            - "Présence continue de la sage-femme"
            - "Méditation/hypnose guidée (audio)"
            - "Information transparente sur la situation"
            
        - stress_level: "severe (9-10)"
          suggestions:
            - "Alerte sage-femme: soutien psychologique urgent"
            - "Évaluation pour anxiété/panique"
            - "Proposition de péridurale si non contre-indiquée"
            - "Si traumatisme en cours: protocole de soutien"

    birth_experience_optimization:
      description: >
        Le système optimise non seulement les outcomes cliniques
        mais aussi l'EXPÉRIENCE VÉCUE de la naissance — facteur
        majeur de santé mentale postnatale.
      
      birth_plan_integration:
        description: >
          Le plan de naissance des parents est intégré dans l'IA.
          Le système essaie de respecter les souhaits tout en
          maintenant la sécurité, et EXPLIQUE quand un écart
          est nécessaire.
        
        example: >
          Le couple souhaitait un accouchement sans péridurale.
          Le travail stagne et le stress maternel augmente.
          
          L'IA : "Je comprends votre souhait d'accoucher sans
          péridurale, et c'est un objectif que nous respectons.
          Cependant, votre niveau de stress actuel semble freiner
          les contractions. Voici quelques alternatives avant de
          reconsidérer la péridurale : [liste d'interventions
          non-pharmacologiques]. Si la situation n'évolue pas
          dans 1 heure, nous pourrions discuter de la péridurale
          non pas comme un échec mais comme un outil pour
          relancer le travail. Qu'en pensez-vous ?"

    postpartum_mental_health_screening:
      description: >
        Dépistage précoce de la dépression post-partum (DPP) et du
        stress post-traumatique (SSPT) lié à l'accouchement.
      
      screening_tools:
        - "EPDS (Edinburgh Postnatal Depression Scale) automatisé"
        - "PCL-5 adapté (PTSD checklist)"
        - "Analyse longitudinale des interactions mère-enfant"
      
      risk_factors_tracked:
        - "Accouchement traumatique (césarienne urgente, hémorragie)"
        - "Séparation mère-enfant prolongée"
        - "Apgar bas / réanimation néonatale"
        - "Perte de contrôle perçue pendant le travail"
        - "Antécédents psychiatriques"
      
      early_intervention:
        description: >
          Si le risque de DPP est élevé (>30%), le système recommande
          une consultation psychologique avant la sortie de maternité,
          un suivi rapproché par la PMI, et fournit des ressources
          d'auto-aide personnalisées.

    team_wellbeing_monitor:
      description: >
        L'IA surveille aussi le bien-être de l'ÉQUIPE SOIGNANTE.
        Le burnout et la fatigue des soignants sont un facteur
        majeur d'erreurs médicales en obstétrique.
      
      signals:
        - "Charge de travail actuelle (nombre de patientes actives)"
        - "Heures de garde continues"
        - "Événements stressants récents (décès périnatal, urgence)"
        - "Patterns de communication (brevité, irritabilité)"
      
      alerts:
        - condition: "Charge critique (>3 travails actifs pour 1 sage-femme)"
          recommendation: "Renfort requis, risque d'omission de surveillance"
        - condition: "Garde > 16h continue pour obstétricien"
          recommendation: "Relève recommandée pour décisions à haut risque"

7. SIMULATION D'ACCOUCHEMENT PRÉDICTIVE (Digital Rehearsal)
Le concept : Répéter virtuellement l'accouchement avant qu'il n'ait lieu
yamlCopy# ============================================================================
# FONCTIONNALITÉ 7: PREDICTIVE BIRTH SIMULATION (Digital Rehearsal)
# ============================================================================

feature:
  id: "predictive-birth-simulation"
  name: "Simulation Prédictive d'Accouchement"
  maturity: "innovative"
  timeline: "12-24 months"

  description: >
    Avant un accouchement à risque (RCIU sévère, utérus cicatriciel,
    macrosomie, prématurité), le système simule l'ensemble du
    scénario d'accouchement en version accélérée (100x-1000x).
    
    L'équipe peut "visualiser" les différentes trajectoires possibles,
    identifier les points de bifurcation critiques, et se préparer
    mentalement et matériellement pour chaque éventualité.
    
    C'est le "briefing avant mission" des pilotes appliqué à
    l'obstétrique.

  capabilities:
    monte_carlo_birth_simulation:
      description: >
        Simule 10,000 scénarios d'accouchement possibles basés sur
        le profil spécifique de la patiente, en faisant varier les
        paramètres incertains (réponse à l'ocytocine, progression
        du travail, résilience fœtale).
      
      inputs:
        - "Profil maternel complet"
        - "Données fœtales actuelles"
        - "Protocole de prise en charge prévu"
        - "Paramètres d'incertitude calibrés"
      
      outputs:
        probability_tree:
          description: "Arbre probabiliste des scénarios"
          branching_points:
            - time: "Début du travail"
              branches:
                - "Travail spontané (40%)"
                - "Déclenchement nécessaire (60%)"
            - time: "Phase active"
              branches:
                - "Progression normale (55%)"
                - "Stagnation (30%)"
                - "Travail rapide (15%)"
            - time: "Décision clé"
              branches:
                - "Accouchement vaginal spontané (35%)"
                - "Extraction instrumentale (15%)"
                - "Césarienne non urgente (30%)"
                - "Césarienne urgente (15%)"
                - "Césarienne code rouge (5%)"
          
          outcome_distribution:
            apgar_7plus_5min: "92% des simulations"
            maternal_hemorrhage: "8% des simulations"
            nicu_admission: "15% des simulations"
            
        timeline_visualization:
          description: >
            Frise chronologique interactive montrant les différents
            scénarios avec code couleur probabiliste. L'équipe peut
            cliquer sur chaque bifurcation pour comprendre les
            facteurs déclenchants et les actions optimales.

    team_briefing_generator:
      description: >
        Génère automatiquement un briefing d'équipe structuré
        (type "huddle" aéronautique) avant l'accouchement à risque.
      
      briefing_structure:
        - section: "Présentation du cas"
          content: "Résumé clinique en 30 secondes"
        - section: "Scénario le plus probable"
          content: "Déroulement attendu et plan de base"
        - section: "Scénarios de contingence"
          content: "Top 3 complications possibles et plans B/C"
        - section: "Rôles et responsabilités"
          content: "Qui fait quoi si urgence code rouge"
        - section: "Points de décision critiques"
          content: "À quel moment basculer du plan A au plan B"
        - section: "Questions de l'équipe"
          content: "Discussion ouverte (IA répond aux questions)"

    training_simulation:
      description: >
        Le même moteur de simulation sert à la FORMATION des internes
        et sages-femmes. Des cas simulés réalistes avec feedback IA
        en temps réel.
      
      features:
        - "Cas générés procéduralement (infinité de scénarios)"
        - "Difficulté adaptative (s'ajuste au niveau de l'apprenant)"
        - "Feedback immédiat sur les décisions (optimal vs choix fait)"
        - "Debriefing automatique avec points d'apprentissage"
        - "Scoring et suivi de progression longitudinal"

8. YAML ADDENDUM — Intégration des Fonctionnalités Révolutionnaires
yamlCopy# ============================================================================
# ADDENDUM AU SYSTEM.YAML — FONCTIONNALITÉS IAMG
# ============================================================================

revolutionary_features:
  # Phase 1: Prêt dans 12-18 mois
  near_term:
    - id: "multimodal-reasoning-engine"
      priority: "P0"
      new_agents:
        - id: MultiModalFusionAgent
          name: "Multi-Modal Clinical Fusion Agent"
          description: "Fusion cross-modale CTG + écho + labos + texte + audio"
          llm_model: "gpt-4o (multimodal) + claude-opus-4 (reasoning)"
          ml_models:
            - "ctg_encoder (Temporal Transformer)"
            - "ultrasound_encoder (ViT-L/14)"
            - "lab_encoder (Tabular Transformer)"
            - "cross_modal_perceiver (Perceiver IO)"
          rest_endpoint:
            path: "/api/v2/multimodal-fusion"
            method: POST

        - id: ContrafactualReasoningAgent
          name: "Contrafactual Clinical Reasoning Agent"
          description: "Simulation de scénarios hypothétiques (what-if)"
          llm_model: "o3 (reasoning) + claude-opus-4"
          ml_models:
            - "causal_inference_model (DoWhy)"
            - "structural_causal_model (EconML)"
          rest_endpoint:
            path: "/api/v2/contrafactual"
            method: POST

    - id: "emotional-intelligence"
      priority: "P1"
      new_agents:
        - id: MaternalStressAgent
          name: "Maternal Stress & Wellbeing Agent"
          description: "Monitoring stress maternel et recommandations non-pharmacologiques"
          inputs:
            - "HRV maternelle (wearable ou monitoring)"
            - "Score de douleur déclaré"
            - "Analyse vocale (prosodie)"
            - "Contexte du travail (durée, événements)"
          llm_model: "mistral-large (empathetic communication)"
          ml_models:
            - "stress_classifier (HRV-based, XGBoost)"
            - "voice_stress_detector (Wav2Vec2 fine-tuned)"

        - id: PostpartumScreeningAgent
          name: "Postpartum Mental Health Screening Agent"
          description: "Dépistage DPP/SSPT et recommandation intervention précoce"
          llm_model: "claude-sonnet-4"
          ml_models:
            - "dpp_risk_predictor (LightGBM)"

    - id: "predictive-birth-simulation"
      priority: "P1"
      new_agents:
        - id: BirthSimulationAgent
          name: "Predictive Birth Simulation Agent"
          description: "Monte Carlo simulation des trajectoires d'accouchement"
          llm_model: "o3 (scenario analysis)"
          ml_models:
            - "labor_progression_model (Neural ODE)"
            - "monte_carlo_sampler (custom)"
          quantum_config:
            enabled: true
            purpose: "Quantum-accelerated Monte Carlo sampling"

  # Phase 2: Prêt dans 18-36 mois
  medium_term:
    - id: "fetal-digital-twin"
      priority: "P0"
      new_agents:
        - id: FetalDigitalTwinAgent
          name: "Fetal Digital Twin Agent"
          description: "Jumeau numérique physiologique continu du fœtus"
          ml_models:
            - "pinn_fetal_cardiovascular (Physics-Informed Neural Network)"
            - "neural_ode_fetal_dynamics (torchdiffeq)"
            - "ensemble_kalman_filter (state estimation)"
            - "bayesian_personalization (parameter calibration)"
          compute_requirements:
            gpu: "NVIDIA A100 80GB (real-time inference)"
            update_frequency: "2-3 Hz (per heartbeat)"

    - id: "autonomous-treatment-planning"
      priority: "P1"
      new_agents:
        - id: TreatmentPlanningAgent
          name: "Autonomous Therapeutic Planning Agent"
          description: "Planification multi-étapes adaptative avec contingences"
          llm_model: "claude-opus-4 (extended thinking)"
          ml_models:
            - "htn_planner (Hierarchical Task Network)"
            - "mcts_optimizer (Monte Carlo Tree Search)"
            - "pk_pd_models (per medication)"
          human_in_the_loop:
            trigger: "ALWAYS (every plan requires human approval)"
            display: "Interactive decision tree with probabilities"

  # Phase 3: Recherche frontière (36+ mois)
  long_term:
    - id: "collective-obstetric-memory"
      priority: "P1"
      infrastructure:
        federated_learning:
          framework: "NVIDIA FLARE"
          min_hospitals: 10
          privacy: "DP (ε=1.0) + Secure Aggregation"
        case_based_reasoning:
          vector_db: "pgvector (HNSW index)"
          target_cases: "10M+"

    - id: "epigenetic-transgenerational"
      priority: "P2"
      status: "research_partnership_required"
      partners:
        - "Genomics institute"
        - "Longitudinal birth cohort studies"
        - "Epigenetics laboratory"

  # Impact projeté
  projected_impact:
    clinical:
      - metric: "Réduction encéphalopathie hypoxique-ischémique"
        current_baseline: "1-2 pour 1000 naissances"
        projected_reduction: "40-60%"
        primary_feature: "fetal-digital-twin"
        evidence_level: "projected (requires validation)"

      - metric: "Réduction césariennes non nécessaires"
        current_baseline: "~20-25% (taux national)"
        projected_reduction: "15-20% du taux actuel"
        primary_feature: "contrafactual-reasoning + birth-simulation"

      - metric: "Détection précoce événements rares"
        examples: "Embolie amniotique, rupture utérine, HELLP"
        improvement: "Pré-alerte 10-60 min avant signes cliniques"
        primary_feature: "collective-obstetric-memory"

      - metric: "Réduction dépression post-partum"
        current_baseline: "10-15% des accouchées"
        projected_reduction: "30-40% (via dépistage + intervention précoce)"
        primary_feature: "emotional-intelligence"

      - metric: "Amélioration Apgar moyen"
        current_baseline: "Apgar <7 à 5 min: ~2%"
        projected_reduction: "50% des cas évitables"
        primary_features:
          - "fetal-digital-twin"
          - "autonomous-treatment-planning"

    systemic:
      - "Réduction des litiges médico-légaux (traçabilité + prédiction)"
      - "Réduction du burnout des soignants (aide décisionnelle + charge cognitive réduite)"
      - "Démocratisation de l'expertise obstétricale (hôpitaux ruraux = même IA que CHU)"
      - "Accélération de la recherche périnatale (patterns émergents, épigénétique)"
      - "Formation continue personnalisée via simulation"

9. TABLEAU COMPARATIF : CDS CLASSIQUE vs IAMG OBSTÉTRICALE
Copy┌──────────────────────────┬────────────────────────────┬─────────────────────────────────┐
│        DIMENSION         │     CDS CLASSIQUE          │     IAMG OBSTÉTRICALE           │
│                          │   (État de l'art 2024)     │   (Vision proposée)             │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Analyse                  │ Un signal à la fois        │ TOUS les signaux simultanément  │
│                          │ (CTG OU écho OU labo)      │ (CTG + écho + labo + voix +     │
│                          │                            │ contexte + émotions)            │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Temporalité              │ Snapshot (état actuel)      │ TRAJECTOIRE (passé → présent    │
│                          │                            │ → futur prédit)                 │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Granularité              │ Classification catégorielle │ Distribution continue de        │
│                          │ (Normal/Pathologique)      │ probabilités avec incertitude   │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Personnalisation         │ Même modèle pour tous      │ Modèle CALIBRÉ sur CE fœtus,    │
│                          │                            │ CETTE mère, CET accouchement    │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Raisonnement             │ "Si X alors Y" (règles)    │ "Si X, mais dans le contexte    │
│                          │                            │ de Y et Z, alors probablement   │
│                          │                            │ W parce que..." (causal)        │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Anticipation             │ Détection (quand ça arrive) │ PRÉDICTION (20-45 min AVANT)    │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Recommandation           │ "Alerte: problème détecté"  │ Plan thérapeutique complet      │
│                          │                            │ multi-étapes avec contingences   │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Contrefactuel            │ Impossible                 │ "Si on fait X, probabilité Y    │
│                          │                            │ est Z%. Si on attend, ..."      │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Apprentissage            │ Statique (retrain manuel)  │ CONTINU (chaque accouchement    │
│                          │                            │ améliore le modèle, fédéré)     │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Scope temporel           │ Pendant l'accouchement     │ Pré-conception → grossesse →    │
│                          │                            │ accouchement → néonatal →       │
│                          │                            │ développement → vie adulte      │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Dimension humaine        │ Ignorée                    │ Stress, émotions, expérience    │
│                          │                            │ vécue, santé mentale intégrés   │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Événements rares         │ Trop peu de données        │ Apprentissage fédéré sur 1M+    │
│                          │ localement                 │ naissances → détection possible │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Explicabilité            │ SHAP/LIME post-hoc         │ Raisonnement en langage naturel │
│                          │                            │ + SHAP + arbre causal visuel    │
├──────────────────────────┼────────────────────────────┼─────────────────────────────────┤
│ Formation                │ Séparé du soin              │ Simulation intégrée, debriefing │
│                          │                            │ IA, apprentissage continu       │
└──────────────────────────┴────────────────────────────┴─────────────────────────────────┘

10. FEUILLE DE ROUTE D'IMPLÉMENTATION
yamlCopy# ============================================================================
# ROADMAP D'IMPLÉMENTATION VERS L'IAMG OBSTÉTRICALE
# ============================================================================

roadmap:
  phase_1_foundation:
    timeline: "Mois 1-6"
    title: "Fondations (Système Actuel Opérationnel)"
    deliverables:
      - "Déploiement du système agentique de base (14 agents)"
      - "Pipeline ML opérationnel (6 modèles spécialisés)"
      - "Frontend dashboard temps réel"
      - "FHIR R4 integration complète"
      - "Audit trail et conformité EU AI Act"
    status: "En cours (ce document)"

  phase_2_multimodal:
    timeline: "Mois 6-18"
    title: "Intelligence Multi-Modale"
    deliverables:
      - "Encodeur CTG pré-entraîné (self-supervised, 500K heures)"
      - "Encodeur échographique (ViT-L/14 fine-tuned)"
      - "Fusion cross-modale Perceiver IO"
      - "Raisonnement contrefactuel (DoWhy/EconML)"
      - "Assistant vocal salle de naissance"
      - "Module stress maternel (HRV + voix)"
      - "Simulation prédictive Monte Carlo"
    research_partnerships:
      - "Collaboration avec 5+ maternités pour données multimodales"
      - "Partenariat université pour modèles causaux"
    regulatory:
      - "Mise à jour dossier technique MDR"
      - "Étude clinique observationnelle (n=1000)"

  phase_3_digital_twin:
    timeline: "Mois 18-36"
    title: "Jumeau Numérique Fœtal"
    deliverables:
      - "PINN cardiovasculaire fœtal validé"
      - "Neural ODE personnalisé par fœtus"
      - "Estimation pH continu non-invasif"
      - "Prédiction décompensation 20-45 min"
      - "Avatar 3D temps réel (Three.js/WebGPU)"
      - "Planification thérapeutique autonome (HTN+MCTS)"
      - "Dépistage DPP/SSPT automatisé"
    validation:
      - "Étude prospective multicentrique (n=5000)"
      - "Comparaison pH estimé vs pH scalp/cordon"
      - "Validation prédiction décompensation vs outcomes"
    regulatory:
      - "Certification CE Mark classe IIb"
      - "Soumission FDA 510(k) ou De Novo"

  phase_4_collective_intelligence:
    timeline: "Mois 36-60"
    title: "Intelligence Collective et Épigénétique"
    deliverables:
      - "Réseau fédéré opérationnel (10+ hôpitaux)"
      - "Base de cas anonymisés (1M+ naissances)"
      - "Détection événements rares (embolie, rupture)"
      - "Module épigénétique (recherche)"
      - "Suivi transgénérationnel (protocole de recherche)"
    research:
      - "Publications sur patterns émergents découverts"
      - "Cohorte longitudinale épigénétique"
    impact_measurement:
      - "Réduction mesurée de l'EHI"
      - "Réduction mesurée des césariennes non nécessaires"
      - "Amélioration mesurée de l'expérience de naissance"
      - "Réduction mesurée de la DPP"


En résumé, ces fonctionnalités transforment le système d'un outil d'aide à la décision ponctuel en une véritable Intelligence Obstétricale Générale : un partenaire clinique qui comprend profondément la physiologie fœto-maternelle, anticipe les complications, planifie les soins de manière holistique, apprend collectivement de chaque naissance, et n'oublie jamais que derrière chaque donnée, il y a une mère, un enfant, et une famille dont la vie va changer pour toujours.

